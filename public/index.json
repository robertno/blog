[{"authors":["admin"],"categories":null,"content":"本人男，16年入读江南大学食品科学博士。\n","date":1554595200,"expirydate":-62135596800,"kind":"taxonomy","lang":"zh","lastmod":1554595200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"本人男，16年入读江南大学食品科学博士。","tags":null,"title":"Dr.二哈","type":"authors"},{"authors":null,"categories":null,"content":"Flexibility This feature can be used for publishing content such as:\n Online courses Project or software documentation Tutorials  The courses folder may be renamed. For example, we can rename it to docs for software/project documentation or tutorials for creating an online course.\nDelete tutorials To remove these pages, delete the courses folder and see below to delete the associated menu link.\nUpdate site menu After renaming or deleting the courses folder, you may wish to update any [[main]] menu links to it by editing your menu configuration at config/_default/menus.toml.\nFor example, if you delete this folder, you can remove the following from your menu configuration:\n[[main]] name = \u0026quot;Courses\u0026quot; url = \u0026quot;courses/\u0026quot; weight = 50  Or, if you are creating a software documentation site, you can rename the courses folder to docs and update the associated Courses menu configuration to:\n[[main]] name = \u0026quot;Docs\u0026quot; url = \u0026quot;docs/\u0026quot; weight = 50  Update the docs menu If you use the docs layout, note that the name of the menu in the front matter should be in the form [menu.X] where X is the folder name. Hence, if you rename the courses/example/ folder, you should also rename the menu definitions in the front matter of files within courses/example/ from [menu.example] to [menu.\u0026lt;NewFolderName\u0026gt;].\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"zh","lastmod":1536451200,"objectID":"59c3ce8e202293146a8a934d37a4070b","permalink":"/courses/example/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/courses/example/","section":"courses","summary":"Learn how to use Academic's docs layout for publishing online courses, software documentation, and tutorials.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 2 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1557010800,"objectID":"74533bae41439377bd30f645c4677a27","permalink":"/courses/example/example1/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example1/","section":"courses","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":null,"title":"Example Page 1","type":"docs"},{"authors":null,"categories":null,"content":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 4 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1557010800,"objectID":"1c2b5a11257c768c90d5050637d77d6a","permalink":"/courses/example/example2/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example2/","section":"courses","summary":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":null,"title":"Example Page 2","type":"docs"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Academic\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1906549200,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"/talk/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example/","section":"talk","summary":"An example talk using Academic's Markdown slides feature.","tags":[],"title":"Example Talk","type":"talk"},{"authors":[],"categories":["R","统计"],"content":"\r第四章 简单的函数\r今天开始第四章。如题所见，就是简单的函数。\rR与其说是一门编程语言，在我看来，它不是，编程只是为了让它更方便快捷，它的初衷，就是统计分析作图。而函数这个概念，在各个编程语言中都出现过，而且地位都不低。这是因为，函数就可以让我们的操作简单起来，算平均值就来个mean()，不用把所有数字加起来再除以个数。\r下面看书上的第一节。\n4.1 tapply函数\r书上的逻辑是这样的：\n先介绍了一下所用的数据集Vrg，是一个对两个温带（美国黄石国家公园和国家野牛保护区）的草原数据的监控分析。这个研究的目的是确定某段时间丛生禾草群落的生物多样性是否发生变化，如果变了，是否与环境因素有关。生物多样性用物种丰富度来定义也就是下面数据展示中的变量R，即每个地点的不同种群数量。研究识别出大约90个物种，数据来自于8个时间截面（也就是变量Transect，对，没看错，中文版就是时间截面），每个截面大约是4-10年，总共选取58个观测值：\r\rVeg \u0026lt;- read.table(file = \u0026quot;F:\\\\database\\\\RBook\\\\Vegetation2.txt\u0026quot;,\rheader = TRUE)\rhead(Veg, n=20L)\r## TransectName Samples Transect Time R ROCK LITTER ML BARESOIL FallPrec\r## 1 A_22_58 1 1 1958 8 27.0 30.0 0 26 30.22\r## 2 A_22_62 2 1 1962 6 26.0 20.0 0 28 99.56\r## 3 A_22_67 3 1 1967 8 30.0 24.0 0 30 43.43\r## 4 A_22_74 4 1 1974 8 18.0 35.0 0 16 54.86\r## 5 A_22_81 5 1 1981 10 23.0 22.0 4 9 24.38\r## 6 A_22_94 6 1 1994 7 26.0 26.0 0 23 10.16\r## 7 A_22_02 7 1 2002 6 39.0 19.0 4 19 34.29\r## 8 C_22_58 8 2 1958 5 25.0 26.0 0 33 30.22\r## 9 C_22_62 9 2 1962 8 24.0 24.0 2 29 99.56\r## 10 C_22_67 10 2 1967 6 21.0 16.0 1 41 43.43\r## 11 C_22_74 11 2 1974 6 18.0 25.0 0 33 54.86\r## 12 C_22_81 12 2 1981 6 19.0 28.0 0 14 24.38\r## 13 C_22_94 13 2 1994 6 10.5 41.5 0 29 10.16\r## 14 C_22_02 14 2 2002 6 26.0 18.0 2 42 34.29\r## 15 D_12_58 15 3 1958 7 56.0 17.0 0 16 33.78\r## 16 D_12_62 16 3 1962 10 45.0 7.0 0 23 143.51\r## 17 D_12_67 17 3 1967 8 28.0 14.0 0 37 56.38\r## 18 D_12_74 18 3 1974 18 27.0 15.0 0 7 68.32\r## 19 D_12_81 19 3 1981 12 10.0 37.0 0 0 57.40\r## 20 D_12_89 20 3 1989 11 17.0 17.0 0 33 17.52\r## SprPrec SumPrec WinPrec FallTmax SprTmax SumTmax WinTmax FallTmin SprTmin\r## 1 75.43 125.47 39.62 16.96 15.77 25.17 3.47 0.49 0.36\r## 2 56.13 94.99 107.44 14.56 15.21 24.85 1.16 -0.18 0.18\r## 3 65.02 112.26 76.70 18.44 12.76 25.51 3.09 1.23 -1.86\r## 4 58.67 70.35 90.67 17.16 14.00 26.67 2.46 1.43 -0.53\r## 5 87.63 81.78 45.97 18.49 14.33 26.02 5.72 1.09 0.75\r## 6 57.15 95.25 60.70 17.39 16.91 26.78 3.64 0.28 0.64\r## 7 31.49 62.99 43.68 19.29 13.86 26.27 2.54 1.86 -1.37\r## 8 75.43 125.47 39.62 16.98 15.79 25.19 3.49 0.51 0.38\r## 9 56.13 94.99 107.44 14.58 15.23 24.87 1.18 -0.16 0.19\r## 10 65.02 112.26 76.70 18.46 12.78 25.53 3.11 1.25 -1.85\r## 11 58.67 70.35 90.67 17.18 14.01 26.68 2.47 1.45 -0.52\r## 12 87.63 81.78 45.97 18.51 14.35 26.04 5.74 1.11 0.76\r## 13 57.15 95.25 60.70 17.41 16.92 26.80 3.65 0.30 0.65\r## 14 31.49 62.99 43.68 19.31 13.88 26.29 2.56 1.88 -1.35\r## 15 107.95 181.61 105.15 13.00 11.79 21.12 -0.32 -3.28 -3.43\r## 16 73.40 125.73 173.48 10.65 11.25 20.81 -2.58 -3.91 -3.58\r## 17 83.05 121.15 117.60 14.42 8.91 21.42 -0.72 -2.55 -5.59\r## 18 65.78 88.64 116.84 13.23 10.09 22.59 -1.29 -2.31 -4.30\r## 19 87.12 133.09 67.05 14.57 10.42 21.96 1.90 -2.69 -3.03\r## 20 101.34 120.14 128.01 15.93 11.00 22.06 -2.77 -2.25 -4.11\r## SumTmin WinTmin PCTSAND PCTSILT PCTOrgC\r## 1 6.97 -8.54 24 30 0.03459\r## 2 6.40 -10.76 24 30 0.03459\r## 3 7.12 -8.50 24 30 0.03459\r## 4 7.20 -8.28 24 30 0.03459\r## 5 6.90 -7.56 24 30 0.03459\r## 6 6.94 -9.21 24 30 0.03459\r## 7 6.96 -9.61 24 30 0.03459\r## 8 6.99 -8.52 20 34 0.06160\r## 9 6.41 -10.74 20 34 0.06160\r## 10 7.14 -8.48 20 34 0.06160\r## 11 7.22 -8.27 20 34 0.06160\r## 12 6.92 -7.54 20 34 0.06160\r## 13 6.96 -9.19 20 34 0.06160\r## 14 6.98 -9.59 20 34 0.06160\r## 15 3.11 -12.23 14 46 0.03630\r## 16 2.55 -14.38 14 46 0.03630\r## 17 3.25 -12.20 14 46 0.03630\r## 18 3.32 -11.92 14 46 0.03630\r## 19 3.06 -11.27 14 46 0.03630\r## 20 3.81 -14.48 14 46 0.03630\rnames(Veg)\r## [1] \u0026quot;TransectName\u0026quot; \u0026quot;Samples\u0026quot; \u0026quot;Transect\u0026quot; \u0026quot;Time\u0026quot; \u0026quot;R\u0026quot; ## [6] \u0026quot;ROCK\u0026quot; \u0026quot;LITTER\u0026quot; \u0026quot;ML\u0026quot; \u0026quot;BARESOIL\u0026quot; \u0026quot;FallPrec\u0026quot; ## [11] \u0026quot;SprPrec\u0026quot; \u0026quot;SumPrec\u0026quot; \u0026quot;WinPrec\u0026quot; \u0026quot;FallTmax\u0026quot; \u0026quot;SprTmax\u0026quot; ## [16] \u0026quot;SumTmax\u0026quot; \u0026quot;WinTmax\u0026quot; \u0026quot;FallTmin\u0026quot; \u0026quot;SprTmin\u0026quot; \u0026quot;SumTmin\u0026quot; ## [21] \u0026quot;WinTmin\u0026quot; \u0026quot;PCTSAND\u0026quot; \u0026quot;PCTSILT\u0026quot; \u0026quot;PCTOrgC\u0026quot;\rstr(Veg)\r## \u0026#39;data.frame\u0026#39;: 58 obs. of 24 variables:\r## $ TransectName: Factor w/ 58 levels \u0026quot;A_22_02\u0026quot;,\u0026quot;A_22_58\u0026quot;,..: 2 3 4 5 6 7 1 9 10 11 ...\r## $ Samples : int 1 2 3 4 5 6 7 8 9 10 ...\r## $ Transect : int 1 1 1 1 1 1 1 2 2 2 ...\r## $ Time : int 1958 1962 1967 1974 1981 1994 2002 1958 1962 1967 ...\r## $ R : int 8 6 8 8 10 7 6 5 8 6 ...\r## $ ROCK : num 27 26 30 18 23 26 39 25 24 21 ...\r## $ LITTER : num 30 20 24 35 22 26 19 26 24 16 ...\r## $ ML : int 0 0 0 0 4 0 4 0 2 1 ...\r## $ BARESOIL : num 26 28 30 16 9 23 19 33 29 41 ...\r## $ FallPrec : num 30.2 99.6 43.4 54.9 24.4 ...\r## $ SprPrec : num 75.4 56.1 65 58.7 87.6 ...\r## $ SumPrec : num 125.5 95 112.3 70.3 81.8 ...\r## $ WinPrec : num 39.6 107.4 76.7 90.7 46 ...\r## $ FallTmax : num 17 14.6 18.4 17.2 18.5 ...\r## $ SprTmax : num 15.8 15.2 12.8 14 14.3 ...\r## $ SumTmax : num 25.2 24.9 25.5 26.7 26 ...\r## $ WinTmax : num 3.47 1.16 3.09 2.46 5.72 ...\r## $ FallTmin : num 0.49 -0.18 1.23 1.43 1.09 ...\r## $ SprTmin : num 0.36 0.18 -1.86 -0.53 0.75 ...\r## $ SumTmin : num 6.97 6.4 7.12 7.2 6.9 ...\r## $ WinTmin : num -8.54 -10.76 -8.5 -8.28 -7.56 ...\r## $ PCTSAND : int 24 24 24 24 24 24 24 20 20 20 ...\r## $ PCTSILT : int 30 30 30 30 30 30 30 34 34 34 ...\r## $ PCTOrgC : num 0.0346 0.0346 0.0346 0.0346 0.0346 ...\r然后算了下8个时间截面的总体物种平均丰富度m以及每个时间截面的平均丰富度m1-m8，并做出了一个向量：\r\rm \u0026lt;- mean(Veg$R)\rm1 \u0026lt;- mean(Veg$R[Veg$Transect==1])\rm2 \u0026lt;- mean(Veg$R[Veg$Transect==2])\rm3 \u0026lt;- mean(Veg$R[Veg$Transect==3])\rm4 \u0026lt;- mean(Veg$R[Veg$Transect==4])\rm5 \u0026lt;- mean(Veg$R[Veg$Transect==5])\rm6 \u0026lt;- mean(Veg$R[Veg$Transect==6])\rm7 \u0026lt;- mean(Veg$R[Veg$Transect==7])\rm8 \u0026lt;- mean(Veg$R[Veg$Transect==8])\rc(m,m1,m2,m3,m4,m5,m6,m7,m8)\r## [1] 9.965517 7.571429 6.142857 10.375000 9.250000 12.375000 11.500000\r## [8] 10.500000 11.833333\r大家也看出来了，算每个时间截面的平均丰富度，要是这么做就太麻烦了，能不能简单点呢。答案是有的，就是tapply函数。先演示一下：\r\rtapply(Veg$R, Veg$Transect, mean)\r## 1 2 3 4 5 6 7 8 ## 7.571429 6.142857 10.375000 9.250000 12.375000 11.500000 10.500000 11.833333\r#或者\rtapply(X = Veg$R, INDEX = Veg$Transect, FUN = mean)\r## 1 2 3 4 5 6 7 8 ## 7.571429 6.142857 10.375000 9.250000 12.375000 11.500000 10.500000 11.833333\r解释一下，看第二个语句就应该明白了。tapply这个函数常用的有3个参数，x=……是告诉它，我要对哪个数据集中的哪个变量操作，INDEX=……是告诉它，我要以什么水平来处理这个x，最后的FUN=……就是告诉它，我要对x做什么运算，可以用内置的函数比如mean，sd什么的，也可以用自己编写的函数。\r注意大小写。\r同理，标准差sd，方差，长度什么的都可以。\nMe \u0026lt;- tapply(Veg$R, Veg$Transect, mean)\rSd \u0026lt;- tapply(Veg$R, Veg$Transect, sd)\rLe \u0026lt;- tapply(Veg$R, Veg$Transect, length)\r#然后用cbind组合起来\rcbind(Me,Sd,Le)\r## Me Sd Le\r## 1 7.571429 1.3972763 7\r## 2 6.142857 0.8997354 7\r## 3 10.375000 3.5831949 8\r## 4 9.250000 2.3145502 8\r## 5 12.375000 2.1339099 8\r## 6 11.500000 2.2677868 8\r## 7 10.500000 3.1464265 6\r## 8 11.833333 2.7141604 6\r第一节就没了，书上还分了两个小节…………咋想的。\n\r4.2 sapply函数和lapply函数\r大家可能也发现了，我并没用tapply函数计算整个变量R的平均值。是因为这个整体的平均值比较简单。但是如果要一次性输出Veg数据集中所有数值型变量的平均值呢，该怎么做？\r这个工作要交给sapply函数,比如我就想一次性输出变量R：ROCK，LITTER，ML，BARESOIL的平均值：\nsapply(Veg[, 5:9], FUN = mean)\r## R ROCK LITTER ML BARESOIL ## 9.965517 20.991379 22.853448 1.086207 17.594828\r这个方括号中的5:9指的就是这5个变量。\r那这小节标题中的lapply呢，它是干什么的。\r还是用例子来说明，我还是计算着5个变量的平均值：\nlapply(Veg[, 5:9], FUN = mean)\r## $R\r## [1] 9.965517\r## ## $ROCK\r## [1] 20.99138\r## ## $LITTER\r## [1] 22.85345\r## ## $ML\r## [1] 1.086207\r## ## $BARESOIL\r## [1] 17.59483\r发现差异了吗？sapply输出结果是个向量，而lapply输出的结果却是个列表（list）。\r这里要注意一点，lappy和sapply中包含数据的变量（对，没看错，中文版就是这么写的，其实指的就是那个x）必须是个数据框，要是这么写，就错了：\nsapply(cbind(Veg$R, Veg$ROCK, Veg$LITTER, Veg$ML, Veg$BARESOIL), FUN = mean)\r## [1] 8.0 6.0 8.0 8.0 10.0 7.0 6.0 5.0 8.0 6.0 6.0 6.0 6.0 6.0 7.0\r## [16] 10.0 8.0 18.0 12.0 11.0 7.0 10.0 8.0 9.0 6.0 12.0 13.0 10.0 8.0 8.0\r## [31] 13.0 16.0 9.0 14.0 11.0 13.0 11.0 12.0 9.0 10.0 14.0 14.0 10.0 14.0 9.0\r## [46] 12.0 11.0 12.0 14.0 9.0 5.0 12.0 9.0 10.0 16.0 12.0 10.0 14.0 27.0 26.0\r## [61] 30.0 18.0 23.0 26.0 39.0 25.0 24.0 21.0 18.0 19.0 10.5 26.0 56.0 45.0 28.0\r## [76] 27.0 10.0 17.0 26.5 36.0 53.0 59.0 45.0 41.0 35.0 44.0 53.5 59.0 15.0 20.0\r## [91] 4.0 8.0 5.0 4.0 2.0 8.0 5.0 7.0 5.0 6.0 3.0 2.0 3.0 0.0 20.0\r## [106] 7.0 11.0 6.0 0.0 15.0 25.0 23.0 14.0 11.0 8.0 13.0 30.0 20.0 24.0 35.0\r## [121] 22.0 26.0 19.0 26.0 24.0 16.0 25.0 28.0 41.5 18.0 17.0 7.0 14.0 15.0 37.0\r## [136] 17.0 14.0 19.0 10.0 5.0 9.0 12.0 24.0 10.0 18.0 9.0 23.0 21.0 51.0 34.0\r## [151] 28.0 30.0 32.0 29.0 32.0 20.0 29.0 19.0 23.0 32.0 22.5 28.0 26.0 29.0 23.0\r## [166] 40.0 14.5 21.0 24.0 15.0 15.0 18.0 29.0 26.0 0.0 0.0 0.0 0.0 4.0 0.0\r## [181] 4.0 0.0 2.0 1.0 0.0 0.0 0.0 2.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\r## [196] 1.0 0.0 3.0 1.0 0.0 0.0 0.0 0.0 5.0 0.0 0.0 0.0 2.0 0.0 5.0\r## [211] 0.0 7.0 0.0 0.0 3.0 0.0 0.0 6.0 0.0 2.0 1.0 1.0 0.0 0.0 0.0\r## [226] 7.0 2.0 4.0 0.0 0.0 0.0 0.0 26.0 28.0 30.0 16.0 9.0 23.0 19.0 33.0\r## [241] 29.0 41.0 33.0 14.0 29.0 42.0 16.0 23.0 37.0 7.0 0.0 33.0 17.5 4.0 20.0\r## [256] 13.0 30.0 7.0 3.0 12.0 7.5 5.0 20.0 19.0 13.0 2.0 1.0 11.0 11.0 5.0\r## [271] 30.0 37.0 12.0 13.0 9.0 4.0 16.5 17.0 27.0 26.0 0.0 0.0 35.0 7.0 20.0\r## [286] 20.0 14.0 4.0 27.0 13.0\r它会输出一个很长的向量，根本不是你想要的。原因就在于cbind输出的不是数据框。\r可以改成这样：\nsapply(data.frame(cbind(Veg$R, Veg$ROCK, Veg$LITTER, Veg$ML, Veg$BARESOIL)), FUN = mean)\r## X1 X2 X3 X4 X5 ## 9.965517 20.991379 22.853448 1.086207 17.594828\r但是对比之前的结果，又有不同的地方，这个语句输出的结果中，丢失了变量标签，只有X1什么的。有两种解决方法，一是在运行sapply之前就生成一个合适的数据框，二是在用cbind结合数据后再用colnames函数来加上标签。\n\r4.3 summary函数\r这个函数，看名字就知道了，会输出变量信息。相当于统计概要：\nZ \u0026lt;- cbind(Veg$R, Veg$ROCK, Veg$LITTER)\rcolnames(Z) \u0026lt;- c(\u0026quot;R\u0026quot;, \u0026quot;ROCK\u0026quot;, \u0026quot;LITTER\u0026quot;)\rsummary(Z)\r## R ROCK LITTER ## Min. : 5.000 Min. : 0.00 Min. : 5.00 ## 1st Qu.: 8.000 1st Qu.: 7.25 1st Qu.:17.00 ## Median :10.000 Median :18.50 Median :23.00 ## Mean : 9.966 Mean :20.99 Mean :22.85 ## 3rd Qu.:12.000 3rd Qu.:27.00 3rd Qu.:28.75 ## Max. :18.000 Max. :59.00 Max. :51.00\r你看结果，最小值，第一四分位数，中位数，平均值，第三四分位数，最大值都出来了。\r下面的语句也可以输出这样的结果：\nsummary(Veg[, c(\u0026quot;R\u0026quot;, \u0026quot;ROCK\u0026quot;, \u0026quot;LITTER\u0026quot;)])\r## R ROCK LITTER ## Min. : 5.000 Min. : 0.00 Min. : 5.00 ## 1st Qu.: 8.000 1st Qu.: 7.25 1st Qu.:17.00 ## Median :10.000 Median :18.50 Median :23.00 ## Mean : 9.966 Mean :20.99 Mean :22.85 ## 3rd Qu.:12.000 3rd Qu.:27.00 3rd Qu.:28.75 ## Max. :18.000 Max. :59.00 Max. :51.00\rsummary(Veg[, c(5, 6, 7)])\r## R ROCK LITTER ## Min. : 5.000 Min. : 0.00 Min. : 5.00 ## 1st Qu.: 8.000 1st Qu.: 7.25 1st Qu.:17.00 ## Median :10.000 Median :18.50 Median :23.00 ## Mean : 9.966 Mean :20.99 Mean :22.85 ## 3rd Qu.:12.000 3rd Qu.:27.00 3rd Qu.:28.75 ## Max. :18.000 Max. :59.00 Max. :51.00\r道理是一样的。\n\r4.4 table函数\r这里以第二章的习题1和7为例，引入鹿的数据，这些数据来源于不同的农场、月份、年份和性别。这项研究的一个目的就是找出寄生虫E.cervi的数量和动物长度的关系（对，你没看出，中文版就是动物长度），而这种关系可能与农场、月份、年份和性别都有关系（对，就是关系与什么什么有关系，中文版就是这么写的），为了验证这一点，统计模型中就要有相互作用。但是，如果某些年份没有进行雌性的抽样，或者某些年份一些农场没有提供抽样，就会出现问题，因为这就形成了缺失值。\rtabble函数的作用就是用来了解每个农场提供抽样动物的数量，每个性别和年份观察值的数量。\nDeer \u0026lt;- read.table(file = \u0026quot;F:\\\\database\\\\RBook\\\\Deer.txt\u0026quot;, header = TRUE, fill=TRUE)\rhead(Deer, n = 20L)\r## Farm Month Year Sex clas1_4 LCT KFI Ecervi Tb\r## 1 AL 10 0 1 4 191 20.45 0.0000 0\r## 2 AL 10 0 1 4 180 16.40 0.0000 0\r## 3 AL 10 0 1 3 192 15.90 2.3800 0\r## 4 AL 10 0 1 4 196 17.30 0.0000 0\r## 5 AL 10 0 1 4 204 NA 0.0000 NA\r## 6 AL 10 0 1 4 190 16.30 0.0000 0\r## 7 AL 10 0 1 4 196 22.20 1.2100 NA\r## 8 AL 10 0 1 4 200 14.70 0.0000 1\r## 9 AL 10 0 1 4 197 13.50 0.8000 0\r## 10 AL 10 0 1 4 208 15.15 0.0000 0\r## 11 AL 10 0 1 4 216 15.20 0.0000 0\r## 12 AL 10 0 1 4 199 14.50 0.9000 1\r## 13 AL 10 0 1 4 178 11.55 53.6000 1\r## 14 AL 10 0 1 4 206 14.00 14.3700 0\r## 15 AL 11 2 2 3 164 24.52 0.0000 0\r## 16 AU 12 99 1 3 173 NA 27.7554 0\r## 17 AU 12 99 1 3 172 26.00 5.4846 0\r## 18 AU 12 99 1 4 184 16.10 5.4846 0\r## 19 AU 12 99 1 3 170 NA 0.0000 NA\r## 20 AU 12 99 1 3 155 NA 0.0000 NA\rnames(Deer)\r## [1] \u0026quot;Farm\u0026quot; \u0026quot;Month\u0026quot; \u0026quot;Year\u0026quot; \u0026quot;Sex\u0026quot; \u0026quot;clas1_4\u0026quot; \u0026quot;LCT\u0026quot; \u0026quot;KFI\u0026quot; ## [8] \u0026quot;Ecervi\u0026quot; \u0026quot;Tb\u0026quot;\rstr(Deer)\r## \u0026#39;data.frame\u0026#39;: 1182 obs. of 9 variables:\r## $ Farm : Factor w/ 28 levels \u0026quot;R\\xd1\\t02\u0026quot;,\u0026quot;R\\xd1\\t12\u0026quot;,..: 3 3 3 3 3 3 3 3 3 3 ...\r## $ Month : int 10 10 10 10 10 10 10 10 10 10 ...\r## $ Year : int 0 0 0 0 0 0 0 0 0 0 ...\r## $ Sex : int 1 1 1 1 1 1 1 1 1 1 ...\r## $ clas1_4: num 4 4 3 4 4 4 4 4 4 4 ...\r## $ LCT : num 191 180 192 196 204 190 196 200 197 208 ...\r## $ KFI : num 20.4 16.4 15.9 17.3 NA ...\r## $ Ecervi : num 0 0 2.38 0 0 0 1.21 0 0.8 0 ...\r## $ Tb : int 0 0 0 0 NA 0 NA 1 0 0 ...\r原文中这个命令并没有fill=TRUE这个参数，我为什么要加上呢，因为没有的话会报错：“Error in scan(file = file, what = what, sep = sep, quote = quote, dec = dec, : line 657 did not have 9 elements”，其实文件中第657行是有9个元素的，所以我加上这个参数让它忽略掉。\r变量中，农场分别采用AL、AU等表示，就是字符串，而其他变量都是数值或者整数型向量。那每个农场的观测值数量就可以这么来获得：\ntable(Deer$Farm)\r## ## R\\xd1\\t02 R\\xd1\\t12 AL AU BA BE CB CRC ## 10 15 15 37 98 19 93 16 ## HB LCV LN MAN MB MO NC NV ## 35 2 34 76 41 278 32 35 ## PA PN QM RF RO SAL SAU SE ## 11 45 75 34 44 1 3 26 ## TI TN VISO VY ## 21 31 15 40\r可以看到，有的农场（MO）抽取了278个样本，而有的农场（SAL）仅抽取了1个样本。\r然后再看看性别和年份：\ntable(Deer$Sex, Deer$Year)\r## ## 0 1 2 3 4 5 99\r## 1 100 88 157 72 78 34 21\r## 2 76 41 198 116 60 35 0\r## 3 0 9 1 0 0 0 0\r## 4 0 5 2 0 0 0 0\r这个结果中横向的0，1，2，3，4，5，99代表2000，2001，2002，2003，2004，2005和1999年，纵向的1和2代表性别。\r可以发现在1999年，只有一种性别的鹿被检测了。如果不知道这个，在后续处理中包含性别/年份交互作用项的数据就会报错。\n\r4.5 我们学习了哪些函数\r自己去整理去。\n\r4.6 习题\r使用tapply，sapply和lappy函数来计算每个月的平均值：\r文件temperature.xls包含了荷兰海岸线上31个不同地点的温度观测值。抽样开始于1990年，结束于2005年12月，为期16年，根据季节的不同，抽样频率为每月0-4次。\r以月为单位计算所有观测点的温度平均值，最终结果应该是一个16×12的变量。再计算每个月的观测值得标准差和数量。\r使用table函数来处理温度数据：\r使用习题1中的数据，确定每个观测点的观测值数量。每年记录了多少个观测值？每个观测点每年记录了多少观测值？\r\r\r\r","date":1583971200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1584019206,"objectID":"c1595dbd1773c547268f727f12bfbfbf","permalink":"/post/a-beginner-guide-to-r-chapter4/","publishdate":"2020-03-12T00:00:00Z","relpermalink":"/post/a-beginner-guide-to-r-chapter4/","section":"post","summary":"第四章 简单的函数 今天开始第四章。如题所见，就是简单的函数。 R","tags":["R","统计"],"title":"R语言初学者指南-第四章","type":"post"},{"authors":null,"categories":["R","统计"],"content":"\r时隔半年，我终于又开始写这个博客了。\r话不多说，言归正传。\n第三章 访问变量和处理数据子集\r在学习上一章导入数据，这一章节来学习对变量的访问和数据子集的处理。\n3.1 访问数据框变量\r当确认导入数据无误后，就可以按照自己的需求开始对数据进行删除部分数据，选取部分数据也就是数据子集了。\r以上一章的鱿鱼数据为例。\n#导入数据，并生成一个数据框\rSquid \u0026lt;- read.table(file = \u0026quot;F:\\\\database\\\\RBook\\\\squid.txt\u0026quot;, header = TRUE)\r#查看数据框中的变量名\rnames(Squid)\r## [1] \u0026quot;Sample\u0026quot; \u0026quot;Year\u0026quot; \u0026quot;Month\u0026quot; \u0026quot;Location\u0026quot; \u0026quot;Sex\u0026quot; \u0026quot;GSI\u0026quot;\r3.1.1 str函数\r这个函数主要是告诉我们这个Squid数据框中5个变量的属性。\nstr(Squid)\r## \u0026#39;data.frame\u0026#39;: 2644 obs. of 6 variables:\r## $ Sample : int 1 2 3 4 5 6 7 8 9 10 ...\r## $ Year : int 1 1 1 1 1 1 1 1 1 1 ...\r## $ Month : int 1 1 1 1 1 1 1 1 1 2 ...\r## $ Location: int 1 3 1 1 1 1 1 3 3 1 ...\r## $ Sex : int 2 2 2 2 2 2 2 2 2 2 ...\r## $ GSI : num 10.44 9.83 9.74 9.31 8.99 ...\r如这个结果所示，变量样本、年份、月份、位置和性别都是整数型即int，GSI是数值型即num。\r为什么建议在读入数据形成数据框之后，用str函数看一下变量属性呢，因为如果在读入数据时使用了错误的分割符号：\n#设定分割符号是\u0026quot;,\u0026quot;\rSquid2 \u0026lt;- read.table(file = \u0026quot;F:\\\\database\\\\RBook\\\\squid.txt\u0026quot;, dec = \u0026quot;,\u0026quot;, header = TRUE)\r#查看数据框中的变量属性\rstr(Squid2)\r## \u0026#39;data.frame\u0026#39;: 2644 obs. of 6 variables:\r## $ Sample : int 1 2 3 4 5 6 7 8 9 10 ...\r## $ Year : int 1 1 1 1 1 1 1 1 1 1 ...\r## $ Month : int 1 1 1 1 1 1 1 1 1 2 ...\r## $ Location: int 1 3 1 1 1 1 1 3 3 1 ...\r## $ Sex : int 2 2 2 2 2 2 2 2 2 2 ...\r## $ GSI : Factor w/ 2472 levels \u0026quot;0.0064\u0026quot;,\u0026quot;0.007\u0026quot;,..: 1533 2466 2462 2445 2428 2407 2379 2308 2288 2247 ...\r这个时候GSI就是个因子即factor，当后续处理时，R就会报错。\r后续我们将对GSI这个变量进行统计分析，值得注意的是，GSI存在于Squid这个数据框中，而没有存在于R的内存中，也就是说，在直接访问GSI的时候，R会报错。\n#我注释掉了，因为不这样的话，会卡在报错那里\r#GSI\r\r3.1.2 函数中的数据参数\r这一节说的是啥呢，书上翻译的感觉啰嗦，其实就是在有些函数中指定数据集。毕竟你想做个线性回归什么的，你得告诉R要用到哪个数据集。\nN1 \u0026lt;- lm(GSI~factor(Location)+factor(Year),\rdata = Squid)\rN1\r## ## Call:\r## lm(formula = GSI ~ factor(Location) + factor(Year), data = Squid)\r## ## Coefficients:\r## (Intercept) factor(Location)2 factor(Location)3 factor(Location)4 ## 1.3939 -2.2178 -0.1417 0.3138 ## factor(Year)2 factor(Year)3 factor(Year)4 ## 1.3548 0.9564 1.2270\r但是有些函数的参数没有这个data=……，比如mean()函数。这个时候可以用attach()函数绑定数据集。这个可以在之后讨论。\n\r3.1.3 $符号\r上文说到有的函数没有data参数，还有一个办法是用$符号。比如：\n#这个命令输出结果太多\r#Squid$GSI\r#于是我用了head显示前几行\rhead(Squid$GSI)\r## [1] 10.4432 9.8331 9.7356 9.3107 8.9926 8.7707\r还有一个方法，就是按列选择，观察数据框可以得知，GSI这个变量在Squid数据集的第6列，那么：\nhead(Squid[,6])\r## [1] 10.4432 9.8331 9.7356 9.3107 8.9926 8.7707\r当然，我不推荐这种方法，还得查第几列，麻烦。\n\r3.1.4 attach函数\r你看，之前提到了这个函数吧。这个函数可以把数据集添加到R的搜索路径中，这样，就可以直接访问数据集中的变量。\nattach(Squid)\r#直接访问变量GSI\rhead(GSI)\r## [1] 10.4432 9.8331 9.7356 9.3107 8.9926 8.7707\r#然后可以画图了\rboxplot(GSI)\r#或者运算\rmean(GSI)\r## [1] 2.187034\r#当想要解绑的时候\rdetach(Squid)\r注意哈，一次绑定一个数据，当想绑定其他数据集的时候，建议最好先解绑前一个数据集，避免有同名的变量干扰。\n\r\r3.2 访问数据子集\rSquid这个数据集里面有个sex变量，别想多了，是性别。此时，我只想对雄性的数据进行处理，可以这么做：\r首先需要知道性别是如何编码的：\nunique(Squid$Sex)\r## [1] 2 1\r这里是这么表示的，雄性是1，雌性是2。\r接下来访问所有的雄性数据，并存储在SquidM的数据框中：\nSe1 \u0026lt;- Squid$Sex == 1\rSquidM \u0026lt;- Squid[Se1,]\rhead(SquidM)\r## Sample Year Month Location Sex GSI\r## 24 24 1 5 1 1 5.2970\r## 48 48 1 5 3 1 4.2968\r## 58 58 1 6 1 1 3.5008\r## 60 60 1 6 1 1 3.2487\r## 61 61 1 6 1 1 3.2304\r## 62 62 1 5 3 1 3.2263\r下面讲下这段代码的逻辑：\n第一行生成一个与变量Sex具有相同长度的逻辑向量Se1，如果Sex值为1，则该变量的值是TRUE，反之则为FALSE。这样的变量也被称为布尔向量，可以用来选择行。\r接下来选择Squid中Se1等于TRUE的行，并存储在SquidM中。\r至此，雄性数据选择完毕。\r当然，这个代码也可以简化为：\r\rSquidM \u0026lt;- Squid[Squid$Sex == 1,]\rhead(SquidM)\r## Sample Year Month Location Sex GSI\r## 24 24 1 5 1 1 5.2970\r## 48 48 1 5 3 1 4.2968\r## 58 58 1 6 1 1 3.5008\r## 60 60 1 6 1 1 3.2487\r## 61 61 1 6 1 1 3.2304\r## 62 62 1 5 3 1 3.2263\r#雌性的数据\rSquidF \u0026lt;- Squid[Squid$Sex == 2,]\rhead(SquidF)\r## Sample Year Month Location Sex GSI\r## 1 1 1 1 1 2 10.4432\r## 2 2 1 1 3 2 9.8331\r## 3 3 1 1 1 2 9.7356\r## 4 4 1 1 1 2 9.3107\r## 5 5 1 1 1 2 8.9926\r## 6 6 1 1 1 2 8.7707\r下面讲一下布尔运算符的用法：或“|”,与“\u0026amp;”，非“!”。\r先看一下Location变量有什么编码值：\nunique(Squid$Location)\r## [1] 1 3 4 2\r然后，我只想要Location为1，2，3的数据，注意这个是并集。\nSquid123 \u0026lt;- Squid[Squid$Location == 1 | Squid$Location == 2 |\rSquid$Location == 3,]\rSquid123 \u0026lt;- Squid[Squid$Location != 4, ]\rSquid123 \u0026lt;- Squid[Squid$Location \u0026lt; 4, ]\rSquid123 \u0026lt;- Squid[Squid$Location \u0026lt;= 3, ]\rSquid123 \u0026lt;- Squid[Squid$Location \u0026gt;= 1 \u0026amp;\rSquid$Location \u0026lt;= 3,]\r以上语句都是一个意思。\r额，写完才发现，我选用的是Cascadia code字体，这样的话……绝对等于也就是两个等于号是==，不等于应该是！=，而这里显示的是!=，同样的，小于等于和大于等于的形式都发生变化了。\r然后，接下来，我想进一步从雄性数据集中提取出Location为1的数据集：\nSquidM.1 \u0026lt;- Squid[Squid$Sex == 1 \u0026amp;\rSquid$Location == 1,]\r3.2.1 数据排序\r有的时候想对数据集根据某一个变量进行排序，从大到小啊或者从小到大，在excel中很好操作，在R中要这样：\n#按月份排序\rhead(Squid[order(Squid$Month),], n=30L)\r## Sample Year Month Location Sex GSI\r## 1 1 1 1 1 2 10.4432\r## 2 2 1 1 3 2 9.8331\r## 3 3 1 1 1 2 9.7356\r## 4 4 1 1 1 2 9.3107\r## 5 5 1 1 1 2 8.9926\r## 6 6 1 1 1 2 8.7707\r## 7 7 1 1 1 2 8.2576\r## 8 8 1 1 3 2 7.4045\r## 9 9 1 1 3 2 7.2156\r## 11 11 1 1 1 2 6.3882\r## 14 14 1 1 1 2 6.0726\r## 18 18 1 1 1 2 5.7757\r## 198 198 1 1 1 1 1.2610\r## 204 204 1 1 1 1 1.1997\r## 244 244 1 1 1 1 0.8373\r## 255 255 1 1 1 2 0.6716\r## 264 264 1 1 1 2 0.5758\r## 271 271 1 1 3 1 0.5518\r## 279 279 1 1 1 1 0.4921\r## 281 281 1 1 1 1 0.4808\r## 292 292 1 1 3 2 0.3828\r## 302 302 1 1 1 1 0.3289\r## 317 317 1 1 1 1 0.2758\r## 329 329 1 1 1 1 0.2506\r## 352 352 1 1 1 2 0.2092\r## 373 373 1 1 1 2 0.1792\r## 381 381 1 1 3 1 0.1661\r## 387 387 1 1 1 2 0.1618\r## 393 393 1 1 1 1 0.1543\r## 394 394 1 1 1 1 0.1541\r因为处理的是Squid中行，所以放在了逗号的前面。也可以对一个变量进行排序：\nhead(Squid$GSI[order(Squid$Month)], n=30L)\r## [1] 10.4432 9.8331 9.7356 9.3107 8.9926 8.7707 8.2576 7.4045 7.2156\r## [10] 6.3882 6.0726 5.7757 1.2610 1.1997 0.8373 0.6716 0.5758 0.5518\r## [19] 0.4921 0.4808 0.3828 0.3289 0.2758 0.2506 0.2092 0.1792 0.1661\r## [28] 0.1618 0.1543 0.1541\r\r\r3.3 使用相同的标识符组合两个数据集\r书里这段说的很啰嗦，其实就是在实际使用中，我们可能会导入很多个excel文件，而这些文件里面的样本是一样的。简单来说，举个例子，我用了10只小鼠，样本命名为1，2，3，……，10，第一个excel文件里记载了每只老鼠血清的甘三酯（TG）含量，第二个excel文件里，记载了每只老鼠肝脏的TG含量，这两个文件分别导入到R中，生成两个数据集，而这两个数据集，样本名是一致的。\r以书中的例子而言，是这样的，Squid1.txt文件里记载了样本和对应的GSI，Squid2.txt文件里记载了样本和其他的对应变量，比如年份、月份、位置、性别。\r下面来读入这两个数据：\nSq1 \u0026lt;- read.table(file = \u0026quot;F:\\\\database\\\\RBook\\\\Squid1.txt\u0026quot;, header = TRUE)\rSq2 \u0026lt;- read.table(file = \u0026quot;F:\\\\database\\\\RBook\\\\Squid2.txt\u0026quot;, header = TRUE)\r然后根据这两个数据集具有一致的样本进行合并，采用merge函数：\nSquidMerged \u0026lt;- merge(Sq1, Sq2, by = \u0026quot;Sample\u0026quot;)\rhead(SquidMerged, n=30L)\r## Sample GSI YEAR MONTH Location Sex\r## 1 1 10.4432 1 1 1 2\r## 2 2 9.8331 1 1 3 2\r## 3 3 9.7356 1 1 1 2\r## 4 5 8.9926 1 1 1 2\r## 5 6 8.7707 1 1 1 2\r## 6 7 8.2576 1 1 1 2\r## 7 8 7.4045 1 1 3 2\r## 8 9 7.2156 1 1 3 2\r## 9 10 6.8372 1 2 1 2\r## 10 11 6.3882 1 1 1 2\r## 11 12 6.3672 1 6 1 2\r## 12 13 6.2998 1 2 1 2\r## 13 14 6.0726 1 1 1 2\r## 14 15 5.8395 1 6 1 2\r## 15 16 5.8070 1 6 1 2\r## 16 17 5.7774 1 6 3 2\r## 17 18 5.7757 1 1 1 2\r## 18 19 5.6484 1 5 3 2\r## 19 20 5.6141 1 5 1 2\r## 20 21 5.6017 1 5 3 2\r## 21 22 5.5510 1 6 1 2\r## 22 23 5.3110 1 5 1 2\r## 23 24 5.2970 1 5 1 1\r## 24 25 5.2253 1 6 1 2\r## 25 26 5.1667 1 6 1 2\r## 26 27 5.1405 1 6 1 2\r## 27 28 5.1292 1 6 1 2\r## 28 29 5.0782 1 6 1 2\r## 29 30 5.0612 1 6 1 2\r## 30 31 5.0097 1 5 1 2\r这个by = “Sample”就是说，Sq1和Sq2以Sample作为相同的标识符来合并。\r另外merge这个函数还有一个参数是all = TRUE/FALSE，默认情况下，这个值是FALSE，什么意思呢，就是说Sq1和Sq2的行如果有缺失值的话，就会被忽略掉，这个样本就不存在于SquidMerged数据集中，反之，则用NA填充。下面举个all = TRUE的例子：\nSquidMerged2 \u0026lt;- merge(Sq1, Sq2, by = \u0026quot;Sample\u0026quot;,\rall = TRUE)\rhead(SquidMerged2, n=30L)\r## Sample GSI YEAR MONTH Location Sex\r## 1 1 10.4432 1 1 1 2\r## 2 2 9.8331 1 1 3 2\r## 3 3 9.7356 1 1 1 2\r## 4 4 9.3107 NA NA NA NA\r## 5 5 8.9926 1 1 1 2\r## 6 6 8.7707 1 1 1 2\r## 7 7 8.2576 1 1 1 2\r## 8 8 7.4045 1 1 3 2\r## 9 9 7.2156 1 1 3 2\r## 10 10 6.8372 1 2 1 2\r## 11 11 6.3882 1 1 1 2\r## 12 12 6.3672 1 6 1 2\r## 13 13 6.2998 1 2 1 2\r## 14 14 6.0726 1 1 1 2\r## 15 15 5.8395 1 6 1 2\r## 16 16 5.8070 1 6 1 2\r## 17 17 5.7774 1 6 3 2\r## 18 18 5.7757 1 1 1 2\r## 19 19 5.6484 1 5 3 2\r## 20 20 5.6141 1 5 1 2\r## 21 21 5.6017 1 5 3 2\r## 22 22 5.5510 1 6 1 2\r## 23 23 5.3110 1 5 1 2\r## 24 24 5.2970 1 5 1 1\r## 25 25 5.2253 1 6 1 2\r## 26 26 5.1667 1 6 1 2\r## 27 27 5.1405 1 6 1 2\r## 28 28 5.1292 1 6 1 2\r## 29 29 5.0782 1 6 1 2\r## 30 30 5.0612 1 6 1 2\r对比这两个组合数据集，就可以发现样本4的差别。\n\r3.4 输出数据\r上文提到我为了研究需要，将雄性鱿鱼的数据给提取出来了，并存储于SquidM的数据集中，下面，我想把这个数据集给导出来，方便我发给小伙伴们。这个时候就会用到write.table函数：\nSquidM \u0026lt;- Squid[Squid$Sex == 1,]\rwrite.table(SquidM, file = \u0026quot;F:\\\\database\\\\RBook\\\\MaleSquid.txt\u0026quot;,\rsep = \u0026quot; \u0026quot;, quote = FALSE,\rappend = FALSE, na = \u0026quot;NA\u0026quot;)\r这样在我的文件夹中就会出现MaleSquid.txt文件。接下来，逐个讲解这个函数中各参数的含义：\n首先要指明要导出的数据集，本例中是SquidM；\r然后需要告诉R，我要以什么名称，在什么位置来导出这个数据集，本例中是file = “F:\\database\\RBook\\MaleSquid.txt”；\rsep = \" \"是告诉R我要将数据用空格隔开，注意引号里面是空格；\rquote = FALSE是要取消字符串的引号标志，也就是标题的引号；\rappend = FALSE嘛……说实话，书中说\"为FALSE的话，就会打开一个新的文件，如果为TRUE，它会将变量SquidM添加到一个已经存在的文件的尾部“，我压根就没看懂，等哪天找到英文原版看一下是不是翻译的问题；\rna = “NA”的意思就简单了，SquidM的缺失值我就用NA来代替。\r看一下输出来的文件长什么样：\r可以发现，按照变量名将下面的数据逐个对应后，第一列没有名字，这个就是R的问题，如果要导入到excel中，需要将第一行的所有变量名向右移一格。说到这里，我又想吐槽了，书中是这么说的：“需要把第一行转移到右侧一列”，你瞅瞅，能理解不。\r\r\r3.5 重新编码分类变量\r首先说下什么是分类变量，结合例子，在前文，我们用str(Squid)命令查看了各变量的类型：\nstr(Squid)\r## \u0026#39;data.frame\u0026#39;: 2644 obs. of 6 variables:\r## $ Sample : int 1 2 3 4 5 6 7 8 9 10 ...\r## $ Year : int 1 1 1 1 1 1 1 1 1 1 ...\r## $ Month : int 1 1 1 1 1 1 1 1 1 2 ...\r## $ Location: int 1 3 1 1 1 1 1 3 3 1 ...\r## $ Sex : int 2 2 2 2 2 2 2 2 2 2 ...\r## $ GSI : num 10.44 9.83 9.74 9.31 8.99 ...\r变量Location编码为1，2，3，4，变量Sex编码为1，2。这样的变量就是分类变量，或者叫做名义变量。\r虽然说这种编码方式可以将一些字符串什么的转换为数字，但是，除了数据集所有者自己，谁也不知道Location的1，2，3，4分别是什么，随着时间的变迁，所有者自己都会忘掉。\r所以就有了将这类分类变量重编码的需要。\nSquid$fLocation \u0026lt;- factor(Squid$Location)\rSquid$fSex \u0026lt;- factor(Squid$Sex)\r这两句的意思是，分别在Squid数据框中生成新变量fLocation和fSex，这里用到了R中的因子概念。\r那我们看一下这两个新变量长什么样子，比如说fSex：\nhead(Squid$fSex, n=100L)\r## [1] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2\r## [38] 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1\r## [75] 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1\r## Levels: 1 2\r注意最后一行：Levels: 1 2，这告诉我们，fSex有两个水平，下面将这两个水平重新编码为“雄性”和“雌性”：\nSquid$fSex \u0026lt;- factor(Squid$Sex, levels = c(1,2),\rlabels = c(\u0026quot;M\u0026quot;, \u0026quot;F\u0026quot;))\rhead(Squid$fSex, n=100L)\r## [1] F F F F F F F F F F F F F F F F F F F F F F F M F F F F F F F F F F F F F\r## [38] F F F F F F F F F F M F F F F F F F F F M F M M M M F M M M M M M M M M M\r## [75] M F M M M M M M M M M M M M M M M M F M M M M M M M\r## Levels: M F\r这里levels = c(1,2)和labels = c(“M”, “F”)就一一对应起来，1对应M也就是雄性，2对应F也就是雌性。\r现在试试用新变量fSex来做个图或者来个线性回归：\nboxplot(GSI ~ fSex, data = Squid)\rM1 \u0026lt;- lm(GSI ~ fSex, data = Squid)\rM1\r## ## Call:\r## lm(formula = GSI ~ fSex, data = Squid)\r## ## Coefficients:\r## (Intercept) fSexF ## 1.226 2.047\r下面，我们看一下FLocation：\nhead(Squid$fLocation, n=100L)\r## [1] 1 3 1 1 1 1 1 3 3 1 1 1 1 1 1 1 3 1 3 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\r## [38] 1 1 3 1 1 1 1 3 1 1 3 1 1 1 1 1 1 1 3 1 1 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1\r## [75] 1 3 1 1 3 1 1 3 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 3 1 3\r## Levels: 1 2 3 4\rboxplot(GSI ~ fLocation, data = Squid)\r注意到，这个名义变量有四个水平，这种情况下，水平值由小到大进行排序，这意味着，在盒形图里，位置为1的数据与位置为2的数据相邻，位置为2的与位置为3的相邻等等。\r但是如果我把这个默认的由小到大的排序改了呢：\nSquid$fLocation \u0026lt;- factor(Squid$Location, levels = c(2,3,1,4))\rhead(Squid$fLocation, n=100L)\r## [1] 1 3 1 1 1 1 1 3 3 1 1 1 1 1 1 1 3 1 3 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\r## [38] 1 1 3 1 1 1 1 3 1 1 3 1 1 1 1 1 1 1 3 1 1 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1\r## [75] 1 3 1 1 3 1 1 3 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 3 1 3\r## Levels: 2 3 1 4\r此时，最后一行显示的是：Levels: 2 3 1 4，我用这个重编码过的fLocation画个图，大家看下差别：\nboxplot(GSI ~ fLocation, data = Squid)\r另外，在本章开始的时候选择雄性数据，我是这么做的：\nSquidM \u0026lt;- Squid[Squid$Sex == 1,]\r那我想用fSex选择雄性呢，是一样的吗，答案是否定的：\nSquidM \u0026lt;- Squid[Squid$fSex == \u0026quot;1\u0026quot;,]\r对于fSex而言，编码数字1必须用双引号括起来，因为fSex是个因子（factor）。\n\r3.6 本章学了哪些R函数\r自己整合去。\n\r3.7 习题\r使用流行病学数据练习使用read.table函数并访问其中的变量：\r文件为BirdFlu.xls，这是一个WHO报道的每年人类感染禽流感A（H5N1)的病例。\r使用深海研究数据练习使用read.table函数并访问其中的变量：\r这个来源于第二张的习题6，做完之后，从ISIT.xls文件载入数据。\r使用深海研究数据练习使用write.table函数：\r提取4月份并且深度超过2000米的测量数据，并输出。\r使用深海研究数据练习使用factor函数并访问数据框中的子集：\r站点1-5是2001年4月抽样，站点6-11是2001年8月抽样，站点12-15是2002年3月抽样，站点16-19是2002年10月抽样，在R里生成两个新变量确定月份和年份。\r\r\r\r","date":1583884800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1583884800,"objectID":"4628563f05e5f3f8ccb06d877b4ef437","permalink":"/post/r%E8%AF%AD%E8%A8%80%E5%88%9D%E5%AD%A6%E8%80%85%E6%8C%87%E5%8D%97-%E7%AC%AC%E4%B8%89%E7%AB%A0/","publishdate":"2020-03-11T00:00:00Z","relpermalink":"/post/r%E8%AF%AD%E8%A8%80%E5%88%9D%E5%AD%A6%E8%80%85%E6%8C%87%E5%8D%97-%E7%AC%AC%E4%B8%89%E7%AB%A0/","section":"post","summary":"时隔半年，我终于又开始写这个博客了。 话不多说，言归正传。 第三","tags":["R","统计"],"title":"R语言初学者指南-第三章","type":"post"},{"authors":null,"categories":["R"],"content":"\r写在前面\r嗯~怎么说呢，之前的那本书，我又鸽了，原因有这几个：\n书太厚了\r讲的东西太全面，而且感觉实用性不大，我在实际使用中很多问题这本书解决不了\r说句不该说的，那本书有很大部分与《R语言实战》重合\r\r所以，我又重开了一本书，这本书解决了我最近的一个大问题。这本书我想以记笔记的形式记录下来，以配套的课后习题为主。\n废话少说，进入正题\n\r第二章：R中数据输入\r2.1 R中的第一步\r2.1.1 少量的数据录入\r这一部分主要针对在R中输入少量数据的问题，数据见下表，有四个形态参数，每个形态参数有8个观测值：\n\r\r翼弦\r踝骨\r头\r体重\r\r\r\r59\r22.3\r31.2\r9.5\r\r55\r19.7\r30.4\r13.8\r\r53.5\r20.8\r30.6\r14.8\r\r55\r20.3\r30.3\r15.2\r\r52.5\r20.8\r30.3\r15.5\r\r57.5\r21.58\r30.8\r15.6\r\r53\r20.6\r32.5\r15.6\r\r55\r21.5\rNA\r15.7\r\r\r\r具体变量的解释就不多说了，知道是变量就可以了。\r对于这种数据量较少的表格，可以一个个输入，不过这种方法很累。比如录入翼弦的前5个数据：\na \u0026lt;- 59\rb \u0026lt;- 55\rc \u0026lt;- 53.5\rd \u0026lt;- 55\re \u0026lt;- 52.5\r此时要想看R中的结果，可以输入“a”，之后敲回车（话说这本书写的是真细）。这里就不演示了，之后对于简单的命令，笔记中都不会进行演示。\n这种方法不仅累，而且以字母最为变量名容易乱，可以改名，但是没什么卵用，比如这样：\nWing1 \u0026lt;- 59\rWing2 \u0026lt;- 55\rWing3 \u0026lt;- 53.5\rWing4 \u0026lt;- 55\rWing5 \u0026lt;- 52.5 \r这本书接下来先以这些变量讲解了一下运算，比如：\nsqrt(Wing1)\r## [1] 7.681146\r2*Wing1\r## [1] 118\rWing1+Wing2\r## [1] 114\r此时，R只是运算了一下，并没将这些结果储存，最好以新变量来储存这些结果：\nSQ.wing1 \u0026lt;- sqrt(Wing1)\r#加了个圆括号就可以直接出结果\r(SQ.wing1 \u0026lt;- sqrt(Wing1))\r## [1] 7.681146\r\r2.1.2 用c函数连接数据\r对于这个表格，4个参数8个变量，共需要32个变量名，而这是不实际的。可以用c()函数简化一下：\n#用c()函数生成了一个长度是8的向量\rWingcrd \u0026lt;- c(59, 55, 53.5, 55, 52.5, 57.5, 53, 55)\r这个时候只要输入Wingcrd就可以查看结果：\nWingcrd\r## [1] 59.0 55.0 53.5 55.0 52.5 57.5 53.0 55.0\r要是想看这个向量的第一个值，可以这样，注意是方括号：\nWingcrd[1]\r## [1] 59\r如果想看前5个值\nWingcrd[1:5]\r## [1] 59.0 55.0 53.5 55.0 52.5\r如果想看除了第二个值之外的\nWingcrd[-2]\r## [1] 59.0 53.5 55.0 52.5 57.5 53.0 55.0\r负号这个用法以后会经常用到。\r至于R中内置的函数，比如sum等，可以这么用，\nS.win \u0026lt;- sum(Wingcrd)\rS.win\r## [1] 440.5\r接下来，把剩余三个参数也输入进R中，一般来说，R中的变量名最好以大写字母开头，而且要方便记忆。\nTarsus \u0026lt;- c(22.3, 19.7, 20.8, 20.3, 20.8, 21.5, 20.6, 21.5)\rHead \u0026lt;- c(31.2, 30.4, 30.6, 30.3, 30.3, 30.8, 32.5, NA)\rWt \u0026lt;- c(9.5, 13.8, 14.8, 15.2, 15.5, 15.6, 15.6, 15.7)\r这个时候发现Head向量中有一个缺失值NA（这不废话吗，上面表格中就看见了），此时算Head的和就会出现问题：\nsum(Head)\r## [1] NA\r调用其他函数比如mean什么的也会这样，这个时候可以用“?sum”命令来看看怎么剔除这个缺失值，发现可以这样做：\nsum(Head, na.rm = TRUE)\r## [1] 216.1\r加个na.rm = TRUE就可以了。当然也可以用na.rm = T代替，不过有时候会出错，所以最好还是用“TRUE”。\n\r2.1.3 使用c，cbind和rbind函数结合变量\r首先用c()函数连接Wingcrd，Tarsus，Head和Wt变量。\nBirdData \u0026lt;- c(Wingcrd, Tarsus, Head, Wt)\r这个时候输入这个新变量名可以看到这是一个长度为32的向量：\nBirdData\r## [1] 59.0 55.0 53.5 55.0 52.5 57.5 53.0 55.0 22.3 19.7 20.8 20.3 20.8 21.5\r## [15] 20.6 21.5 31.2 30.4 30.6 30.3 30.3 30.8 32.5 NA 9.5 13.8 14.8 15.2\r## [29] 15.5 15.6 15.6 15.7\r但是这个变量并没有区分哪些值输入哪一个变量，为实现这一目的，可以生成另一个长度为32的向量，命名为ID：\nId \u0026lt;- c(1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4)\rId\r## [1] 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4\r这样也很费时间，可以这样：\nId \u0026lt;- rep(c(1, 2, 3, 4), each = 8)\rId\r## [1] 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4\r还可以这样：\nId \u0026lt;- rep(1:4, each = 8)\rId\r## [1] 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4\r还可以这样：\na \u0026lt;- seq(from = 1, to = 4, by = 1)\ra\r## [1] 1 2 3 4\rrep(a, each = 8)\r## [1] 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4\r至此，这里只是实现了数字的连接，假如想生成一个长度为32的向量“Id“，这个向量包含单词”Wingcrd“8次，”Tarsus“8次等，可以先生成一个名为VarNames的新变量：\nVarNames \u0026lt;- c(\u0026quot;Wingcrd\u0026quot;, \u0026quot;Tarsus\u0026quot;, \u0026quot;Head\u0026quot;, \u0026quot;Wt\u0026quot;)\rVarNames\r## [1] \u0026quot;Wingcrd\u0026quot; \u0026quot;Tarsus\u0026quot; \u0026quot;Head\u0026quot; \u0026quot;Wt\u0026quot;\r但是这只是名称，而不是含有数值的变量。接下来再用rep函数来生成需要的向量：\nId2 \u0026lt;- rep(VarNames, each = 8)\rId2\r## [1] \u0026quot;Wingcrd\u0026quot; \u0026quot;Wingcrd\u0026quot; \u0026quot;Wingcrd\u0026quot; \u0026quot;Wingcrd\u0026quot; \u0026quot;Wingcrd\u0026quot; \u0026quot;Wingcrd\u0026quot; \u0026quot;Wingcrd\u0026quot;\r## [8] \u0026quot;Wingcrd\u0026quot; \u0026quot;Tarsus\u0026quot; \u0026quot;Tarsus\u0026quot; \u0026quot;Tarsus\u0026quot; \u0026quot;Tarsus\u0026quot; \u0026quot;Tarsus\u0026quot; \u0026quot;Tarsus\u0026quot; ## [15] \u0026quot;Tarsus\u0026quot; \u0026quot;Tarsus\u0026quot; \u0026quot;Head\u0026quot; \u0026quot;Head\u0026quot; \u0026quot;Head\u0026quot; \u0026quot;Head\u0026quot; \u0026quot;Head\u0026quot; ## [22] \u0026quot;Head\u0026quot; \u0026quot;Head\u0026quot; \u0026quot;Head\u0026quot; \u0026quot;Wt\u0026quot; \u0026quot;Wt\u0026quot; \u0026quot;Wt\u0026quot; \u0026quot;Wt\u0026quot; ## [29] \u0026quot;Wt\u0026quot; \u0026quot;Wt\u0026quot; \u0026quot;Wt\u0026quot; \u0026quot;Wt\u0026quot;\r注意不能丢掉each，否则会得到：\nId3 \u0026lt;- rep(VarNames,8)\rId3\r## [1] \u0026quot;Wingcrd\u0026quot; \u0026quot;Tarsus\u0026quot; \u0026quot;Head\u0026quot; \u0026quot;Wt\u0026quot; \u0026quot;Wingcrd\u0026quot; \u0026quot;Tarsus\u0026quot; \u0026quot;Head\u0026quot; ## [8] \u0026quot;Wt\u0026quot; \u0026quot;Wingcrd\u0026quot; \u0026quot;Tarsus\u0026quot; \u0026quot;Head\u0026quot; \u0026quot;Wt\u0026quot; \u0026quot;Wingcrd\u0026quot; \u0026quot;Tarsus\u0026quot; ## [15] \u0026quot;Head\u0026quot; \u0026quot;Wt\u0026quot; \u0026quot;Wingcrd\u0026quot; \u0026quot;Tarsus\u0026quot; \u0026quot;Head\u0026quot; \u0026quot;Wt\u0026quot; \u0026quot;Wingcrd\u0026quot;\r## [22] \u0026quot;Tarsus\u0026quot; \u0026quot;Head\u0026quot; \u0026quot;Wt\u0026quot; \u0026quot;Wingcrd\u0026quot; \u0026quot;Tarsus\u0026quot; \u0026quot;Head\u0026quot; \u0026quot;Wt\u0026quot; ## [29] \u0026quot;Wingcrd\u0026quot; \u0026quot;Tarsus\u0026quot; \u0026quot;Head\u0026quot; \u0026quot;Wt\u0026quot;\r结果差异很明显了。\r前面用c()来结合数据，实际上没个乱用，我也不知道这本书为啥会写它，实际应用中主要用cbind函数来进行数据连接。\nZ \u0026lt;- cbind(Wingcrd, Tarsus, Head, Wt)\rZ\r## Wingcrd Tarsus Head Wt\r## [1,] 59.0 22.3 31.2 9.5\r## [2,] 55.0 19.7 30.4 13.8\r## [3,] 53.5 20.8 30.6 14.8\r## [4,] 55.0 20.3 30.3 15.2\r## [5,] 52.5 20.8 30.3 15.5\r## [6,] 57.5 21.5 30.8 15.6\r## [7,] 53.0 20.6 32.5 15.6\r## [8,] 55.0 21.5 NA 15.7\r假设需要访问Z的第一列，\nZ[,1]\r## [1] 59.0 55.0 53.5 55.0 52.5 57.5 53.0 55.0\r要访问第二行，\nZ[2,]\r## Wingcrd Tarsus Head Wt ## 55.0 19.7 30.4 13.8\r方括号中，逗号前面代表行，后面代表列。\r当然也可以将这些查询结果储存为新变量，\nX \u0026lt;- Z[2,]\rY \u0026lt;- Z[,-3]\rW \u0026lt;- Z[,c(-1,-3)]\r如果想知道Z的维度，\ndim(Z)\r## [1] 8 4\r也可以将这个结果存储起来，\nn \u0026lt;- dim(Z)\rn\r## [1] 8 4\r或者，仅需要储存Z的行数，\nnrow \u0026lt;- dim(Z)[1]\rnrow\r## [1] 8\r当然，cbind也可以用rbind来代替，不过就是行表示形态变量而列表示鸟个体，\nZ2 \u0026lt;- rbind(Wingcrd, Tarsus, Head, Wt)\rZ2\r## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]\r## Wingcrd 59.0 55.0 53.5 55.0 52.5 57.5 53.0 55.0\r## Tarsus 22.3 19.7 20.8 20.3 20.8 21.5 20.6 21.5\r## Head 31.2 30.4 30.6 30.3 30.3 30.8 32.5 NA\r## Wt 9.5 13.8 14.8 15.2 15.5 15.6 15.6 15.7\r\r2.1.4 使用vector函数结合数据\rvector()函数与c()函数类似，可以用来代替c函数。\r假如想生成一个长度为8，包含了所有8只鸟的Wingcrd数据的一个向量，可以这么做：\nW \u0026lt;- vector(length = 8)\rW[1] \u0026lt;- 59\rW[2] \u0026lt;- 55\rW[3] \u0026lt;- 53.5\rW[4] \u0026lt;- 55\rW[5] \u0026lt;- 52.5\rW[6] \u0026lt;- 57.5\rW[7] \u0026lt;- 53\rW[8] \u0026lt;- 55\rW\r## [1] 59.0 55.0 53.5 55.0 52.5 57.5 53.0 55.0\r可以看到这是先生成一个长度为8的向量，然后再向其中每个元素赋值的方法。所以在输入第一条命令后直接键入W，会得到一个FALSE的向量，因为R并不知道这个W是啥。\n先定义向量长度，这就是vector函数的优点，比如在做循环运算的时候，当然，平常还是用c()比较方便。\n和c()函数一样，可以用W[i]，W[i:j]，W[-i]，W[i,j,k]等访问其中元素，i，j，k是具体的数字哈。\n\r2.1.5 使用矩阵结合数据\r书上说初学者可以跳过这一节，我是吗？\n可能吧~\n不过在具体数据分析时，经常会用到矩阵或者数据框的形式，所以，我才不是初学者呢。\r回归正题，为了不用向量来显示4个变量Wingcrd，Tarsus，Head和Wt（每个向量长度为8，这在创建矩阵时非常重要，每个向量长度要一致），可以生成一个8×4的矩阵：\nDmat \u0026lt;- matrix(nrow = 8, ncol = 4)\rDmat\r## [,1] [,2] [,3] [,4]\r## [1,] NA NA NA NA\r## [2,] NA NA NA NA\r## [3,] NA NA NA NA\r## [4,] NA NA NA NA\r## [5,] NA NA NA NA\r## [6,] NA NA NA NA\r## [7,] NA NA NA NA\r## [8,] NA NA NA NA\r当然此时并没有给矩阵Dmat中的元素赋值，所以元素都是Na。\n为了给每个元素赋值，可以这么做：\nDmat[, 1] \u0026lt;- c(59, 55, 53.5, 55, 52.5, 57.5, 53, 55)\rDmat[, 2] \u0026lt;- c(22.3, 19.7, 20.8, 20.3, 20.8, 21.5,\r20.6, 21.5)\rDmat[, 3] \u0026lt;- c(31.2, 30.4, 30.6, 30.3, 30.3, 30.8,\r32.5, NA)\rDmat[, 4] \u0026lt;- c(9.5, 13.8, 14.8, 15.2, 15.5, 15.6,\r15.6, 15.7)\rDmat\r## [,1] [,2] [,3] [,4]\r## [1,] 59.0 22.3 31.2 9.5\r## [2,] 55.0 19.7 30.4 13.8\r## [3,] 53.5 20.8 30.6 14.8\r## [4,] 55.0 20.3 30.3 15.2\r## [5,] 52.5 20.8 30.3 15.5\r## [6,] 57.5 21.5 30.8 15.6\r## [7,] 53.0 20.6 32.5 15.6\r## [8,] 55.0 21.5 NA 15.7\r这是在按Dmat矩阵的每列分别赋值。当然也可以按行来赋值（方括号中的行列[行，列]）。\n此时可以发现，这个矩阵没有列标签，默认的是[,1]，[,2]，[,3]，[,4]。可以用colnames()函数来给这个矩阵加上列标签，也就是列名：\ncolnames(Dmat) \u0026lt;- c(\u0026quot;Wingcrd\u0026quot;, \u0026quot;Tarsus\u0026quot;, \u0026quot;Head\u0026quot;, \u0026quot;Wt\u0026quot;)\rDmat\r## Wingcrd Tarsus Head Wt\r## [1,] 59.0 22.3 31.2 9.5\r## [2,] 55.0 19.7 30.4 13.8\r## [3,] 53.5 20.8 30.6 14.8\r## [4,] 55.0 20.3 30.3 15.2\r## [5,] 52.5 20.8 30.3 15.5\r## [6,] 57.5 21.5 30.8 15.6\r## [7,] 53.0 20.6 32.5 15.6\r## [8,] 55.0 21.5 NA 15.7\r以此类推，给每个行命名也是可以的，用rownames()函数就可以了。\n但是，可以发现，这么给矩阵元素赋值还是比较麻烦，毕竟我们已经有了具体的Wingcrd，Tarsus，Head和Wt这四个向量，那么，可以这么做：\nDmat2 \u0026lt;- as.matrix(cbind(Wingcrd,Tarsus,Head, Wt))\rDmat2\r## Wingcrd Tarsus Head Wt\r## [1,] 59.0 22.3 31.2 9.5\r## [2,] 55.0 19.7 30.4 13.8\r## [3,] 53.5 20.8 30.6 14.8\r## [4,] 55.0 20.3 30.3 15.2\r## [5,] 52.5 20.8 30.3 15.5\r## [6,] 57.5 21.5 30.8 15.6\r## [7,] 53.0 20.6 32.5 15.6\r## [8,] 55.0 21.5 NA 15.7\r这里就用到了as.matrix()和cbind()函数。\n\r2.1.6 使用data.frame函数结合数据\r前面提到了数据框，这一小节就是利用数据框来结合数据。同样，要求也是向量长度必须相同。\nDfrm \u0026lt;- data.frame(WC = Wingcrd, TS = Tarsus,\rHD = Head, W = Wt)\rDfrm\r## WC TS HD W\r## 1 59.0 22.3 31.2 9.5\r## 2 55.0 19.7 30.4 13.8\r## 3 53.5 20.8 30.6 14.8\r## 4 55.0 20.3 30.3 15.2\r## 5 52.5 20.8 30.3 15.5\r## 6 57.5 21.5 30.8 15.6\r## 7 53.0 20.6 32.5 15.6\r## 8 55.0 21.5 NA 15.7\rdata.frame()这个函数创建了一个名为Dfrm的数据框。数据框的优点在于可以在不影响原始数据的基础上改变数据，比如可以在这个数据框中结合体重值和体重值的平方根：\nDfrm1 \u0026lt;- data.frame(WC = Wingcrd, TS = Tarsus,\rHD = Head, W = Wt, Wsq=sqrt(Wt))\rDfrm1\r## WC TS HD W Wsq\r## 1 59.0 22.3 31.2 9.5 3.082207\r## 2 55.0 19.7 30.4 13.8 3.714835\r## 3 53.5 20.8 30.6 14.8 3.847077\r## 4 55.0 20.3 30.3 15.2 3.898718\r## 5 52.5 20.8 30.3 15.5 3.937004\r## 6 57.5 21.5 30.8 15.6 3.949684\r## 7 53.0 20.6 32.5 15.6 3.949684\r## 8 55.0 21.5 NA 15.7 3.962323\r这就相当于增加了一列。\n\r2.1.7 使用list函数结合数据\r嗯，书上又说了初学者可以跳过这一节。\n就不跳。\n书上是这么说list的。假设现在需要一个黑盒子，里面可以放入尽可能多的各种各样的变量，一些可能是相关的，一些可能具有相似的维数，一些可能是向量，一些可能是矩阵，一些可能是字符串，这就是list能完成的事。\n其实，就一句话，list里面包含所有的数据类型。下面举个例子：\nx1 \u0026lt;- c(1,2,3)#数值向量\rx2 \u0026lt;- c(\u0026quot;a\u0026quot;,\u0026quot;b\u0026quot;,\u0026quot;c\u0026quot;,\u0026quot;d\u0026quot;)#字符向量\rx3 \u0026lt;- 3#数值\rx4 \u0026lt;- matrix(nrow = 2,ncol = 2)#矩阵\rx4[,1] \u0026lt;- c(1,2)\rx4[,2] \u0026lt;- c(3,4)\rY \u0026lt;- list(x1=x1,x2=x2,x3=x3,x4=x4)\r此时键入Y，可以得到：\nY\r## $x1\r## [1] 1 2 3\r## ## $x2\r## [1] \u0026quot;a\u0026quot; \u0026quot;b\u0026quot; \u0026quot;c\u0026quot; \u0026quot;d\u0026quot;\r## ## $x3\r## [1] 3\r## ## $x4\r## [,1] [,2]\r## [1,] 1 3\r## [2,] 2 4\r也可以通过Y$x1什么的单独访问某个信息。\n为什么要介绍list呢，因为在之后的学习中，有一些函数的结果，比如线性回归什么的，这些结果都是存储在list中的。比如应用线性回归模型实现将翅膀长度表示为体重的函数：\nM \u0026lt;- lm(WC ~ Wt, data = Dfrm)\r如果键入：\nnames(M)\r## [1] \u0026quot;coefficients\u0026quot; \u0026quot;residuals\u0026quot; \u0026quot;effects\u0026quot; \u0026quot;rank\u0026quot; ## [5] \u0026quot;fitted.values\u0026quot; \u0026quot;assign\u0026quot; \u0026quot;qr\u0026quot; \u0026quot;df.residual\u0026quot; ## [9] \u0026quot;xlevels\u0026quot; \u0026quot;call\u0026quot; \u0026quot;terms\u0026quot; \u0026quot;model\u0026quot;\r会得到一堆奇特的输出结果。这时就可以用M$cofficients什么的分别访问。这个M就是个列表。\n回到原来的例子。对于前面表2.1中鸟的形态参数，由于其中每一行都代表同一只鸟的数据，所以将其存入一个列表中没啥用。然而，当任务就是生成一个列表，这个列表需要将所有数据放在一个长向量中，还需要另一个向量来识别这些变量（例如ID的作用），同时需要一个8×4的矩阵来表示这些数据，并且还需要一个包含了4中形态参数名称的向量时，可以这么处理：\nAllData \u0026lt;- list(BirdData = BirdData, Id = Id, Z = Z,\rVarNames = VarNames)\r可以看下结果：\nAllData\r## $BirdData\r## [1] 59.0 55.0 53.5 55.0 52.5 57.5 53.0 55.0 22.3 19.7 20.8 20.3 20.8 21.5\r## [15] 20.6 21.5 31.2 30.4 30.6 30.3 30.3 30.8 32.5 NA 9.5 13.8 14.8 15.2\r## [29] 15.5 15.6 15.6 15.7\r## ## $Id\r## [1] 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4\r## ## $Z\r## Wingcrd Tarsus Head Wt\r## [1,] 59.0 22.3 31.2 9.5\r## [2,] 55.0 19.7 30.4 13.8\r## [3,] 53.5 20.8 30.6 14.8\r## [4,] 55.0 20.3 30.3 15.2\r## [5,] 52.5 20.8 30.3 15.5\r## [6,] 57.5 21.5 30.8 15.6\r## [7,] 53.0 20.6 32.5 15.6\r## [8,] 55.0 21.5 NA 15.7\r## ## $VarNames\r## [1] \u0026quot;Wingcrd\u0026quot; \u0026quot;Tarsus\u0026quot; \u0026quot;Head\u0026quot; \u0026quot;Wt\u0026quot;\r这种数据的存放方法在处理一些数据，比如用某些R包处理代谢组学数据时，极为有用。\n\r\r2.2数据的载入\r前面都是说的数据的输入，少量数据还好，但是大量的数据，这个就不合适了，最好是直接将excel文件什么的直接导入R中。\n2.2.1 Excel中的数据载入\r2.2.1.1 Excel中的数据准备\r这节很重要，因为原始文件中数据的排列方式不仅对向R导入，还对之后的分析至关重要。\n为方便，一般将数据排列成样本-变量的形式，也就是说，行代表各种变量，列代表各种样本，当然，反过来也行。一般最好以Excel中的第一列来识别样本，第一行作为变量名。举个例子，下图是一组乌贼的性腺指数（GSI）的数据库。\r\r2.2.1.2 数据提取到制表符分割的ascii文件\r将这个Excel文件另存为文本文件（制表符分割）即txt文件，注意，另存为那里还有别的txt文件格式，别选错了。\n\r2.2.1.3 read.table函数\r当制表符分割的ascii文件没有空内容或者包含空格的名称时（想想看，为什么不能有包含空格的名称），就可以将数据载入R中。\n#Squid \u0026lt;- read.table(file = \u0026quot;C:/RBook/squidGSI.txt\u0026quot;,header = TRUE)\r为了不报错，我将这个命令注释掉了。因为我在C盘下，没有这个文件夹和文件。header = TRUE这参数表示第一行包含了标签。\n\r\r2.2.2 从其他统计程序包中访问数据\r其实R不仅能从文本文件也就是txt文件中读出数据，.xls等Excel文件也可以。后面再讲。\r同时，也可以从Minitab，SAS，SPSS什么的导入数据。可以键入：\n#library(foreign)\r然后再查找这个包的帮助文档来解决导入其他数据文件。\n\r2.2.3 访问数据库\r嗯~~这部分就不讲了，目前在学数据库，没搞明白呢。因为这个从R中访问数据库，需要一些驱动程序，有些麻烦。\n\r\r2.3 本章涉及的R函数\r自己去整合吧。\n\r习题\r有人通过观察生长在西班牙一些地方的野猪和马鹿得到这个数据，包含了两种生物的肺结核（tuberculosis，Tb）信息，寄生虫Elaphostrongylus cervi的信息，这种寄生虫只会感染马鹿。\r在另一些人的研究中，Tb被当做是一个连续变量的函数，动物的长度由lengthCT（CT是cabeza-tronco的缩写，表示头体）表示Tb和Ecervi是由0和1组成的向量，分别代表未发现或发现了Tb和Ecervi的幼虫。下表的前7行给出了马鹿的数据。\r\r\r\r农场\r月份\r年份\r性别\rLengthClass\rLengthCT\rEcervi\rTb\r\r\r\rMO\r11\r00\r1\r1\r75\r0\r0\r\rMO\r07\r00\r2\r1\r85\r0\r0\r\rMO\r07\r01\r2\r1\r91.6\r0\r1\r\rMO\rNA\rNA\r2\r1\r95\rNA\rNA\r\rLN\r09\r03\r1\r1\rNA\r0\r0\r\rSE\r09\r03\r2\r1\r105.5\r0\r0\r\rQM\r11\r02\r2\r1\r106\r0\r0\r\r\r\r使用c()函数创建一个包含了7只动物长度值的变量，再生成一个包含了Tb的变量，包含NA，并求7只动物的平均长度。\n继续习题1中的数据。首先生成一个包含了农场和月份的变量，注意农场是字符串。然后用cbind结合月份、长度和Tb的数据，并将结果储存在变量Boar中，同时确保可以提取Boar的行、列及每个元素。并用dim，nrow和ncol函数确定Boar中动物的数量和变量的数量。\n\r继续习题1的数据。类似于习题2，使用vector函数集合Tb数据，使用不一样的变量名，如TB2。\n\r在R中生成下面的矩阵，并确定它的转置矩阵，逆矩阵，同时计算D和它的逆矩阵之乘积（结果将是单位矩阵）。\r\\[\rD=\\begin{bmatrix}\r1\u0026amp;2\u0026amp;3\\\\\r4\u0026amp;2\u0026amp;1\\\\\r2\u0026amp;3\u0026amp;0\\\\\r\\end{bmatrix}\r\\]\r继续习题1至3的问题。生成一个包含习题1表中所有数据的数据框，并将长度数据值的平方根加到这个数据框中，再用list函数完成同样的操作，比较它们之间的不同点。\n\r文件ISIT.xls包含了深海生物发光的数据，准备一个电子数据表，并且把数据提取到ascii文件中，依次使用read.table和scan函数将这些数据载入到R中，使用两个不同的变量来储存数据，比较它们的不同点，使用is.matrix和is.data.frame函数回答这个问题。\n\r文件Deer.xls包含了习题1讨论的马鹿数据，但也包含其他动物的数据，把需要的数据从Excel提取到Ascii文件中，并将它载入R。\n\r\r\r\r","date":1570492800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1570492800,"objectID":"556f0466f5734c527a309e1415d0d474","permalink":"/post/r%E8%AF%AD%E8%A8%80%E5%88%9D%E5%AD%A6%E8%80%85%E6%8C%87%E5%8D%97-%E7%AC%AC%E4%BA%8C%E7%AB%A0/","publishdate":"2019-10-08T00:00:00Z","relpermalink":"/post/r%E8%AF%AD%E8%A8%80%E5%88%9D%E5%AD%A6%E8%80%85%E6%8C%87%E5%8D%97-%E7%AC%AC%E4%BA%8C%E7%AB%A0/","section":"post","summary":"写在前面 嗯~怎么说呢，之前的那本书，我又鸽了，原因有这几个：","tags":["R"],"title":"R语言初学者指南-第二章","type":"post"},{"authors":null,"categories":["R","统计"],"content":"\r第四章\r\r","date":1561766400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1561766400,"objectID":"aa31728513b5479c8811177d40f2318c","permalink":"/post/r%E8%AF%AD%E8%A8%80%E7%BB%9F%E8%AE%A1%E5%88%86%E6%9E%90%E4%B8%8E%E5%BA%94%E7%94%A8-%E7%AC%AC%E5%9B%9B%E7%AB%A0/","publishdate":"2019-06-29T00:00:00Z","relpermalink":"/post/r%E8%AF%AD%E8%A8%80%E7%BB%9F%E8%AE%A1%E5%88%86%E6%9E%90%E4%B8%8E%E5%BA%94%E7%94%A8-%E7%AC%AC%E5%9B%9B%E7%AB%A0/","section":"post","summary":"第四章","tags":["R","统计"],"title":"R语言统计分析与应用-第四章","type":"post"},{"authors":null,"categories":["R","统计"],"content":"\r3.5 变量的重命名\r继续接上期。上期讲到啥了~~\n算了，根据标题来。这一节主要讲如何修改变量的名称。一般来说，可以通过交互式或者编程的方法来实现。\n假设希望将变量名manager变为managerID。\n#fix(leader)\r#在弹出的界面单击manager就可以修改了\r上面是交互式修改，下面介绍如何用命令行修改。\nmanager \u0026lt;- c(1,2,3,4,5)\rdate \u0026lt;- c(\u0026quot;10/20/08\u0026quot;,\u0026quot;10/21/08\u0026quot;,\u0026quot;10/10/08\u0026quot;,\u0026quot;10/19/08\u0026quot;,\u0026quot;6/1/09\u0026quot;)\rcountry \u0026lt;- c(\u0026quot;US\u0026quot;,\u0026quot;UK\u0026quot;,\u0026quot;US\u0026quot;,\u0026quot;UK\u0026quot;,\u0026quot;US\u0026quot;)\rgender \u0026lt;- c(\u0026quot;M\u0026quot;,\u0026quot;F\u0026quot;,\u0026quot;M\u0026quot;,\u0026quot;F\u0026quot;,\u0026quot;M\u0026quot;)\rage \u0026lt;- c(32,43,26,38,99)\rq1 \u0026lt;- c(5,3,3,3,2)\rq2 \u0026lt;- c(4,5,5,3,2)\rq3 \u0026lt;- c(5,2,5,4,1)\rq4 \u0026lt;- c(5,5,5,NA,1)\rq5 \u0026lt;- c(5,5,2,NA,1)\rleader \u0026lt;- data.frame(manager,date,country,gender,age,\rq1,q2,q3,q4,q5,\rstringsAsFactors = FALSE)\r#首先调用reshape包\rlibrary(reshape)\r#修改manager和date变量名\r#这里书上出现了个错误。managerID应该用双引号括起来\rleader \u0026lt;- rename(leader, c(manager=\u0026quot;managerID\u0026quot;,\rdate=\u0026quot;testDate\u0026quot;))\rleader\r## managerID testDate country gender age q1 q2 q3 q4 q5\r## 1 1 10/20/08 US M 32 5 4 5 5 5\r## 2 2 10/21/08 UK F 43 3 5 2 5 5\r## 3 3 10/10/08 US M 26 3 5 5 5 2\r## 4 4 10/19/08 UK F 38 3 3 4 NA NA\r## 5 5 6/1/09 US M 99 2 2 1 1 1\r#也可以通过names()函数来重命名变量\r#比如讲q1-q5变为item1-item5\rnames(leader)[6:10] \u0026lt;- c(\u0026quot;item1\u0026quot;,\u0026quot;item2\u0026quot;,\u0026quot;item3\u0026quot;,\r\u0026quot;item4\u0026quot;,\u0026quot;item5\u0026quot;)\rleader\r## managerID testDate country gender age item1 item2 item3 item4 item5\r## 1 1 10/20/08 US M 32 5 4 5 5 5\r## 2 2 10/21/08 UK F 43 3 5 2 5 5\r## 3 3 10/10/08 US M 26 3 5 5 5 2\r## 4 4 10/19/08 UK F 38 3 3 4 NA NA\r## 5 5 6/1/09 US M 99 2 2 1 1 1\r嗯，就这么简单。\n\r3.6 缺失值\r说起缺失值，很烦的好不好。在实际的数据处理中，经常会遇到缺失值的出现。有些是因为某些样本并没有这个变量（指标），也有些是因为测量过程中出现问题导致的。\n缺失值的存在对后续的数据处理是个很大的问题。在R中，缺失值用NA表示。可以用函数is.na()检测缺失值是否存在。它将返回逻辑值。出现NA就用TRUE，反之则是FALSE。看下面的例子。\nx \u0026lt;- c(1,2,NA,3,4)\ris.na(x)\r## [1] FALSE FALSE TRUE FALSE FALSE\r现在将这个函数应用在leader数据框上：\nis.na(leader[6:10])\r## item1 item2 item3 item4 item5\r## [1,] FALSE FALSE FALSE FALSE FALSE\r## [2,] FALSE FALSE FALSE FALSE FALSE\r## [3,] FALSE FALSE FALSE FALSE FALSE\r## [4,] FALSE FALSE FALSE TRUE TRUE\r## [5,] FALSE FALSE FALSE FALSE FALSE\r那么问题来了，现在已经检测到缺失值了，要怎么处理呢？\n第一种方法是删除这些缺失值，用其余的数据进行之后的运算\n#先构建几个向量\ra \u0026lt;- c(1,NA,2,3,4)\rb \u0026lt;- c(10,20,NA,30,40)\rz \u0026lt;- a+b\rz\r## [1] 11 NA NA 33 44\rd \u0026lt;- a[1]+a[2]+a[3]+a[4]+a[5]\rd\r## [1] NA\re \u0026lt;- sum(a)\re\r## [1] NA\r#可以看出e算不出来，在sum函数中加入na.rm=TRUE删掉缺失值\re \u0026lt;- sum(a,na.rm = TRUE)\r也可以用函数na.omit()来移除所有含有缺失值的观测，也就是变量，它将删除所有含有缺失值的行。\nleader\r## managerID testDate country gender age item1 item2 item3 item4 item5\r## 1 1 10/20/08 US M 32 5 4 5 5 5\r## 2 2 10/21/08 UK F 43 3 5 2 5 5\r## 3 3 10/10/08 US M 26 3 5 5 5 2\r## 4 4 10/19/08 UK F 38 3 3 4 NA NA\r## 5 5 6/1/09 US M 99 2 2 1 1 1\rnewdata \u0026lt;- na.omit(leader)\rnewdata\r## managerID testDate country gender age item1 item2 item3 item4 item5\r## 1 1 10/20/08 US M 32 5 4 5 5 5\r## 2 2 10/21/08 UK F 43 3 5 2 5 5\r## 3 3 10/10/08 US M 26 3 5 5 5 2\r## 5 5 6/1/09 US M 99 2 2 1 1 1\r可以看见少了两行。要注意的是，这个函数尽量不要用，因为它作用太强了。\n那么问题又来了，不能用这个函数，还能用什么呢。\n在其他地方看到，可以用填补法把缺失值填上去（不影响原有数据的分布）。不过现在忘了在哪里看到了，等有空了再补上。\n\r3.8 类型转换\r嗯，我就是跳过了3.7节，也就是日期值的内容。有兴趣的话自己去看看吧。\n类型转换包括数值型、字符型等的互转，数据框、矩阵等的互转。见下表。\n\r\r判断\r转换\r\r\r\ris.numeric()\ras.numeric()\r\ris.character()\ras..character()\r\ris.vector()\ras.vector()\r\ris.matrix()\ras.matrix()\r\ris.data.frame()\ras.data.frame()\r\ris.factor()\ras.factor()\r\ris.logical()\ras.logical()\r\r\r\r一般来说，先判断类型，再根据需求转换。例子我就不举了，以后会用到。\r算了，讲一个吧。\nxyz \u0026lt;- c(2,4,5,6,7)\ris.numeric(xyz)\r## [1] TRUE\ris.vector(xyz)\r## [1] TRUE\ris.character(xyz)\r## [1] FALSE\rxyz \u0026lt;- as.character(xyz)\ris.numeric(xyz)\r## [1] FALSE\ris.vector(xyz)\r## [1] TRUE\ris.character(xyz)\r## [1] TRUE\r\r3.9 数据排序\r排序嘛，很好理解。举个栗子。\n#用order()函数\rnewdata1 \u0026lt;- leader[order(leader$age)]\rnewdata1\r## country managerID gender testDate age\r## 1 US 1 M 10/20/08 32\r## 2 UK 2 F 10/21/08 43\r## 3 US 3 M 10/10/08 26\r## 4 UK 4 F 10/19/08 38\r## 5 US 5 M 6/1/09 99\r或者\nattach(leader)\r## The following objects are masked _by_ .GlobalEnv:\r## ## age, country, gender\rnewdata2 \u0026lt;- leader[order(gender,age)]\rnewdata2\r## gender testDate country managerID age\r## 1 M 10/20/08 US 1 32\r## 2 F 10/21/08 UK 2 43\r## 3 M 10/10/08 US 3 26\r## 4 F 10/19/08 UK 4 38\r## 5 M 6/1/09 US 5 99\r\r3.10 数据集的合并\r说实话，我觉得应该先讲数据集的拆分，不过无所谓了。\n数据集的合并可以看成在原来的数据集上添加行或者列。多数情况下，两个数据框是通过一个或多个共有变量进行联结的，叫做内联结（inner join）。\rmerge()函数是用来横向合并数据集的，即列合并。\n\rtotal \u0026lt;- merge(dataframe1,datafame2,by=“ID”)\n\r下面看下具体的例子。\nlibrary(multilevel)\r## 载入需要的程辑包：nlme\r## 载入需要的程辑包：MASS\rdata(cohesion)\rcohesion\r## UNIT PLATOON COH01 COH02 COH03 COH04 COH05\r## 1 1044B 1ST 4 5 5 5 5\r## 2 1044B 1ST 3 NA 5 5 5\r## 3 1044B 1ST 2 3 3 3 3\r## 4 1044B 2ND 3 4 3 4 4\r## 5 1044B 2ND 4 4 3 4 4\r## 6 1044B 2ND 3 3 2 2 1\r## 7 1044C 1ST 3 3 3 3 3\r## 8 1044C 1ST 3 1 4 3 4\r## 9 1044C 2ND 3 3 3 3 3\r## 10 1044C 2ND 2 2 2 3 2\r## 11 1044C 2ND 1 1 1 3 3\r#现在新建一个数据框group.size\rgroup.size \u0026lt;- data.frame(\rUNIT=c(\u0026quot;1044B\u0026quot;,\u0026quot;1044B\u0026quot;,\u0026quot;1044C\u0026quot;,\u0026quot;1044C\u0026quot;),\rPLATOON=c(\u0026quot;1ST\u0026quot;,\u0026quot;2ND\u0026quot;,\u0026quot;1ST\u0026quot;,\u0026quot;2ND\u0026quot;),\rPSIZE=c(3,3,2,3)\r)\rgroup.size\r## UNIT PLATOON PSIZE\r## 1 1044B 1ST 3\r## 2 1044B 2ND 3\r## 3 1044C 1ST 2\r## 4 1044C 2ND 3\rnew.cohesion \u0026lt;- merge(cohesion,group.size,\rby=c(\u0026quot;UNIT\u0026quot;,\u0026quot;PLATOON\u0026quot;))\rnew.cohesion\r## UNIT PLATOON COH01 COH02 COH03 COH04 COH05 PSIZE\r## 1 1044B 1ST 4 5 5 5 5 3\r## 2 1044B 1ST 3 NA 5 5 5 3\r## 3 1044B 1ST 2 3 3 3 3 3\r## 4 1044B 2ND 3 4 3 4 4 3\r## 5 1044B 2ND 4 4 3 4 4 3\r## 6 1044B 2ND 3 3 2 2 1 3\r## 7 1044C 1ST 3 3 3 3 3 2\r## 8 1044C 1ST 3 1 4 3 4 2\r## 9 1044C 2ND 3 3 3 3 3 3\r## 10 1044C 2ND 2 2 2 3 2 3\r## 11 1044C 2ND 1 1 1 3 3 3\r那么，纵向合并也就是行合并怎么弄呢。用rbind()函数。\n\rtotal \u0026lt;- rbind(dataframe1,datafame2)\n\r注意一点，两个数据框必须拥有相同的变量，顺序倒是无所谓。如果A数据框含有B数据框没有的变量，那么就采取下面两种方法：\r1. 将它删除；\n在B中追加这个变量并将其值设置为NA。\r\r\r3.11 数据集取子集\r这节的内容就是在解决第三章开头的第5个问题。\n在实际操作中，经常会出现导入的数据集包含了太多样本以及变量，而仅仅只想针对某些样本或者变量来展开研究。下面一一介绍取子集的方法。\n3.11.1 选入样本\r见例子：\ndata(cohesion)\rcohesion\r## UNIT PLATOON COH01 COH02 COH03 COH04 COH05\r## 1 1044B 1ST 4 5 5 5 5\r## 2 1044B 1ST 3 NA 5 5 5\r## 3 1044B 1ST 2 3 3 3 3\r## 4 1044B 2ND 3 4 3 4 4\r## 5 1044B 2ND 4 4 3 4 4\r## 6 1044B 2ND 3 3 2 2 1\r## 7 1044C 1ST 3 3 3 3 3\r## 8 1044C 1ST 3 1 4 3 4\r## 9 1044C 2ND 3 3 3 3 3\r## 10 1044C 2ND 2 2 2 3 2\r## 11 1044C 2ND 1 1 1 3 3\r#选择第一到第三行并命名为newdata3数据集\r#注意方括号的用法\u0026quot;[行, 列]\u0026quot;\rnewdata3 \u0026lt;- cohesion[1:3,]\r#按条件筛选\r#注意绝对等于“==”以及连接符“\u0026amp;”\rnewdata4 \u0026lt;- cohesion[which(cohesion$UNIT==\u0026quot;1044B\u0026quot;\r\u0026amp;\rcohesion$COH03\u0026gt;=4),]\r当然，这个方法不唯一，subset()函数也可以。\n\r3.11.2 选入变量\r同样见例子。\ndata(cohesion)\rcohesion\r## UNIT PLATOON COH01 COH02 COH03 COH04 COH05\r## 1 1044B 1ST 4 5 5 5 5\r## 2 1044B 1ST 3 NA 5 5 5\r## 3 1044B 1ST 2 3 3 3 3\r## 4 1044B 2ND 3 4 3 4 4\r## 5 1044B 2ND 4 4 3 4 4\r## 6 1044B 2ND 3 3 2 2 1\r## 7 1044C 1ST 3 3 3 3 3\r## 8 1044C 1ST 3 1 4 3 4\r## 9 1044C 2ND 3 3 3 3 3\r## 10 1044C 2ND 2 2 2 3 2\r## 11 1044C 2ND 1 1 1 3 3\r#选择cohesion数据集中第一个到第三个变量，也就是列\rnewdata5 \u0026lt;- cohesion[1:3]\rnewdata5\r## UNIT PLATOON COH01\r## 1 1044B 1ST 4\r## 2 1044B 1ST 3\r## 3 1044B 1ST 2\r## 4 1044B 2ND 3\r## 5 1044B 2ND 4\r## 6 1044B 2ND 3\r## 7 1044C 1ST 3\r## 8 1044C 1ST 3\r## 9 1044C 2ND 3\r## 10 1044C 2ND 2\r## 11 1044C 2ND 1\r#等价于\rv \u0026lt;- c(\u0026quot;UNIT\u0026quot;,\u0026quot;PLATOON\u0026quot;,\u0026quot;COH01\u0026quot;)\rnewdata6 \u0026lt;- cohesion[v]\rnewdata6\r## UNIT PLATOON COH01\r## 1 1044B 1ST 4\r## 2 1044B 1ST 3\r## 3 1044B 1ST 2\r## 4 1044B 2ND 3\r## 5 1044B 2ND 4\r## 6 1044B 2ND 3\r## 7 1044C 1ST 3\r## 8 1044C 1ST 3\r## 9 1044C 2ND 3\r## 10 1044C 2ND 2\r## 11 1044C 2ND 1\r\r3.11.3 剔除变量\r捡栗子，不对，见例子：\nmyvariable \u0026lt;- names(cohesion) %in%\rc(\u0026quot;COH01\u0026quot;,\u0026quot;COH03\u0026quot;,\u0026quot;COH05\u0026quot;)\rnewdata7 \u0026lt;- cohesion[!myvariable]\rnewdata7\r## UNIT PLATOON COH02 COH04\r## 1 1044B 1ST 5 5\r## 2 1044B 1ST NA 5\r## 3 1044B 1ST 3 3\r## 4 1044B 2ND 4 4\r## 5 1044B 2ND 4 4\r## 6 1044B 2ND 3 2\r## 7 1044C 1ST 3 3\r## 8 1044C 1ST 1 3\r## 9 1044C 2ND 3 3\r## 10 1044C 2ND 2 3\r## 11 1044C 2ND 1 3\r下面讲解一下：\r\u0026gt;names(cohesion)产生一个包含所有变量名的字符向量\n\rnames(cohesion) %in% c(“COH01”,“COH03”,“COH05”)返回一个逻辑向量，names(cohesion)中每个匹配这三个变量的元素的值为TRUE，反之为FALSE。即c(FALSE,FALSE,TRUE,FALSE,TRUE,FALSE,TRUE)\n\r\r运算符非（即“！”）将逻辑值翻转即c(TRUE,TRUE,FALSE,TRUE,FALSE,TRUE,FALSE)\n\r\rcohesion[c(TRUE,TRUE,FALSE,TRUE,FALSE,TRUE,FALSE)]选了TRUE的列。\n\r于是COH01，COH03，COH05被删除了。\r当然也可以根据这三个变量的位置来操作。\nnewdata8 \u0026lt;- cohesion[c(-3,-5,-7)]\rnewdata8\r## UNIT PLATOON COH02 COH04\r## 1 1044B 1ST 5 5\r## 2 1044B 1ST NA 5\r## 3 1044B 1ST 3 3\r## 4 1044B 2ND 4 4\r## 5 1044B 2ND 4 4\r## 6 1044B 2ND 3 2\r## 7 1044C 1ST 3 3\r## 8 1044C 1ST 1 3\r## 9 1044C 2ND 3 3\r## 10 1044C 2ND 2 3\r## 11 1044C 2ND 1 3\r\r3.11.4 subset()函数\r前面提到了这个函数，举个例子：\nnewdata9 \u0026lt;- subset(cohesion, COH02\u0026gt;=4 | COH02\u0026lt;=1,\rselect=c(COH01,COH02,COH03,COH04,COH05))\rnewdata9\r## COH01 COH02 COH03 COH04 COH05\r## 1 4 5 5 5 5\r## 4 3 4 3 4 4\r## 5 4 4 3 4 4\r## 8 3 1 4 3 4\r## 11 1 1 1 3 3\rnewdata10 \u0026lt;- subset(cohesion, UNIT==\u0026quot;1044B\u0026quot; \u0026amp; COH02\u0026gt;=4,\rselect=c(COH01,COH02,COH03,COH04,COH05))\rnewdata10\r## COH01 COH02 COH03 COH04 COH05\r## 1 4 5 5 5 5\r## 4 3 4 3 4 4\r## 5 4 4 3 4 4\r嗯，这章就结束了。\n\r\r","date":1557273600,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1557273600,"objectID":"fa92dd987612cdff7d7abd82654d3c88","permalink":"/post/r%E8%AF%AD%E8%A8%80%E7%BB%9F%E8%AE%A1%E5%88%86%E6%9E%90%E4%B8%8E%E5%BA%94%E7%94%A8-%E7%AC%AC%E4%B8%89%E7%AB%A0-2/","publishdate":"2019-05-08T00:00:00Z","relpermalink":"/post/r%E8%AF%AD%E8%A8%80%E7%BB%9F%E8%AE%A1%E5%88%86%E6%9E%90%E4%B8%8E%E5%BA%94%E7%94%A8-%E7%AC%AC%E4%B8%89%E7%AB%A0-2/","section":"post","summary":"3.5 变量的重命名 继续接上期。上期讲到啥了~~ 算了，根据标题来。","tags":["R","统计"],"title":"R语言统计分析与应用-第三章-2","type":"post"},{"authors":null,"categories":["R","统计"],"content":"\r第三章 基本数据管理\r前面讲了一些常用的函数以及数据的输入，在数据处理过程中，在数据输入之后还要对数据进行筛选啊拆分啊什么的，这一章主要讲的就是这个。\n下面讲一个例子：\r某项研究想确定男性和女性在领导各自企业方式上的不同，主要的问题如下：\n处于管理岗位的男性和女性在听从上级的程度上是否不同；\n\r这种情况是否依国家不同而不同，或者由性别导致的不同是否普遍存在。\n\r\r针对这两个问题，让多个国家的经理人的上司对其服从程度打分：\r这位经理人在做出决策之前会询问我的意见。\n\r\r态度\r分数\r\r\r\r非常不同意\r1\r\r不同意\r2\r\r中立\r3\r\r同意\r4\r\r非常同意\r5\r\r\r\r在这里，每位上司根据这个对某一名经理人进行评分，为简化，一共5个经理人，5个上司。因此，上司的评分就有q1到q5，共5个向量。\nmanager \u0026lt;- c(1,2,3,4,5)\rdate \u0026lt;- c(\u0026quot;10/20/08\u0026quot;,\u0026quot;10/21/08\u0026quot;,\u0026quot;10/10/08\u0026quot;,\u0026quot;10/19/08\u0026quot;,\u0026quot;6/1/09\u0026quot;)\rcountry \u0026lt;- c(\u0026quot;US\u0026quot;,\u0026quot;UK\u0026quot;,\u0026quot;US\u0026quot;,\u0026quot;UK\u0026quot;,\u0026quot;US\u0026quot;)\rgender \u0026lt;- c(\u0026quot;M\u0026quot;,\u0026quot;F\u0026quot;,\u0026quot;M\u0026quot;,\u0026quot;F\u0026quot;,\u0026quot;M\u0026quot;)\rage \u0026lt;- c(32,43,26,38,99)\rq1 \u0026lt;- c(5,3,3,3,2)\rq2 \u0026lt;- c(4,5,5,3,2)\rq3 \u0026lt;- c(5,2,5,4,1)\rq4 \u0026lt;- c(5,5,5,NA,1)\rq5 \u0026lt;- c(5,5,2,NA,1)\rleader \u0026lt;- data.frame(manager,date,country,gender,age,\rq1,q2,q3,q4,q5,\rstringsAsFactors = FALSE)\rleader\r## manager date country gender age q1 q2 q3 q4 q5\r## 1 1 10/20/08 US M 32 5 4 5 5 5\r## 2 2 10/21/08 UK F 43 3 5 2 5 5\r## 3 3 10/10/08 US M 26 3 5 5 5 2\r## 4 4 10/19/08 UK F 38 3 3 4 NA NA\r## 5 5 6/1/09 US M 99 2 2 1 1 1\r为从这些数据里分析出东西来，就要对这些数据进行管理。比如；\n5个评分（q1到q5）需要组合起来，即为每位经理人生成一个平均服从程度得分；\n\r从上面可以看出，有些得分出现了NA缺失值，同时也需要为99岁这样的数据重编码为缺失值，因为99岁这明显不对啊。因此需要一种处理不完整数据的方法；\n\r在某些数据集中往往包含了数百个变量，而我们可能只对一些感兴趣，因此希望创建一个只包含那些变量的新数据集；\n\r在本例中，领导行为可能随经理人的年龄而改变，即二者存在某种函数关系。要检验这种观点，需要将当前的年龄数值重编码为类别型的年龄组（比如，年轻，中年，年长）；\n\r领导行为可能随时间推移而发生变化，我们可能想重点研究最近全球金融危机期间的服从行为。那么，需要将研究范围限定在某一个特定的时间段（比如1/1/09到12/31/09）。\n\r\r这些问题怎么解决呢，下面将一一介绍。\n3.1 创建新变量\r创建新变量很简单，重点在于如何将新变量整合到原来的数据集中：\ny1 \u0026lt;- c(1,2,3,4,5)\ry2 \u0026lt;- c(12,13,15,16,17)\rnewdata \u0026lt;- data.frame(y1,y2)\rhead(newdata)\r## y1 y2\r## 1 1 12\r## 2 2 13\r## 3 3 15\r## 4 4 16\r## 5 5 17\r#创建新变量\rsumy \u0026lt;- newdata$y1+newdata$y2\rmeany \u0026lt;- (newdata$y1+newdata$y2)/2\rsumy\r## [1] 13 15 18 20 22\rmeany\r## [1] 6.5 7.5 9.0 10.0 11.0\r#可以看出只是创建了新变量，但是不在newdata中\r#整合到newdata数据框中\r#方法一\rnewdata1 \u0026lt;- data.frame(newdata, sumy, meany)\rhead(newdata1)\r## y1 y2 sumy meany\r## 1 1 12 13 6.5\r## 2 2 13 15 7.5\r## 3 3 15 18 9.0\r## 4 4 16 20 10.0\r## 5 5 17 22 11.0\r#方法二\rnewdata2 \u0026lt;- transform(newdata,\rsumy=y1+y2,\rmeany=(y1+y2)/2)\rhead(newdata2)\r## y1 y2 sumy meany\r## 1 1 12 13 6.5\r## 2 2 13 15 7.5\r## 3 3 15 18 9.0\r## 4 4 16 20 10.0\r## 5 5 17 22 11.0\r#方法三\rnewdata3 \u0026lt;- newdata\rattach(newdata3)\r## The following objects are masked _by_ .GlobalEnv:\r## ## y1, y2\rnewdata3$sumy \u0026lt;- y1+y2\rnewdata3$meany \u0026lt;- (y1+y2)/2\rdetach(newdata3)\rhead(newdata3)\r## y1 y2 sumy meany\r## 1 1 12 13 6.5\r## 2 2 13 15 7.5\r## 3 3 15 18 9.0\r## 4 4 16 20 10.0\r## 5 5 17 22 11.0\r\r3.2 向量运算\r3.2.1 添加或删除向量\r在R中，向量一旦建立起来，里面的元素就已经确定了。因此，如果想添加或删除元素，就需要重新给向量赋值。\nqwe \u0026lt;- c(12,13,14,23,78)\r#在中间添加一个元素，数值56\rqwe \u0026lt;- c(qwe[1:3],56,qwe[4:5])\rqwe\r## [1] 12 13 14 56 23 78\r\r3.2.2 向量运算\r这部分就是线性代数的内容。嗯……不讲了。看例子吧\nx \u0026lt;- c(2,3,4)\ry \u0026lt;- c(2,5,7)\rx+y\r## [1] 4 8 11\rx*y\r## [1] 4 15 28\r\r3.2.3 用: 运算符创建向量\r：运算符用于生成指定范围内数值构成的向量。\r看例子：\n5:8\r## [1] 5 6 7 8\r5:1\r## [1] 5 4 3 2 1\r#要注意运算符的优先级\ri \u0026lt;- 2\r#冒号的优先级高于减号，所以先计算i:i，变成个一元向量，然后再减1\ri:i-1\r## [1] 1\r#括号的优先级高于冒号，所以先计算i-1，于是就相当于计算2:1\ri:(i-1)\r## [1] 2 1\r注意了，这个地方书上说的不对，解释的也是乱七八糟。它的结果是：\ri:i-1的结果是“0 1”，i:(i-1)的结果是“1”。\n\r3.2.4 使用seq()以及rep()函数创建向量\r比上面那个冒号“：”运算符更常用的是seq()函数。它用来生成等差数列。\nseq(from=10,to=30,by=3)\r## [1] 10 13 16 19 22 25 28\r?seq()\r## starting httpd help server ... done\rseq(10,30,3)\r## [1] 10 13 16 19 22 25 28\rrep()函数可以把同一常数放在向量中，语法是：\nrep(x, times, each)，前两个参数很好理解，最后的each参数是指定x交替重复的次数。\nx \u0026lt;- rep(7,5)\rx\r## [1] 7 7 7 7 7\ry \u0026lt;- rep(c(1,2,3),3)\ry\r## [1] 1 2 3 1 2 3 1 2 3\rrep(1:3,2)\r## [1] 1 2 3 1 2 3\rrep(c(2,6,12),each=3)\r## [1] 2 2 2 6 6 6 12 12 12\r\r\r3.3 处理数据对象的常用函数\r这一部分就不再写了，用的时候自然就知道了。\n\r3.4 变量的重编码\r现在解决前言中的问题2：\r\u0026gt; 2. 从上面可以看出，有些得分出现了NA缺失值，同时也需要为99岁这样的数据重编码为缺失值，因为99岁这明显不对啊。因此需要一种处理不完整数据的方法。\n现在将连续型变量age重编码为类别型变量：agecat(Young,Middle Aged,Elder)。\n#首先把99岁的年龄值编码成缺失值。\rleader$age[leader$age == 99] \u0026lt;- NA\r#然后创建agecat向量\rleader$agecat[leader$age \u0026gt;= 75] \u0026lt;- \u0026quot;Elder\u0026quot;\rleader$agecat[leader$age \u0026lt; 75 \u0026amp; leader$age \u0026gt;=55] \u0026lt;- \u0026quot;Middle Aged\u0026quot;\rleader$agecat[leader$age \u0026lt; 55] \u0026lt;- \u0026quot;Young\u0026quot;\rleader\r## manager date country gender age q1 q2 q3 q4 q5 agecat\r## 1 1 10/20/08 US M 32 5 4 5 5 5 Young\r## 2 2 10/21/08 UK F 43 3 5 2 5 5 Young\r## 3 3 10/10/08 US M 26 3 5 5 5 2 Young\r## 4 4 10/19/08 UK F 38 3 3 4 NA NA Young\r## 5 5 6/1/09 US M NA 2 2 1 1 1 \u0026lt;NA\u0026gt;\r当然这个方法不唯一。\n嗯……今天就到这里。\n\r\r","date":1555718400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1555718400,"objectID":"8821e6a53ce0833c21d308bc41c792a3","permalink":"/post/r%E8%AF%AD%E8%A8%80%E7%BB%9F%E8%AE%A1%E5%88%86%E6%9E%90%E4%B8%8E%E5%BA%94%E7%94%A8-%E7%AC%AC%E4%B8%89%E7%AB%A0-1/","publishdate":"2019-04-20T00:00:00Z","relpermalink":"/post/r%E8%AF%AD%E8%A8%80%E7%BB%9F%E8%AE%A1%E5%88%86%E6%9E%90%E4%B8%8E%E5%BA%94%E7%94%A8-%E7%AC%AC%E4%B8%89%E7%AB%A0-1/","section":"post","summary":"第三章 基本数据管理 前面讲了一些常用的函数以及数据的输入，在数","tags":["R","统计"],"title":"R语言统计分析与应用-第三章-1","type":"post"},{"authors":null,"categories":["R","统计"],"content":"\r书接上文，上回讲到了因子，现在继续讲列表。\n6.列表\n列表就是个大杂烩，可以整合很多对象到单个对象下面。比如，某个列表可能包含了很多向量，矩阵，数据框什么的，甚至可以包含其他列表。创建列表使用list()函数。\n#当然这个只是个实例，肯定运行不出东西的\r#为避免Rmd报错，注释掉好了\r#Mylist \u0026lt;- list(object1, object2)\r下面这个才是栗子（没错，就是栗子）：\na \u0026lt;- \u0026quot;list example\u0026quot;\rx \u0026lt;- c(1,2,3,4,5)\rmatrix \u0026lt;- matrix(1:20,nrow = 5,byrow = FALSE)\rk \u0026lt;- c(\u0026quot;one\u0026quot;,\u0026quot;two\u0026quot;,\u0026quot;four\u0026quot;)\rmylist \u0026lt;- list(a,x,matrix,k)\rmylist\r## [[1]]\r## [1] \u0026quot;list example\u0026quot;\r## ## [[2]]\r## [1] 1 2 3 4 5\r## ## [[3]]\r## [,1] [,2] [,3] [,4]\r## [1,] 1 6 11 16\r## [2,] 2 7 12 17\r## [3,] 3 8 13 18\r## [4,] 4 9 14 19\r## [5,] 5 10 15 20\r## ## [[4]]\r## [1] \u0026quot;one\u0026quot; \u0026quot;two\u0026quot; \u0026quot;four\u0026quot;\r#想要查询某个元素怎么办\r#使用双重方括号，在方括号里面指明某个成分的数字或者名称\rmylist[[3]]\r## [,1] [,2] [,3] [,4]\r## [1,] 1 6 11 16\r## [2,] 2 7 12 17\r## [3,] 3 8 13 18\r## [4,] 4 9 14 19\r## [5,] 5 10 15 20\r#这个等价于\rmylist$matrix\r## NULL\rmylist[[\u0026quot;matrix\u0026quot;]]\r## NULL\r上面这个例子就是创建了一个包含字符串（a），数值型向量（x），矩阵（matrix）以及字符型向量（k）的列表（mylist）。\n下面是补充内容咯：\n这时应该会有人觉得，诶？不是可以通过指明某个成分的名称来查询吗，但是最后两条语句为什么会出现“NULL”的返回值呢。\r这是应为没有给各个成分起名字。列表的成分可以通过列表中成分的索引访问。在命名列表的情况下，它也可以使用名称来访问。\n#给个成分命名\rnames(mylist) \u0026lt;- c(\u0026quot;a\u0026quot;,\u0026quot;x\u0026quot;,\u0026quot;matrix\u0026quot;,\u0026quot;k\u0026quot;)\r#再用名字查询下试试\rmylist$matrix\r## [,1] [,2] [,3] [,4]\r## [1,] 1 6 11 16\r## [2,] 2 7 12 17\r## [3,] 3 8 13 18\r## [4,] 4 9 14 19\r## [5,] 5 10 15 20\rmylist[[\u0026quot;matrix\u0026quot;]]\r## [,1] [,2] [,3] [,4]\r## [1,] 1 6 11 16\r## [2,] 2 7 12 17\r## [3,] 3 8 13 18\r## [4,] 4 9 14 19\r## [5,] 5 10 15 20\r看，这回成功了吧。\r这个问题解决，开始下一部分。\n","date":1555632000,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1555632000,"objectID":"c4760b4d714268bbe0649b6a3146c773","permalink":"/post/r%E8%AF%AD%E8%A8%80%E7%BB%9F%E8%AE%A1%E5%88%86%E6%9E%90%E4%B8%8E%E5%BA%94%E7%94%A8-%E7%AC%AC%E4%BA%8C%E7%AB%A0-3/","publishdate":"2019-04-19T00:00:00Z","relpermalink":"/post/r%E8%AF%AD%E8%A8%80%E7%BB%9F%E8%AE%A1%E5%88%86%E6%9E%90%E4%B8%8E%E5%BA%94%E7%94%A8-%E7%AC%AC%E4%BA%8C%E7%AB%A0-3/","section":"post","summary":"书接上文，上回讲到了因子，现在继续讲列表。 6.列表 列表就是个","tags":["R","统计"],"title":"R语言统计分析与应用-第二章-3","type":"post"},{"authors":null,"categories":["R","统计"],"content":"\r2.1.2 R运算符\r这个部分相对简单些。R中的运算符分为算数运算符、比较算符、逻辑算符。\n算数运算符\r\r就是指加减乘除等等啦，见下表：\n\r\r算数算符\r含义\r\r\r\r+\r加\r\r-\r减\r\r*\r乘\r\r/\r除\r\r^\r幂\r\r%%\r模运算\r\r%/%\r整数除法\r\r\r\r比较算符\r\r就是大于、小于、不等于等等啦，见下表：\n\r\r比较算符\r含义\r\r\r\r==\r等于\r\r!=\r不等于\r\r\u0026gt;\r大于\r\r\u0026lt;\r小于\r\r\u0026gt;=\r大于等于\r\r\u0026lt;+\r小于等于\r\r\r\r逻辑算符\r\r其实就是数学中的或与非啦，见下表：\n\r\r逻辑算符\r含义\r\r\r\r\u0026amp;\u0026amp;\r标量的“与”运算\r\r\r\r\r\u0026amp;\r向量的“与”运算\r\r\r\r\r!\r非\r\r\r\r关于这个就不啰嗦了，或与非其实是高中数学内容了。\r大家应该注意到上面说到了标量这个词，在R中，表面上没有标量的类型，但实际上它可以看做是含有一个元素的向量。下面的例子可以看出逻辑运算符对标量和向量的区别：\nx \u0026lt;- c(TRUE,FALSE,TRUE)\ry \u0026lt;- c(TRUE,TRUE,FALSE)\rx \u0026amp; y\r## [1] TRUE FALSE FALSE\rx[1] \u0026amp;\u0026amp; y[1]\r## [1] TRUE\rx \u0026amp;\u0026amp; y\r## [1] TRUE\rif (x[1] \u0026amp;\u0026amp; y[1])\rprint(\u0026quot;both true\u0026quot;)\r## [1] \u0026quot;both true\u0026quot;\rif (x \u0026amp; y)\rprint(\u0026quot;both true\u0026quot;)\r## Warning in if (x \u0026amp; y) print(\u0026quot;both true\u0026quot;): 条件的长度大于一，因此只能用其第\r## 一元素\r## [1] \u0026quot;both true\u0026quot;\r可以看到最后一条语句报错了“the condition has length \u0026gt; 1 and only the first element will be used”。\r这是因为if结构判断语句的取值，只能是一个逻辑值，而不是逻辑值的向量。\n运算次序\r\r这个~没啥好讲的~\n\r2.2 R常用函数及其应用\r嗯~~前面讲了很多R的基本结构，向量啦，矩阵啦什么的，现在再进一步，开始讲一下R的常用函数。\n2.2.1 数学函数\r#绝对值\rabs(-1)\r## [1] 1\r#平方根\rsqrt(36)\r## [1] 6\r25^(0.5)\r## [1] 5\r#不小于x的最小整数\rceiling(3.1415926)\r## [1] 4\r#不大于x的最大整数\rfloor(3.1415926)\r## [1] 3\r#向0的方向截取x中的整数部分\rtrunc(5.99)\r## [1] 5\r#将x舍入为指定位数的小数\rround(3.1415926, digits = 2)\r## [1] 3.14\r#将x舍入为指定位数的有效数字\rsignif(3.1415926, digits = 2)\r## [1] 3.1\r#一些三角函数\rcos(3.1415926)\r## [1] -1\rsin(3.1415926)\r## [1] 5.358979e-08\rtan(3.1415926)\r## [1] -5.358979e-08\racos(3.1415926)\r## Warning in acos(3.1415926): 产生了NaNs\r## [1] NaN\rasin(3.1415926)\r## Warning in asin(3.1415926): 产生了NaNs\r## [1] NaN\ratan(3.1415926)\r## [1] 1.262627\r#双曲余弦\rcosh(3.1415926)\r## [1] 11.59195\r#双曲正弦\rsinh(3.1415926)\r## [1] 11.54874\r#反双曲余弦、正弦\racosh(3.1415926)\r## [1] 1.811526\rasinh(3.1415926)\r## [1] 1.862296\r#log(x, base=n)，对x取以n为底的对数\rlog(8,2)\r## [1] 3\r#取自然对数\rlog(8)\r## [1] 2.079442\r#常用对数\rlog10(8)\r## [1] 0.90309\rlog(8,10)\r## [1] 0.90309\r#指数函数\rexp(2)\r## [1] 7.389056\r\r2.2.2 样本统计函数\r#平均数\rmean(c(1,2,3,4))\r## [1] 2.5\r#中位数\rmedian(c(1,2,3,4))\r## [1] 2.5\rmedian(c(1,2,3,4,5))\r## [1] 3\r#标准差\rsd(c(1,2,3,4))\r## [1] 1.290994\r#方差\rvar(c(1,2,3,4))\r## [1] 1.666667\r#绝对中位差\rmad(c(1,2,3,4))\r## [1] 1.4826\r#quantile(x,probs)，求分位数，x为待求分位数的数值型向量\r#probs为一个由[0,1]之间的概率组成的数值向量\r#求向量x的第25和75百分位数\rquantile(c(1,2,3,4,5,6,7), c(.25,.75))\r## 25% 75% ## 2.5 5.5\r#求值域\rrange(c(1,2,3,4,5,6,7))\r## [1] 1 7\r#求和\rsum(c(1,2,3,4,5,6,7))\r## [1] 28\r#最大值\rmax(c(1,2,3,4,5,6,7))\r## [1] 7\r#最小值\rmin(c(1,2,3,4,5,6,7))\r## [1] 1\r#scale(x,center=TRUE,scale=TRUE)\r#将数据对象x按列进行中心化（center=TRUE）\r#或标准化（center=TRUE,scale=TRUE）\r#默认情况下，这个函数对矩阵或数据框的指定列进行均值为0\r#标准差为1的标准化\rmydata \u0026lt;- matrix(c(1,2,3,4,5,6), nrow = 2)\rscale(mydata)\r## [,1] [,2] [,3]\r## [1,] -0.7071068 -0.7071068 -0.7071068\r## [2,] 0.7071068 0.7071068 0.7071068\r## attr(,\u0026quot;scaled:center\u0026quot;)\r## [1] 1.5 3.5 5.5\r## attr(,\u0026quot;scaled:scale\u0026quot;)\r## [1] 0.7071068 0.7071068 0.7071068\r#要对每一列进行任意均值和标准差的标准化\r#可以采用下面的语句：mydata \u0026lt;- scale(mydata)*SD+M\r#其中M是想要的均值，SD是想要的标准差\rscale(mydata)*0.25+3\r## [,1] [,2] [,3]\r## [1,] 2.823223 2.823223 2.823223\r## [2,] 3.176777 3.176777 3.176777\r## attr(,\u0026quot;scaled:center\u0026quot;)\r## [1] 1.5 3.5 5.5\r## attr(,\u0026quot;scaled:scale\u0026quot;)\r## [1] 0.7071068 0.7071068 0.7071068\r\r2.2.4 字符处理函数\r前面讲了很多函数，不过都是数值型的，现在接下来要讲的是有关字符处理的函数。\r字符处理函数可以从文本型数据中抽取信息，或者为打印输出和生成报告重设文本的格式。\n#返回字符串x的字符数量\rx \u0026lt;- c(\u0026quot;ab\u0026quot;,\u0026quot;cde\u0026quot;,\u0026quot;dsdesd\u0026quot;)\rlength(x)\r## [1] 3\rnchar(x)\r## [1] 2 3 6\rnchar(x[3])\r## [1] 6\r#substr(x, start, stop)返回字符串x中指定位置范围的子字符串\rx \u0026lt;- \u0026quot;abcdefghij\u0026quot;\rsubstr(x, 2, 4)\r## [1] \u0026quot;bcd\u0026quot;\rsubstr(x, 2, 4) \u0026lt;- \u0026quot;22222\u0026quot;\rx\r## [1] \u0026quot;a222efghij\u0026quot;\r#grep(pattern, x, ignore.case=FALSE, fixed=FALSE)\r#在字符串x中搜索给定的子字符串pattern。\r#若fixed=FALSE，则pattern为一个正则表达式\r#若fixed=TRUE，则pattern为一个文本字符串，返回值为匹配的下标\rgrep(\u0026quot;A\u0026quot;,c(\u0026quot;b\u0026quot;,\u0026quot;A\u0026quot;,\u0026quot;c\u0026quot;), fixed = TRUE)\r## [1] 2\rgrep(\u0026quot;A\u0026quot;,c(\u0026quot;b\u0026quot;,\u0026quot;A\u0026quot;,\u0026quot;c\u0026quot;), fixed = FALSE)\r## [1] 2\r#sub(pattern, replacement, x, ignore.case=FALSE, fixed=FALSE)在x中搜索pattern，并以文本replacement将其替换。\r#若fixed=FALSE，则pattern为一个正则表达式\r#若fixed=TRUE，则pattern为一个文本字符串\r#下例中“\\s”是一个查找空白的正则表达式\r#使用“\\\\s”而不是“\\”的原因在于后者是R中的转义字符\rsub(\u0026quot;\\\\s\u0026quot;, \u0026quot;.\u0026quot;, \u0026quot;Hello There\u0026quot;)\r## [1] \u0026quot;Hello.There\u0026quot;\r#strsplit(x,split,fixed=FALSE)将在以split处分割字符向量x中\r#将元素拆分为若干个子字符串，返回这些子字符串的列表\r#若fixed=FALSE，则pattern为一个正则表达式\r#若fixed=TRUE，则pattern为一个文本字符串\ry \u0026lt;- strsplit(\u0026quot;abc\u0026quot;,\u0026quot;\u0026quot;)\ry\r## [[1]]\r## [1] \u0026quot;a\u0026quot; \u0026quot;b\u0026quot; \u0026quot;c\u0026quot;\runlist(y)[2]\r## [1] \u0026quot;b\u0026quot;\rsapply(y,\u0026quot;[\u0026quot;,2)\r## [1] \u0026quot;b\u0026quot;\rstrsplit(\u0026quot;6-16-2011\u0026quot;,split = \u0026quot;-\u0026quot;)\r## [[1]]\r## [1] \u0026quot;6\u0026quot; \u0026quot;16\u0026quot; \u0026quot;2011\u0026quot;\r#paste(……, sep=\u0026quot;\u0026quot;)把若干个字符串拼接在一起，分隔符为sep\rpaste(\u0026quot;x\u0026quot;, 1:3, sep = \u0026quot;\u0026quot;)\r## [1] \u0026quot;x1\u0026quot; \u0026quot;x2\u0026quot; \u0026quot;x3\u0026quot;\rpaste(\u0026quot;x\u0026quot;, 1:3, sep = \u0026quot;M\u0026quot;)\r## [1] \u0026quot;xM1\u0026quot; \u0026quot;xM2\u0026quot; \u0026quot;xM3\u0026quot;\rpaste(\u0026quot;Today is\u0026quot;, date())\r## [1] \u0026quot;Today is Fri Apr 19 20:30:41 2019\u0026quot;\rpaste(\u0026quot;North\u0026quot;, \u0026quot;Pole\u0026quot;)\r## [1] \u0026quot;North Pole\u0026quot;\rpaste(\u0026quot;North\u0026quot;, \u0026quot;Pole\u0026quot;, sep = \u0026quot; \u0026quot;)\r## [1] \u0026quot;North Pole\u0026quot;\rpaste(\u0026quot;North\u0026quot;, \u0026quot;Pole\u0026quot;, sep = \u0026quot;\u0026quot;)\r## [1] \u0026quot;NorthPole\u0026quot;\rpaste(\u0026quot;North\u0026quot;, \u0026quot;Pole\u0026quot;, sep = \u0026quot;.\u0026quot;)\r## [1] \u0026quot;North.Pole\u0026quot;\rpaste(\u0026quot;North\u0026quot;, \u0026quot;and\u0026quot;, \u0026quot;Pole\u0026quot;, \u0026quot;South\u0026quot;, sep = \u0026quot;\u0026quot;)\r## [1] \u0026quot;NorthandPoleSouth\u0026quot;\r#大写转换\rtoupper(\u0026quot;abc\u0026quot;)\r## [1] \u0026quot;ABC\u0026quot;\r#小写转换\rtolower(\u0026quot;ABC\u0026quot;)\r## [1] \u0026quot;abc\u0026quot;\r#regexpr(pattern,x)在字符串x中寻找pattern\r#返回与pattern匹配的第一个子字符串的起始字符位置\rregexpr(\u0026quot;uat\u0026quot;, \u0026quot;Equator\u0026quot;)\r## [1] 3\r## attr(,\u0026quot;match.length\u0026quot;)\r## [1] 3\r## attr(,\u0026quot;index.type\u0026quot;)\r## [1] \u0026quot;chars\u0026quot;\r## attr(,\u0026quot;useBytes\u0026quot;)\r## [1] TRUE\r#gregexpr(pattern,x)与前一个功能一样\r#不过它会寻找与pattern匹配的全部子字符串的起始位置\rgregexpr(\u0026quot;iss\u0026quot;, \u0026quot;Missppiissist\u0026quot;)\r## [[1]]\r## [1] 2 8\r## attr(,\u0026quot;match.length\u0026quot;)\r## [1] 3 3\r## attr(,\u0026quot;index.type\u0026quot;)\r## [1] \u0026quot;chars\u0026quot;\r## attr(,\u0026quot;useBytes\u0026quot;)\r## [1] TRUE\rgregexpr(\u0026quot;uat\u0026quot;, \u0026quot;Equator\u0026quot;)\r## [[1]]\r## [1] 3\r## attr(,\u0026quot;match.length\u0026quot;)\r## [1] 3\r## attr(,\u0026quot;index.type\u0026quot;)\r## [1] \u0026quot;chars\u0026quot;\r## attr(,\u0026quot;useBytes\u0026quot;)\r## [1] TRUE\r\r2.2.5 其他实用函数\r对象x的长度：\nx \u0026lt;- c(1,2,3,4,5,6)\rlength(x)\r## [1] 6\r生成一个序列：\nmysequ \u0026lt;- seq(1,20,3)\rmysequ\r## [1] 1 4 7 10 13 16 19\r将x重复n次：\nrep(\u0026quot;ABC\u0026quot;,3)\r## [1] \u0026quot;ABC\u0026quot; \u0026quot;ABC\u0026quot; \u0026quot;ABC\u0026quot;\rrep(1:3,3)\r## [1] 1 2 3 1 2 3 1 2 3\r将连续型变量x分割为有着n个水平的因子：\nx \u0026lt;- c(1:1000)\rcut(x, 5)\r## [1] (0.001,201] (0.001,201] (0.001,201] (0.001,201] (0.001,201]\r## [6] (0.001,201] (0.001,201] (0.001,201] (0.001,201] (0.001,201]\r## [11] (0.001,201] (0.001,201] (0.001,201] (0.001,201] (0.001,201]\r## [16] (0.001,201] (0.001,201] (0.001,201] (0.001,201] (0.001,201]\r## [21] (0.001,201] (0.001,201] (0.001,201] (0.001,201] (0.001,201]\r## [26] (0.001,201] (0.001,201] (0.001,201] (0.001,201] (0.001,201]\r## [31] (0.001,201] (0.001,201] (0.001,201] (0.001,201] (0.001,201]\r## [36] (0.001,201] (0.001,201] (0.001,201] (0.001,201] (0.001,201]\r## [41] (0.001,201] (0.001,201] (0.001,201] (0.001,201] (0.001,201]\r## [46] (0.001,201] (0.001,201] (0.001,201] (0.001,201] (0.001,201]\r## [51] (0.001,201] (0.001,201] (0.001,201] (0.001,201] (0.001,201]\r## [56] (0.001,201] (0.001,201] (0.001,201] (0.001,201] (0.001,201]\r## [61] (0.001,201] (0.001,201] (0.001,201] (0.001,201] (0.001,201]\r## [66] (0.001,201] (0.001,201] (0.001,201] (0.001,201] (0.001,201]\r## [71] (0.001,201] (0.001,201] (0.001,201] (0.001,201] (0.001,201]\r## [76] (0.001,201] (0.001,201] (0.001,201] (0.001,201] (0.001,201]\r## [81] (0.001,201] (0.001,201] (0.001,201] (0.001,201] (0.001,201]\r## [86] (0.001,201] (0.001,201] (0.001,201] (0.001,201] (0.001,201]\r## [91] (0.001,201] (0.001,201] (0.001,201] (0.001,201] (0.001,201]\r## [96] (0.001,201] (0.001,201] (0.001,201] (0.001,201] (0.001,201]\r## [101] (0.001,201] (0.001,201] (0.001,201] (0.001,201] (0.001,201]\r## [106] (0.001,201] (0.001,201] (0.001,201] (0.001,201] (0.001,201]\r## [111] (0.001,201] (0.001,201] (0.001,201] (0.001,201] (0.001,201]\r## [116] (0.001,201] (0.001,201] (0.001,201] (0.001,201] (0.001,201]\r## [121] (0.001,201] (0.001,201] (0.001,201] (0.001,201] (0.001,201]\r## [126] (0.001,201] (0.001,201] (0.001,201] (0.001,201] (0.001,201]\r## [131] (0.001,201] (0.001,201] (0.001,201] (0.001,201] (0.001,201]\r## [136] (0.001,201] (0.001,201] (0.001,201] (0.001,201] (0.001,201]\r## [141] (0.001,201] (0.001,201] (0.001,201] (0.001,201] (0.001,201]\r## [146] (0.001,201] (0.001,201] (0.001,201] (0.001,201] (0.001,201]\r## [151] (0.001,201] (0.001,201] (0.001,201] (0.001,201] (0.001,201]\r## [156] (0.001,201] (0.001,201] (0.001,201] (0.001,201] (0.001,201]\r## [161] (0.001,201] (0.001,201] (0.001,201] (0.001,201] (0.001,201]\r## [166] (0.001,201] (0.001,201] (0.001,201] (0.001,201] (0.001,201]\r## [171] (0.001,201] (0.001,201] (0.001,201] (0.001,201] (0.001,201]\r## [176] (0.001,201] (0.001,201] (0.001,201] (0.001,201] (0.001,201]\r## [181] (0.001,201] (0.001,201] (0.001,201] (0.001,201] (0.001,201]\r## [186] (0.001,201] (0.001,201] (0.001,201] (0.001,201] (0.001,201]\r## [191] (0.001,201] (0.001,201] (0.001,201] (0.001,201] (0.001,201]\r## [196] (0.001,201] (0.001,201] (0.001,201] (0.001,201] (0.001,201]\r## [201] (201,401] (201,401] (201,401] (201,401] (201,401] ## [206] (201,401] (201,401] (201,401] (201,401] (201,401] ## [211] (201,401] (201,401] (201,401] (201,401] (201,401] ## [216] (201,401] (201,401] (201,401] (201,401] (201,401] ## [221] (201,401] (201,401] (201,401] (201,401] (201,401] ## [226] (201,401] (201,401] (201,401] (201,401] (201,401] ## [231] (201,401] (201,401] (201,401] (201,401] (201,401] ## [236] (201,401] (201,401] (201,401] (201,401] (201,401] ## [241] (201,401] (201,401] (201,401] (201,401] (201,401] ## [246] (201,401] (201,401] (201,401] (201,401] (201,401] ## [251] (201,401] (201,401] (201,401] (201,401] (201,401] ## [256] (201,401] (201,401] (201,401] (201,401] (201,401] ## [261] (201,401] (201,401] (201,401] (201,401] (201,401] ## [266] (201,401] (201,401] (201,401] (201,401] (201,401] ## [271] (201,401] (201,401] (201,401] (201,401] (201,401] ## [276] (201,401] (201,401] (201,401] (201,401] (201,401] ## [281] (201,401] (201,401] (201,401] (201,401] (201,401] ## [286] (201,401] (201,401] (201,401] (201,401] (201,401] ## [291] (201,401] (201,401] (201,401] (201,401] (201,401] ## [296] (201,401] (201,401] (201,401] (201,401] (201,401] ## [301] (201,401] (201,401] (201,401] (201,401] (201,401] ## [306] (201,401] (201,401] (201,401] (201,401] (201,401] ## [311] (201,401] (201,401] (201,401] (201,401] (201,401] ## [316] (201,401] (201,401] (201,401] (201,401] (201,401] ## [321] (201,401] (201,401] (201,401] (201,401] (201,401] ## [326] (201,401] (201,401] (201,401] (201,401] (201,401] ## [331] (201,401] (201,401] (201,401] (201,401] (201,401] ## [336] (201,401] (201,401] (201,401] (201,401] (201,401] ## [341] (201,401] (201,401] (201,401] (201,401] (201,401] ## [346] (201,401] (201,401] (201,401] (201,401] (201,401] ## [351] (201,401] (201,401] (201,401] (201,401] (201,401] ## [356] (201,401] (201,401] (201,401] (201,401] (201,401] ## [361] (201,401] (201,401] (201,401] (201,401] (201,401] ## [366] (201,401] (201,401] (201,401] (201,401] (201,401] ## [371] (201,401] (201,401] (201,401] (201,401] (201,401] ## [376] (201,401] (201,401] (201,401] (201,401] (201,401] ## [381] (201,401] (201,401] (201,401] (201,401] (201,401] ## [386] (201,401] (201,401] (201,401] (201,401] (201,401] ## [391] (201,401] (201,401] (201,401] (201,401] (201,401] ## [396] (201,401] (201,401] (201,401] (201,401] (201,401] ## [401] (401,600] (401,600] (401,600] (401,600] (401,600] ## [406] (401,600] (401,600] (401,600] (401,600] (401,600] ## [411] (401,600] (401,600] (401,600] (401,600] (401,600] ## [416] (401,600] (401,600] (401,600] (401,600] (401,600] ## [421] (401,600] (401,600] (401,600] (401,600] (401,600] ## [426] (401,600] (401,600] (401,600] (401,600] (401,600] ## [431] (401,600] (401,600] (401,600] (401,600] (401,600] ## [436] (401,600] (401,600] (401,600] (401,600] (401,600] ## [441] (401,600] (401,600] (401,600] (401,600] (401,600] ## [446] (401,600] (401,600] (401,600] (401,600] (401,600] ## [451] (401,600] (401,600] (401,600] (401,600] (401,600] ## [456] (401,600] (401,600] (401,600] (401,600] (401,600] ## [461] (401,600] (401,600] (401,600] (401,600] (401,600] ## [466] (401,600] (401,600] (401,600] (401,600] (401,600] ## [471] (401,600] (401,600] (401,600] (401,600] (401,600] ## [476] (401,600] (401,600] (401,600] (401,600] (401,600] ## [481] (401,600] (401,600] (401,600] (401,600] (401,600] ## [486] (401,600] (401,600] (401,600] (401,600] (401,600] ## [491] (401,600] (401,600] (401,600] (401,600] (401,600] ## [496] (401,600] (401,600] (401,600] (401,600] (401,600] ## [501] (401,600] (401,600] (401,600] (401,600] (401,600] ## [506] (401,600] (401,600] (401,600] (401,600] (401,600] ## [511] (401,600] (401,600] (401,600] (401,600] (401,600] ## [516] (401,600] (401,600] (401,600] (401,600] (401,600] ## [521] (401,600] (401,600] (401,600] (401,600] (401,600] ## [526] (401,600] (401,600] (401,600] (401,600] (401,600] ## [531] (401,600] (401,600] (401,600] (401,600] (401,600] ## [536] (401,600] (401,600] (401,600] (401,600] (401,600] ## [541] (401,600] (401,600] (401,600] (401,600] (401,600] ## [546] (401,600] (401,600] (401,600] (401,600] (401,600] ## [551] (401,600] (401,600] (401,600] (401,600] (401,600] ## [556] (401,600] (401,600] (401,600] (401,600] (401,600] ## [561] (401,600] (401,600] (401,600] (401,600] (401,600] ## [566] (401,600] (401,600] (401,600] (401,600] (401,600] ## [571] (401,600] (401,600] (401,600] (401,600] (401,600] ## [576] (401,600] (401,600] (401,600] (401,600] (401,600] ## [581] (401,600] (401,600] (401,600] (401,600] (401,600] ## [586] (401,600] (401,600] (401,600] (401,600] (401,600] ## [591] (401,600] (401,600] (401,600] (401,600] (401,600] ## [596] (401,600] (401,600] (401,600] (401,600] (401,600] ## [601] (600,800] (600,800] (600,800] (600,800] (600,800] ## [606] (600,800] (600,800] (600,800] (600,800] (600,800] ## [611] (600,800] (600,800] (600,800] (600,800] (600,800] ## [616] (600,800] (600,800] (600,800] (600,800] (600,800] ## [621] (600,800] (600,800] (600,800] (600,800] (600,800] ## [626] (600,800] (600,800] (600,800] (600,800] (600,800] ## [631] (600,800] (600,800] (600,800] (600,800] (600,800] ## [636] (600,800] (600,800] (600,800] (600,800] (600,800] ## [641] (600,800] (600,800] (600,800] (600,800] (600,800] ## [646] (600,800] (600,800] (600,800] (600,800] (600,800] ## [651] (600,800] (600,800] (600,800] (600,800] (600,800] ## [656] (600,800] (600,800] (600,800] (600,800] (600,800] ## [661] (600,800] (600,800] (600,800] (600,800] (600,800] ## [666] (600,800] (600,800] (600,800] (600,800] (600,800] ## [671] (600,800] (600,800] (600,800] (600,800] (600,800] ## [676] (600,800] (600,800] (600,800] (600,800] (600,800] ## [681] (600,800] (600,800] (600,800] (600,800] (600,800] ## [686] (600,800] (600,800] (600,800] (600,800] (600,800] ## [691] (600,800] (600,800] (600,800] (600,800] (600,800] ## [696] (600,800] (600,800] (600,800] (600,800] (600,800] ## [701] (600,800] (600,800] (600,800] (600,800] (600,800] ## [706] (600,800] (600,800] (600,800] (600,800] (600,800] ## [711] (600,800] (600,800] (600,800] (600,800] (600,800] ## [716] (600,800] (600,800] (600,800] (600,800] (600,800] ## [721] (600,800] (600,800] (600,800] (600,800] (600,800] ## [726] (600,800] (600,800] (600,800] (600,800] (600,800] ## [731] (600,800] (600,800] (600,800] (600,800] (600,800] ## [736] (600,800] (600,800] (600,800] (600,800] (600,800] ## [741] (600,800] (600,800] (600,800] (600,800] (600,800] ## [746] (600,800] (600,800] (600,800] (600,800] (600,800] ## [751] (600,800] (600,800] (600,800] (600,800] (600,800] ## [756] (600,800] (600,800] (600,800] (600,800] (600,800] ## [761] (600,800] (600,800] (600,800] (600,800] (600,800] ## [766] (600,800] (600,800] (600,800] (600,800] (600,800] ## [771] (600,800] (600,800] (600,800] (600,800] (600,800] ## [776] (600,800] (600,800] (600,800] (600,800] (600,800] ## [781] (600,800] (600,800] (600,800] (600,800] (600,800] ## [786] (600,800] (600,800] (600,800] (600,800] (600,800] ## [791] (600,800] (600,800] (600,800] (600,800] (600,800] ## [796] (600,800] (600,800] (600,800] (600,800] (600,800] ## [801] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03]\r## [806] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03]\r## [811] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03]\r## [816] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03]\r## [821] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03]\r## [826] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03]\r## [831] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03]\r## [836] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03]\r## [841] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03]\r## [846] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03]\r## [851] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03]\r## [856] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03]\r## [861] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03]\r## [866] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03]\r## [871] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03]\r## [876] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03]\r## [881] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03]\r## [886] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03]\r## [891] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03]\r## [896] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03]\r## [901] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03]\r## [906] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03]\r## [911] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03]\r## [916] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03]\r## [921] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03]\r## [926] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03]\r## [931] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03]\r## [936] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03]\r## [941] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03]\r## [946] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03]\r## [951] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03]\r## [956] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03]\r## [961] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03]\r## [966] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03]\r## [971] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03]\r## [976] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03]\r## [981] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03]\r## [986] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03]\r## [991] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03]\r## [996] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03] (800,1e+03]\r## Levels: (0.001,201] (201,401] (401,600] (600,800] (800,1e+03]\r创建美观的分割点。通过选取n+1个等间距的取整值，将一个连续型变量x分割为n个区间：\nx \u0026lt;- pretty(c(-3,3), 30)\rx\r## [1] -3.0 -2.8 -2.6 -2.4 -2.2 -2.0 -1.8 -1.6 -1.4 -1.2 -1.0 -0.8 -0.6 -0.4\r## [15] -0.2 0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4 1.6 1.8 2.0 2.2 2.4\r## [29] 2.6 2.8 3.0\r\r\r","date":1555632000,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1555632000,"objectID":"dda9795adbe72a27d4fb31b8bdc0bde6","permalink":"/post/r%E8%AF%AD%E8%A8%80%E7%BB%9F%E8%AE%A1%E5%88%86%E6%9E%90%E4%B8%8E%E5%BA%94%E7%94%A8-%E7%AC%AC%E4%BA%8C%E7%AB%A0-4/","publishdate":"2019-04-19T00:00:00Z","relpermalink":"/post/r%E8%AF%AD%E8%A8%80%E7%BB%9F%E8%AE%A1%E5%88%86%E6%9E%90%E4%B8%8E%E5%BA%94%E7%94%A8-%E7%AC%AC%E4%BA%8C%E7%AB%A0-4/","section":"post","summary":"2.1.2 R运算符 这个部分相对简单些。R中的运算符分为算数运算符、比","tags":["R","统计"],"title":"R语言统计分析与应用-第二章-4","type":"post"},{"authors":null,"categories":["R","统计"],"content":"\r2.3 数据的输入\r前面讲了好多的函数以及R的基础知识，但是没有数据怎么办呢?\r下面就介绍几种输入数据的方法。\n2.3.1 使用键盘输入数据\r这是最简单的了，不过只适用于少量的数据。\n#newdata \u0026lt;- data.frame(age=numeric(),sex=character(),weight=numeric())\r#newdata \u0026lt;- edit(newdata)\r上面创建了一个数据框newdata，其中包含两个数值型变量age以及weight，一个字符型变量sex。\r然后用edit()命令调用文本编辑器，输入数据。\r图我就不展示了，总之就是可以直接用键盘输入数据了。\n\r2.3.2 数据集的导入\r前文说到直接用键盘输入数据只适用于少量的数据，那么，大量的数据怎么办。\r也只能导入咯~这是一句废话。\n从带分隔符的文本文件导入数据\r用read.table()就可以了，导入数据之后，保存为数据框。\r命令语法是这样的：\r\u0026gt; read.table(file, header=TRUE, sep=“delimiter”,row.names=“names”)\r\r这里面，file就是要导入的ASCII文本文件；\rheader是一个表明首行是否包含了变量名的逻辑值；\rsep用来指定分割数据的分隔符；\rrow.names是一个可选参数，用于指定一个或多个表示行标识符的变量。\n下面是个例子：\n#Example2_1 \u0026lt;- read.table(\u0026quot;example2_1.csv\u0026quot;, header = TRUE,sep = \u0026quot;,\u0026quot;)\r#Example2_1\r#参数中的sep，可以用sep=\u0026quot;\\t\u0026quot;来读取制表符分割的文件\r#此参数的默认值为sep=\u0026quot;\u0026quot;，即表示分隔符可以是一个或多个空格\r#或者制表符，换行符以及回车符\r导入excel数据\r\r当然，对于一般不做生信的人来说，csv文件其实不常见，常用的excel的数据。\r对于这种文件用下面的方法导入，当然方法很多，这只是其中一个：\n#install.packages(\u0026quot;RODBC\u0026quot;)\r#library(RODBC)\r#Example2_2 \u0026lt;- odbcConnectExcel(\u0026quot;example2_2.xls\u0026quot;)\r#mydata \u0026lt;- sqlFetch(Example2_2, \u0026quot;sheet1\u0026quot;)\r#odbcClose(Example2_2)\r导入SPSS数据\r\r常见的格式还是SPSS数据。\n#library(Hmisc)\r#use.value.labels=TRUE这个参数让函数将带有值标签的标量\r#导入为R中水平对应的因子。\r#mydata \u0026lt;- spss.get(\u0026quot;mydata.sav\u0026quot;, use.value.labels=TRUE)\r嗯，就这样了，第二章断断续续地结束了。\n\r\r","date":1555632000,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1555632000,"objectID":"04b41a2b2af8a8904123ad7730984b73","permalink":"/post/r%E8%AF%AD%E8%A8%80%E7%BB%9F%E8%AE%A1%E5%88%86%E6%9E%90%E4%B8%8E%E5%BA%94%E7%94%A8-%E7%AC%AC%E4%BA%8C%E7%AB%A0-5/","publishdate":"2019-04-19T00:00:00Z","relpermalink":"/post/r%E8%AF%AD%E8%A8%80%E7%BB%9F%E8%AE%A1%E5%88%86%E6%9E%90%E4%B8%8E%E5%BA%94%E7%94%A8-%E7%AC%AC%E4%BA%8C%E7%AB%A0-5/","section":"post","summary":"2.3 数据的输入 前面讲了好多的函数以及R的基础知识，但是没有数据","tags":["R","杂"],"title":"R语言统计分析与应用-第二章-5","type":"post"},{"authors":["Dr.二哈"],"categories":null,"content":" Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1554595200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1554595200,"objectID":"557dc08fd4b672a0c08e0a8cf0c9ff7d","permalink":"/publication/preprint/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/preprint/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example preprint / working paper","type":"publication"},{"authors":null,"categories":["R","统计"],"content":"\rHello，大家好，Dr.二哈又回来了。可能没什么人看，嗯，就说给自己听吧。 去年本来想继续更新的，结果12月初开题，从预开题开始就被训的不行，一直忙的焦头烂额。好不容易开题过了，结果后院又起火了，找师姐帮忙灭火之后，又开始重新处理之前的数据，还要忙着我爸妈和我老婆的父母见面~\n汗~\n不过现在稍微轻松点了，该弄的都差不多了。 于是我又回来了。 闲话不多说，继续去年未完成的第二章。\n因子 变量可以分成三种，名义型，有序型以及连续型。名义型就是没有顺序之分的类别变量。而有序型则表示存在一种顺序关系，而非数量关系。连续型则可以呈现为某个范围内的任意值，并且可以同时表示顺序和数量。比如年龄就是一个连续型变量。 类别（名义型）以及有序类别（有序型）变量，在R中，被称为因子。它的思想来源于统计学中的名义变量或分类变量，这些变量本质上不是数字，而是对应分类。例如血型，尽管可以用数字对其编码，但它还是分类的。 函数factor()可以以一个整数向量的形式存储类别值，将一个由字符串（原始值）组成的内部向量映射到这些整数上。\r\rhypertention \u0026lt;- c(\u0026quot;yes\u0026quot;, \u0026quot;no\u0026quot;, \u0026quot;no\u0026quot;, \u0026quot;yes\u0026quot;)\r#下面这个语句将原来的hypertention向量存储为（2,1,1,2）\r#并在内部将其关联为1=no，2=yes（根据字幕顺序而定）\r#因此，针对向量hypertention进行的任何分析都会将其作为名义型变量对待\rhypertention \u0026lt;- factor(hypertention)\rhypertention\r## [1] yes no no yes\r## Levels: no yes\rstr(hypertention)\r## Factor w/ 2 levels \u0026quot;no\u0026quot;,\u0026quot;yes\u0026quot;: 2 1 1 2\r在R中，因子可以简单地理解为一个附加更多信息的向量。这额外的信息包括向量中不同值的记录，被称为“水平”。\nx \u0026lt;- c(5, 12, 13, 12)\rx \u0026lt;- factor(x)\rx\r## [1] 5 12 13 12\r## Levels: 5 12 13\rstr(x)\r## Factor w/ 3 levels \u0026quot;5\u0026quot;,\u0026quot;12\u0026quot;,\u0026quot;13\u0026quot;: 1 2 3 2\rlength(x)\r## [1] 4\r这个例子中，x中不同数值（5，12，13）就是水平。x的核心是（1，2，3，2），意味着这个数据是由水平1，水平2和水平3的值构成的。因此，数据已经重新编码成水平，当然，水平本身也被记录下来。要注意的是，因子的长度被定义为数据的长度，而不是水平的个数。 要表示有序型变量，需要为factor()指定参数ordered=TRUE。\nseverity \u0026lt;- c(\u0026quot;high\u0026quot;, \u0026quot;middle\u0026quot;, \u0026quot;low\u0026quot;, \u0026quot;middle\u0026quot;)\r#下面这个语句将向量编码为（1,3,2,3），并在内部将这些值关联为1=high，2=low以及3=middle\rseverity \u0026lt;- factor(severity, ordered = TRUE)\rseverity\r## [1] high middle low middle\r## Levels: high \u0026lt; low \u0026lt; middle\rstr(severity)\r## Ord.factor w/ 3 levels \u0026quot;high\u0026quot;\u0026lt;\u0026quot;low\u0026quot;\u0026lt;\u0026quot;middle\u0026quot;: 1 3 2 3\r值得注意的一点是，对于字符型向量，因子的水平默认按字母顺序创建，所以水平“high”，“middle”，“low”的排序与逻辑顺序不一致。 可以通过指定levels选项来覆盖默认排序。\nseverity \u0026lt;- factor(severity, ordered = TRUE, levels = c(\u0026quot;low\u0026quot;, \u0026quot;middle\u0026quot;,\u0026quot;high\u0026quot;))\r这样就会按逻辑顺序排列了。 下面的一段代码将展示因子如何影响数据分析结果：\nIDnumber \u0026lt;- c(101, 102, 103, 104)\rage \u0026lt;- c(24, 78, 56, 45)\rhypertention \u0026lt;- c(\u0026quot;yes\u0026quot;, \u0026quot;no\u0026quot;, \u0026quot;no\u0026quot;, \u0026quot;yes\u0026quot;)\rseverity \u0026lt;- c(\u0026quot;high\u0026quot;, \u0026quot;middle\u0026quot;, \u0026quot;low\u0026quot;, \u0026quot;middle\u0026quot;)\rhypertention \u0026lt;- factor(hypertention)\rseverity \u0026lt;- factor(severity, ordered = TRUE)\rpatientdata \u0026lt;- data.frame(IDnumber, age, hypertention, severity)\rstr(patientdata)\r## \u0026#39;data.frame\u0026#39;: 4 obs. of 4 variables:\r## $ IDnumber : num 101 102 103 104\r## $ age : num 24 78 56 45\r## $ hypertention: Factor w/ 2 levels \u0026quot;no\u0026quot;,\u0026quot;yes\u0026quot;: 2 1 1 2\r## $ severity : Ord.factor w/ 3 levels \u0026quot;high\u0026quot;\u0026lt;\u0026quot;low\u0026quot;\u0026lt;\u0026quot;middle\u0026quot;: 1 3 2 3\rsummary(patientdata)\r## IDnumber age hypertention severity\r## Min. :101.0 Min. :24.00 no :2 high :1 ## 1st Qu.:101.8 1st Qu.:39.75 yes:2 low :1 ## Median :102.5 Median :50.50 middle:2 ## Mean :102.5 Mean :50.75 ## 3rd Qu.:103.2 3rd Qu.:61.50 ## Max. :104.0 Max. :78.00\r嗯~~今天就到这里了。 有点短哈，不过反正也只是给自己看看的，这话说着好心酸啊。 自己学到了就好了。 再练会钢笔字就回寝室。\n","date":1553558400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1553558400,"objectID":"0540d40a57c12b4ae6da791c616034db","permalink":"/post/r%E8%AF%AD%E8%A8%80%E7%BB%9F%E8%AE%A1%E5%88%86%E6%9E%90%E4%B8%8E%E5%BA%94%E7%94%A8-%E7%AC%AC%E4%BA%8C%E7%AB%A0-2/","publishdate":"2019-03-26T00:00:00Z","relpermalink":"/post/r%E8%AF%AD%E8%A8%80%E7%BB%9F%E8%AE%A1%E5%88%86%E6%9E%90%E4%B8%8E%E5%BA%94%E7%94%A8-%E7%AC%AC%E4%BA%8C%E7%AB%A0-2/","section":"post","summary":"Hello，大家好，Dr.二哈又回来了。可能没什么人看，嗯，","tags":["R","统计"],"title":"R语言统计分析与应用-第二章-2","type":"post"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Academic  Academic | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click  PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}   Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions?  Ask\n Documentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":["R","统计"],"content":"\r写在前面的话，R语言统计分析与应用这本书的第一章是讲的怎么下载与安装R，这里就不再赘述了。下面开始第二章。 这本书我决定不再像之前那本书一样，照着书上写，这本书会加入自己的吐槽，只不过在代码上保持一致。 # 第二章 R编程入门 在学习R的时候，总会发现，自己编写一些函数还是比较爽的。在介绍编程之前，首先回顾下R的基础知识。 ## 2.1.1 数据集的概念 这个数据集，对于R语言而言非常重要，在我日常处理的时候，往往因为数据集的问题而导致R报错。看来基础知识还是要掌握地扎实才可以。 1. 向量 这个是R组基础的东西了，是一系列元素的组合，可以存储数值型、字符型或者逻辑型的数据。\n#创建一个向量\r#数值型\ra \u0026lt;- c(1,2,3,4,10,-9,20)\r#字符型\rb \u0026lt;- c(\u0026quot;one\u0026quot;, \u0026quot;two\u0026quot;, \u0026quot;three\u0026quot;)\r#逻辑型\rc \u0026lt;- c(TRUE, FALSE, TRUE, TRUE, FALSE, FALSE)\r#字符型\rd \u0026lt;- c(\u0026quot;a\u0026quot;, \u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;)\r有的时候想查询某个向量中的某个元素，可以这样做：\nd \u0026lt;- c(1,3,5,9,7,10,23,21,17)\r#查询第二个元素\rd[2]\r## [1] 3\r#查询第二到第五个元素\rd[2:5]\r## [1] 3 5 9 7\r#查询某几个元素\rd[c(1,2,6,7)]\r## [1] 1 3 10 23\r矩阵 矩阵就是线性代数里的概念，是个二维数组，每个元素是相同的类型（同为数值、同为字符或者同为逻辑），可通过函数matrix创建。\r\r#创建一个4行，5列的矩阵，数值排列为按列\rx \u0026lt;- matrix(21:40, nrow = 4, ncol = 5, byrow = FALSE)\rx\r## [,1] [,2] [,3] [,4] [,5]\r## [1,] 21 25 29 33 37\r## [2,] 22 26 30 34 38\r## [3,] 23 27 31 35 39\r## [4,] 24 28 32 36 40\r#创建一个含有列名标签的矩阵，并按行排列数值\rfourcell \u0026lt;- c(1,2,3,10,20,30)\rrnames \u0026lt;- c(\u0026quot;R1\u0026quot;, \u0026quot;R2\u0026quot;)\rcnames \u0026lt;- c(\u0026quot;C1\u0026quot;, \u0026quot;C2\u0026quot;, \u0026quot;C3\u0026quot;)\rmymatrix \u0026lt;- matrix(fourcell, nrow = 2, ncol = 3, byrow = TRUE,\rdimnames = list(rnames, cnames))\rmymatrix\r## C1 C2 C3\r## R1 1 2 3\r## R2 10 20 30\r#创建一个含有列名标签的矩阵，并按列排列数值\rmymatrix1 \u0026lt;- matrix(fourcell, nrow = 2, ncol = 3, byrow = FALSE,\rdimnames = list(rnames, cnames))\rmymatrix1\r## C1 C2 C3\r## R1 1 3 20\r## R2 2 10 30\r类似于向量，矩阵也可以用类似的方式查询某行某列的元素。 不过要从向量的一维推广到矩阵的二维。\naa \u0026lt;- matrix(1:20, nrow = 5)\raa\r## [,1] [,2] [,3] [,4]\r## [1,] 1 6 11 16\r## [2,] 2 7 12 17\r## [3,] 3 8 13 18\r## [4,] 4 9 14 19\r## [5,] 5 10 15 20\r#查询第三行\raa[3,]\r## [1] 3 8 13 18\r#查询第三列\raa[,3]\r## [1] 11 12 13 14 15\r#查询第三行的第三、第四列元素\raa[3,c(3,4)]\r## [1] 13 18\r#查询第三行第三列元素\raa[3,3]\r## [1] 13\r#查询第三、第四列元素\raa[,c(3,4)]\r## [,1] [,2]\r## [1,] 11 16\r## [2,] 12 17\r## [3,] 13 18\r## [4,] 14 19\r## [5,] 15 20\r数组 矩阵只能是二维的，这是必须的~，而要创建2维以上的，则要用到数组了创建函数是array(vector, dimensions, dimnames)，其中的参数vector是数组中的数据，dimensions是一个数值型向量，给出了各个维度下标的最大值，而dimnames则是各维度名称的列表。\r\rdim1 \u0026lt;- c(\u0026quot;X1\u0026quot;, \u0026quot;X2\u0026quot;)\rdim2 \u0026lt;- c(\u0026quot;Y1\u0026quot;, \u0026quot;Y2\u0026quot;, \u0026quot;Y3\u0026quot;)\rdim3 \u0026lt;- c(\u0026quot;Z1\u0026quot;, \u0026quot;Z2\u0026quot;, \u0026quot;Z3\u0026quot;, \u0026quot;Z4\u0026quot;)\r#这个数组中c(4,3,2)代表着，与dimnames对应，dim3最多有4个数值，dim2最多有3个数值，dim1最多有2个数值\rxyz \u0026lt;- array(1:24, c(4,3,2), dimnames = list(dim3, dim2, dim1))\rxyz\r## , , X1\r## ## Y1 Y2 Y3\r## Z1 1 5 9\r## Z2 2 6 10\r## Z3 3 7 11\r## Z4 4 8 12\r## ## , , X2\r## ## Y1 Y2 Y3\r## Z1 13 17 21\r## Z2 14 18 22\r## Z3 15 19 23\r## Z4 16 20 24\r数组的查询方式与矩阵类似。为方便理解，将X定义为“长”，Y定义为“宽”，Z则定义为“高”.\n#查询高下标为1，宽下标为2的元素\rxyz[1,2,]\r## X1 X2 ## 5 17\r#查询高下标为1，宽下标为3的元素\rxyz[1,3,]\r## X1 X2 ## 9 21\r#查询宽下标为2，长下标为2的元素\rxyz[,2,2]\r## Z1 Z2 Z3 Z4 ## 17 18 19 20\r#查询高下标为3，宽下标为2，长下标为1的元素\rxyz[3,2,1]\r## [1] 7\r数据框 这个数据框与SPSS中看到的数据集类似。不同的列可以包含不同类型的元素（数值型、字符型等）。这也是R中最常见的数据结构。有些时候，矩阵不够用的情况下，这个数据框就会起很大作用。\r\rIDnumber \u0026lt;- c(101,102,103,104)\rage \u0026lt;- c(24,78,56,45)\rhypertention \u0026lt;- c(\u0026quot;yes\u0026quot;, \u0026quot;no\u0026quot;, \u0026quot;no\u0026quot;, \u0026quot;yes\u0026quot;)\rseverity \u0026lt;- c(\u0026quot;high\u0026quot;, \u0026quot;middle\u0026quot;, \u0026quot;low\u0026quot;, \u0026quot;middle\u0026quot;)\rpatientdata \u0026lt;- data.frame(IDnumber, age, hypertention, severity)\rpatientdata\r## IDnumber age hypertention severity\r## 1 101 24 yes high\r## 2 102 78 no middle\r## 3 103 56 no low\r## 4 104 45 yes middle\r在数据框中选取元素可以用很多种方式，既可以用矩阵、数组的下标方法，也可以直接指定列名。\n#查询第一列也就是IDnumber\rpatientdata[1]\r## IDnumber\r## 1 101\r## 2 102\r## 3 103\r## 4 104\r#查询第一列以及第二列，也就是IDnumber和age\rpatientdata[1:2]\r## IDnumber age\r## 1 101 24\r## 2 102 78\r## 3 103 56\r## 4 104 45\r#查询age这一列\rpatientdata[\u0026quot;age\u0026quot;]\r## age\r## 1 24\r## 2 78\r## 3 56\r## 4 45\r#查询age和severity\rpatientdata[\u0026quot;age\u0026quot;, \u0026quot;sverity\u0026quot;]\r## NULL\r#查询age中的元素\rpatientdata$age\r## [1] 24 78 56 45\r这个“$”符号是比较常用的使用方法，它被用来选取一个给定数据框的某个特定变量。也可以联合使用attach()和detach()函数，或者单独使用with()函数来简化代码……\n书上是这么说的，但我觉得，“$”这个符号在日后阅读代码时比较好理解。\nattach()函数可以将数据框添加到R的搜索路径中。而detach()函数将数据框从搜索路径中移除。下面的代码获取年龄（age）变量的描述性统计，并分别绘制age变量与收缩压（hypertention）的散点图。\nsystolic \u0026lt;- c(120,130,140,150,160)\rage \u0026lt;- c(20,30,40,50,55)\rhypertention \u0026lt;- data.frame(systolic, age)\rhypertention\r## systolic age\r## 1 120 20\r## 2 130 30\r## 3 140 40\r## 4 150 50\r## 5 160 55\rsummary(hypertention$age)\r## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 20 30 40 39 50 55\rsummary(hypertention$systolic)\r## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 120 130 140 140 150 160\rplot(hypertention$age, hypertention$systolic)\r#上面代码也可以简化为\rattach(hypertention)\r## The following objects are masked _by_ .GlobalEnv:\r## ## age, systolic\rsummary(age)\r## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 20 30 40 39 50 55\rsummary(systolic)\r## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 120 130 140 140 150 160\rplot(systolic, age)\rdetach(hypertention)\r#或者\rwith(hypertention,{\rsummary(age)\rsummary(systolic)\rplot(systolic, age)\r})\r但是with()函数有一个特殊情况需要注意，如果出现with()里要对某个不在原数据框中的变量赋值，那这个变量若不注意赋值格式，则会出现下面的问题。\nwith(hypertention, {\rstat \u0026lt;- summary(age)\rstat\r})\r## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 20 30 40 39 50 55\r#这个时候如果输入stat，则会出现“找不到对象‘stat’”\r这个问题就出在赋值符号\u0026lt;-上，如果要创建在with()结构以外存在的对象，则要用“\u0026lt;\u0026lt;-”符号代替“\u0026lt;-”。这样，这个对象就可以保存在with()之外的全局环境中。\nwith(hypertention, {\rstat \u0026lt;\u0026lt;- summary(age)\r})\r#这个时候stat就成为全局变量了\rstat\r## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 20 30 40 39 50 55\r","date":1543795200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1543795200,"objectID":"8ca50e9bf65d9e9615b3c28ae163202e","permalink":"/post/r%E8%AF%AD%E8%A8%80%E7%BB%9F%E8%AE%A1%E5%88%86%E6%9E%90%E4%B8%8E%E5%BA%94%E7%94%A8-%E7%AC%AC%E4%BA%8C%E7%AB%A0-1/","publishdate":"2018-12-03T00:00:00Z","relpermalink":"/post/r%E8%AF%AD%E8%A8%80%E7%BB%9F%E8%AE%A1%E5%88%86%E6%9E%90%E4%B8%8E%E5%BA%94%E7%94%A8-%E7%AC%AC%E4%BA%8C%E7%AB%A0-1/","section":"post","summary":"写在前面的话，R语言统计分析与应用这本书的第一章是讲的怎么下","tags":["R","统计"],"title":"R语言统计分析与应用-第二章-1","type":"post"},{"authors":null,"categories":[],"content":"\r如题，开个新书，R语言统计分析与应用。之前那个书感觉开不下去了~\n","date":1543795200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1543795200,"objectID":"e5e313b804cd5221c19e8ac6121e5d87","permalink":"/post/%E5%BC%80%E6%96%B0%E4%B9%A6%E5%95%A6/","publishdate":"2018-12-03T00:00:00Z","relpermalink":"/post/%E5%BC%80%E6%96%B0%E4%B9%A6%E5%95%A6/","section":"post","summary":"如题，开个新书，R语言统计分析与应用。之前那个书感觉开不下去","tags":["杂"],"title":"开新书啦","type":"post"},{"authors":null,"categories":["R"],"content":"这几天忙着做实验的同时还再帮某兄弟解决作图，这兄弟想做个热图，我就用pheatmap给他做，结果做完了发现，诶？尼玛，这横轴标签怎么是垂直的，于是又找解决方法，终于找到了一个。 上代码。\n#创建数据\rtest = matrix(rnorm(200), 20, 10)\rtest[1:10, seq(1, 10, 2)] = test[1:10, seq(1, 10, 2)] + 3\rtest[11:20, seq(2, 10, 2)] = test[11:20, seq(2, 10, 2)] + 2\rtest[15:20, seq(2, 10, 2)] = test[15:20, seq(2, 10, 2)] + 4\rcolnames(test) = paste(\u0026quot;Test\u0026quot;, 1:10, sep = \u0026quot;\u0026quot;)\rrownames(test) = paste(\u0026quot;Gene\u0026quot;, 1:20, sep = \u0026quot;\u0026quot;)\rhead(test)\r ## Test1 Test2 Test3 Test4 Test5 Test6 Test7\r## Gene1 3.478948 -1.3189620 2.022492 -1.8908125 3.063350 0.6009318 4.317662\r## Gene2 4.354549 0.5188468 4.367425 -0.5386495 1.355116 1.5142165 4.480402\r## Gene3 4.192323 -1.0382861 3.509188 0.8541905 3.635153 0.4159976 3.793672\r## Gene4 3.353073 0.2624581 3.759387 0.5848898 3.004100 -0.4968918 1.091723\r## Gene5 3.129363 -0.9422255 4.558563 0.7275991 2.571372 -1.4574945 3.016973\r## Gene6 3.206768 -1.6356026 2.877822 -0.6683236 3.490102 -1.7531713 2.106235\r## Test8 Test9 Test10\r## Gene1 1.83005199 2.235624 -1.3683971\r## Gene2 0.38677603 3.843029 -1.0146326\r## Gene3 -1.66711704 1.493430 -0.4044687\r## Gene4 0.02498933 1.995961 1.8579663\r## Gene5 -0.60796743 1.950566 0.6641153\r## Gene6 1.21738912 2.711145 -2.3203194\r library(pheatmap)\rlibrary(vegan)\r ## 载入需要的程辑包：permute\r ## 载入需要的程辑包：lattice\r ## This is vegan 2.5-2\r library(permute)\rlibrary(lattice)\rpheatmap(test)\r #看到没有，图下面的Test1-10字样都是垂直的\r#要想修改，就要改pheatmap包里面的东西\r#修改pheatmap:::draw_colnames什么的\r#先载入grid包\rlibrary(grid)\rdraw_colnames_45 \u0026lt;- function (coln, ...) {\rm = length(coln)\rx = (1:m)/m - 1/2/m\rgrid.text(coln, x = x, y = unit(0.96, \u0026quot;npc\u0026quot;), vjust = .5, hjust = 1, rot = 45, gp = gpar(...)) ## 注意缺省值为 'hjust=0' 和'rot=270'\r}\r#然后将default draw_colnames覆盖\rassignInNamespace(x=\u0026quot;draw_colnames\u0026quot;, value=\u0026quot;draw_colnames_45\u0026quot;,\rns=asNamespace(\u0026quot;pheatmap\u0026quot;))\r#再作图，这回就妥了\rpheatmap(test)\r #可以美化下……额，这个美化不好~将就看吧\rpheatmap(test, color = colorRampPalette(c(\u0026quot;pink\u0026quot;, \u0026quot;white\u0026quot;, \u0026quot;red\u0026quot;))(100),\rscale = \u0026quot;none\u0026quot;, legend = TRUE, border_color = \u0026quot;black\u0026quot;,\rtreeheight_row = 80, treeheight_col = 80\r)\r #另外，输出图片可以用tiff(),png()等命令，这样可以调整分辨率\r#不过建议用tiff()命令\r#注意命令顺序，如下\rtiff(\u0026quot;test1.tiff\u0026quot;, units=\u0026quot;in\u0026quot;, width=9, height=6,\rres=300) ##res设置的是分辨率)\rpheatmap(test, color = colorRampPalette(c(\u0026quot;pink\u0026quot;, \u0026quot;white\u0026quot;, \u0026quot;red\u0026quot;))(100),\rscale = \u0026quot;none\u0026quot;, legend = TRUE, border_color = \u0026quot;black\u0026quot;,\rtreeheight_row = 80, treeheight_col = 80\r)\rdev.off()\r ## tiff ## 3\r 备注一下，方法来源于网页https://stackoverflow.com/questions/15505607/diagonal-labels-orientation-on-x-axis-in-heatmaps 另外可以看下其他的绘制热图的代码。\n#载入所需包\rlibrary(ggplot2)\rlibrary(gplots)\r ## ## 载入程辑包：'gplots'\r ## The following object is masked from 'package:stats':\r## ## lowess\r #最简单的热图\rheatmap(test, scale = \u0026quot;none\u0026quot;)\r #而下面这个出现color key，并且横坐标字体变小，其他与上面一致\rheatmap.2(test, scale = \u0026quot;none\u0026quot;, trace = \u0026quot;none\u0026quot;, key = TRUE, symkey = FALSE,\rdensity.info = \u0026quot;none\u0026quot;, margins = c(4, 8),\rcexRow = 1, cexCol = 1)\r 这几个程序啥的，我还是喜欢pheatmap，尽管微调美化上有点难度~~~\n","date":1540684800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1540684800,"objectID":"0febf2b06cc01fb69fcb98a39f779df5","permalink":"/post/%E5%85%B3%E4%BA%8Epheatmap%E7%BB%98%E5%88%B6%E7%83%AD%E5%9B%BE%E6%A8%AA%E8%BD%B4%E6%A0%87%E7%AD%BE%E5%80%BE%E6%96%9C%E4%BB%A5%E5%8F%8A%E5%87%A0%E4%B8%AA%E7%83%AD%E5%9B%BE%E4%BB%A3%E7%A0%81/","publishdate":"2018-10-28T00:00:00Z","relpermalink":"/post/%E5%85%B3%E4%BA%8Epheatmap%E7%BB%98%E5%88%B6%E7%83%AD%E5%9B%BE%E6%A8%AA%E8%BD%B4%E6%A0%87%E7%AD%BE%E5%80%BE%E6%96%9C%E4%BB%A5%E5%8F%8A%E5%87%A0%E4%B8%AA%E7%83%AD%E5%9B%BE%E4%BB%A3%E7%A0%81/","section":"post","summary":"这几天忙着做实验的同时还再帮某兄弟解决作图，这兄弟想做个热图","tags":["R"],"title":"关于pheatmap绘制热图横轴标签倾斜以及几个热图代码","type":"post"},{"authors":null,"categories":["R","统计"],"content":"\r第十一章 多元回归\r终于到了在统计中最常见的多元回归了~这本书之前都在讲什么\n首先介绍下多元回归的基本模型： \\[\ry=\\beta_0+\\beta_1x_1+\\cdot\\cdot\\cdot+\\beta_kx_k+\\epsilon\r\\] 其中，\\(x_1,...,x_k\\)等是解释变量（也叫作预测变量）；模型参数\\(\\beta_1,...,\\beta_k\\)可通过最小二乘法估计得出（具体参见6.1节）。\n11.1 多维数据绘图\r下面以Altman（1991）提到的一个关于囊胞性纤维症患者肺功能的研究为例子。数据包含在ISwR包内的cystfibr数据框中。\n使用pairs函数可以绘制数据集中任意两个变量间的散点图：\nlibrary(ISwR)\rpar(mex = 0.5)\rpairs(cystfibr, gap = 0, cex.labels = 0.9)\r在这个代码中，参数gap和cex.lables用来控制图形的外观。前者用来移除各个子图之间的图间距，后者用来缩放图中的字号，而绘图命令mex则用来减少图形边界的行间距。\n用plot命令也能做出类似的图：\nplot(cystfibr)\r用pairs命令得到的那个图，各个子图相对较小，不适合直接放在论文中。不过，这种图形可以清晰的看到多维数据的整体情况，比如，就可以看到age、height和weight具有强相关关系。\n为了便于直接引用cystfibr数据集中的变量。可以将该数据集加入到当前的搜索路径中：\nattach(cystfibr)\r## The following object is masked from package:ISwR:\r## ## tlc\r\r11.2 模型设定和模型输出\r多元回归分析的模型是通过在模型公式中的解释变量（~应该就是自变量）之间添加+号来实现：\n#注意一点，在之前分工作目录中可能会存在名称相同的变量，比如age这个变量，因此在运行这个命令前，需要清空工作目录。\rlm(pemax~age+sex+height+weight+bmp+fev1+rv+frc+tlc)\r## ## Call:\r## lm(formula = pemax ~ age + sex + height + weight + bmp + fev1 + ## rv + frc + tlc)\r## ## Coefficients:\r## (Intercept) age sex height weight ## 176.0582 -2.5420 -3.7368 -0.4463 2.9928 ## bmp fev1 rv frc tlc ## -1.7449 1.0807 0.1970 -0.3084 0.1886\r这个公式意思就是，pemax这个变量可由一个包含变量age、sex等组成的模型来描述（pemax是患者的最大呼气压力）。\n与前面一样，lm函数返回的结果有限，然而，借助summary函数可以得到更多有趣的结果：\nsummary(lm(pemax~age+sex+height+weight+bmp+fev1+rv+frc+tlc))\r## ## Call:\r## lm(formula = pemax ~ age + sex + height + weight + bmp + fev1 + ## rv + frc + tlc)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -37.338 -11.532 1.081 13.386 33.405 ## ## Coefficients:\r## Estimate Std. Error t value Pr(\u0026gt;|t|)\r## (Intercept) 176.0582 225.8912 0.779 0.448\r## age -2.5420 4.8017 -0.529 0.604\r## sex -3.7368 15.4598 -0.242 0.812\r## height -0.4463 0.9034 -0.494 0.628\r## weight 2.9928 2.0080 1.490 0.157\r## bmp -1.7449 1.1552 -1.510 0.152\r## fev1 1.0807 1.0809 1.000 0.333\r## rv 0.1970 0.1962 1.004 0.331\r## frc -0.3084 0.4924 -0.626 0.540\r## tlc 0.1886 0.4997 0.377 0.711\r## ## Residual standard error: 25.47 on 15 degrees of freedom\r## Multiple R-squared: 0.6373, Adjusted R-squared: 0.4197 ## F-statistic: 2.929 on 9 and 15 DF, p-value: 0.03195\r注意，这个结果表明所有变量对应的 t 值都不显著，但是，联合 F 检验的结果却是显著的，这一定是有原因的。\n这个原因就在于，t 检验说明的是仅仅是，当从模型中删除某个变量而保留其他变量时模型的变化结果；对于变量在简化模型中是否统计显著，则没有做出说明；值得注意的是，t 检验认为没有一个变量是不能从模型中删除的。\n注意，输出结果中未调整R2（Multiple R-squared）和调整后R2（Adjusted R-squared）有较大差异，这归咎于模型中较多的变量个数，而这个与方差的自由度密切相关。前者表示的是与空模型相对的残差平方和的变化，后者对应的是残差方差的类似变化：\n1-25.5^2/var(pemax)\r## [1] 0.4183949\r其中，25.5这个数字取自summary函数输出结果中的残差标准误（Residual standard error）。通过anova函数可以得到多元回归分析对应的方差分析表，该表给出了一个截然不同的模型结果：\nanova(lm(pemax~age+sex+height+weight+bmp+fev1+rv+frc+tlc))\r## Analysis of Variance Table\r## ## Response: pemax\r## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## age 1 10098.5 10098.5 15.5661 0.001296 **\r## sex 1 955.4 955.4 1.4727 0.243680 ## height 1 155.0 155.0 0.2389 0.632089 ## weight 1 632.3 632.3 0.9747 0.339170 ## bmp 1 2862.2 2862.2 4.4119 0.053010 . ## fev1 1 1549.1 1549.1 2.3878 0.143120 ## rv 1 561.9 561.9 0.8662 0.366757 ## frc 1 194.6 194.6 0.2999 0.592007 ## tlc 1 92.4 92.4 0.1424 0.711160 ## Residuals 15 9731.2 648.7 ## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\r注意，除了最后一行（对应于变量tlc）之外，这里的 F 检验结果与summary函数输出的 t 检验结果几乎完全相悖。这里，age变量的检验结果变得显著了，导致这种结果的原因在于这里的检验过程是逐步进行的；具体而言，对应于（从下至上）将变量逐个从模型中移除，直至剩下age变量。在该过程中，变量bmp的检验结果一度接近5%的临界点，但考虑到检验的个数，这一结果几乎不显著。\n在8次独立的检验中，结果给出小于等于0.053的 p 值的概率仅仅略高于35%。虽然ANOVA表中的检验并非完全独立，但是其近似结果还是不错的。\nANOVA表的输出结果表明在模型已包含age变量的情况下，再添加其他变量，模型准确度并未得到显著的提高。可以进行联合检验，看看是否可以将age以外的变量全部去掉，做法是求贡献值的平方和加，再对总和进行 F 检验：\n955.4+155.0+632.3+2862.2+1549.1+561.9+194.6+92.4\r## [1] 7002.9\r7002.9/8\r## [1] 875.3625\r875.36/648.7\r## [1] 1.349407\r1-pf(1.349407, 8,15)\r## [1] 0.2935148\r对应于去掉边框线的表格，它看起来是这样的：\n\r\r\rDf\rSum Sq\rMean Sq\rF\rPr(\u0026gt;F)\r\r\r\rage\r1\r10098.5\r10098.5\r15.566\r0.00130\r\rothers\r8\r7002.9\r875.4\r1.349\r0.29351\r\rResidual\r15\r9731.2\r648.7\r\r\r\r\r\r这个表格是自己根据数据整理的~不是系统的输出。\n如要直接得到上述结果，可运行：\nm1 \u0026lt;- lm(pemax~age+sex+height+weight+bmp+fev1+rv+frc+tlc)\rm2 \u0026lt;- lm(pemax~age)\ranova(m1, m2)\r## Analysis of Variance Table\r## ## Model 1: pemax ~ age + sex + height + weight + bmp + fev1 + rv + frc + ## tlc\r## Model 2: pemax ~ age\r## Res.Df RSS Df Sum of Sq F Pr(\u0026gt;F)\r## 1 15 9731.2 ## 2 23 16734.2 -8 -7002.9 1.3493 0.2936\r\r11.3 模型筛选\rR有一个按照赤池信息准则（Akaike Information Criterion）进行模型筛选的函数step()。而这个本书不讲~~\n本书只使用一种较为简单的人工向后消元法。\n下面是一个模型降阶的例子，注意，为减少输出结果占用的空间，对输出信息进行了编辑：\n#书上是只保留了Coefficients这一项\rsummary(lm(pemax~age+sex+height+weight+bmp+fev1+rv+frc+tlc))\r## ## Call:\r## lm(formula = pemax ~ age + sex + height + weight + bmp + fev1 + ## rv + frc + tlc)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -37.338 -11.532 1.081 13.386 33.405 ## ## Coefficients:\r## Estimate Std. Error t value Pr(\u0026gt;|t|)\r## (Intercept) 176.0582 225.8912 0.779 0.448\r## age -2.5420 4.8017 -0.529 0.604\r## sex -3.7368 15.4598 -0.242 0.812\r## height -0.4463 0.9034 -0.494 0.628\r## weight 2.9928 2.0080 1.490 0.157\r## bmp -1.7449 1.1552 -1.510 0.152\r## fev1 1.0807 1.0809 1.000 0.333\r## rv 0.1970 0.1962 1.004 0.331\r## frc -0.3084 0.4924 -0.626 0.540\r## tlc 0.1886 0.4997 0.377 0.711\r## ## Residual standard error: 25.47 on 15 degrees of freedom\r## Multiple R-squared: 0.6373, Adjusted R-squared: 0.4197 ## F-statistic: 2.929 on 9 and 15 DF, p-value: 0.03195\r人工进行模型降阶的优点在于该模型引入逻辑结构。在本利中，很自然地会先想到去掉肺功能的指标。\nsummary(lm(pemax~age+sex+height+weight+bmp+fev1+rv+frc))\r## ## Call:\r## lm(formula = pemax ~ age + sex + height + weight + bmp + fev1 + ## rv + frc)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -38.072 -10.067 0.113 13.526 36.990 ## ## Coefficients:\r## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 221.8055 185.4350 1.196 0.2491 ## age -3.1346 4.4144 -0.710 0.4879 ## sex -4.6933 14.8363 -0.316 0.7558 ## height -0.5428 0.8428 -0.644 0.5286 ## weight 3.3157 1.7672 1.876 0.0790 .\r## bmp -1.9403 1.0047 -1.931 0.0714 .\r## fev1 1.0183 1.0392 0.980 0.3417 ## rv 0.1857 0.1887 0.984 0.3396 ## frc -0.2605 0.4628 -0.563 0.5813 ## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\r## ## Residual standard error: 24.78 on 16 degrees of freedom\r## Multiple R-squared: 0.6339, Adjusted R-squared: 0.4508 ## F-statistic: 3.463 on 8 and 16 DF, p-value: 0.01649\rsummary(lm(pemax~age+sex+height+weight+bmp+fev1+rv))\r## ## Call:\r## lm(formula = pemax ~ age + sex + height + weight + bmp + fev1 + ## rv)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -39.425 -12.391 3.834 14.797 36.693 ## ## Coefficients:\r## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 166.71822 154.31294 1.080 0.2951 ## age -1.81783 3.66773 -0.496 0.6265 ## sex 0.10239 11.89990 0.009 0.9932 ## height -0.40981 0.79257 -0.517 0.6118 ## weight 2.87386 1.55120 1.853 0.0814 .\r## bmp -1.94971 0.98415 -1.981 0.0640 .\r## fev1 1.41526 0.74788 1.892 0.0756 .\r## rv 0.09567 0.09798 0.976 0.3425 ## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\r## ## Residual standard error: 24.28 on 17 degrees of freedom\r## Multiple R-squared: 0.6266, Adjusted R-squared: 0.4729 ## F-statistic: 4.076 on 7 and 17 DF, p-value: 0.008452\rsummary(lm(pemax~age+sex+height+weight+bmp+fev1))\r## ## Call:\r## lm(formula = pemax ~ age + sex + height + weight + bmp + fev1)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -43.238 -7.403 -0.081 15.534 36.028 ## ## Coefficients:\r## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 260.6313 120.5215 2.163 0.0443 *\r## age -2.9062 3.4898 -0.833 0.4159 ## sex -1.2115 11.8083 -0.103 0.9194 ## height -0.6067 0.7655 -0.793 0.4384 ## weight 3.3463 1.4719 2.273 0.0355 *\r## bmp -2.3042 0.9136 -2.522 0.0213 *\r## fev1 1.0274 0.6329 1.623 0.1219 ## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\r## ## Residual standard error: 24.24 on 18 degrees of freedom\r## Multiple R-squared: 0.6057, Adjusted R-squared: 0.4743 ## F-statistic: 4.608 on 6 and 18 DF, p-value: 0.00529\rsummary(lm(pemax~age+sex+height+weight+bmp))\r## ## Call:\r## lm(formula = pemax ~ age + sex + height + weight + bmp)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -43.194 -9.412 -2.425 9.157 40.112 ## ## Coefficients:\r## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 280.4482 124.9556 2.244 0.0369 *\r## age -3.0750 3.6352 -0.846 0.4081 ## sex -11.5281 10.3720 -1.111 0.2802 ## height -0.6853 0.7962 -0.861 0.4001 ## weight 3.5546 1.5281 2.326 0.0312 *\r## bmp -1.9613 0.9263 -2.117 0.0476 *\r## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\r## ## Residual standard error: 25.27 on 19 degrees of freedom\r## Multiple R-squared: 0.548, Adjusted R-squared: 0.429 ## F-statistic: 4.606 on 5 and 19 DF, p-value: 0.006388\r上上述结果看，去掉4个肺功能相关的变量没什么不妥，接下来尝试删除那些描述病人身体发育状态或尺寸信息的变量。在开始时，尽量避免删除weight和bmp变量，因为它们对应的 p 值很接近5%的显著性界限。\nsummary(lm(pemax~age+height+weight+bmp))\r## ## Call:\r## lm(formula = pemax ~ age + height + weight + bmp)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -41.501 -15.460 -2.838 11.082 42.991 ## ## Coefficients:\r## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 274.5307 125.5745 2.186 0.0409 *\r## age -3.0832 3.6566 -0.843 0.4091 ## height -0.6985 0.8008 -0.872 0.3934 ## weight 3.6338 1.5354 2.367 0.0282 *\r## bmp -1.9621 0.9317 -2.106 0.0480 *\r## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\r## ## Residual standard error: 25.41 on 20 degrees of freedom\r## Multiple R-squared: 0.5186, Adjusted R-squared: 0.4223 ## F-statistic: 5.386 on 4 and 20 DF, p-value: 0.004137\rsummary(lm(pemax~height+weight+bmp))\r## ## Call:\r## lm(formula = pemax ~ height + weight + bmp)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -41.794 -11.764 -1.218 13.202 43.631 ## ## Coefficients:\r## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 245.3936 119.8927 2.047 0.0534 .\r## height -0.8264 0.7808 -1.058 0.3019 ## weight 2.7717 1.1377 2.436 0.0238 *\r## bmp -1.4876 0.7375 -2.017 0.0566 .\r## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\r## ## Residual standard error: 25.24 on 21 degrees of freedom\r## Multiple R-squared: 0.5015, Adjusted R-squared: 0.4302 ## F-statistic: 7.041 on 3 and 21 DF, p-value: 0.00187\rsummary(lm(pemax~weight+bmp))\r## ## Call:\r## lm(formula = pemax ~ weight + bmp)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -42.924 -13.399 4.361 16.642 48.404 ## ## Coefficients:\r## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 124.8297 37.4786 3.331 0.003033 ** ## weight 1.6403 0.3900 4.206 0.000365 ***\r## bmp -1.0054 0.5814 -1.729 0.097797 . ## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\r## ## Residual standard error: 25.31 on 22 degrees of freedom\r## Multiple R-squared: 0.4749, Adjusted R-squared: 0.4271 ## F-statistic: 9.947 on 2 and 22 DF, p-value: 0.0008374\rsummary(lm(pemax~weight))\r## ## Call:\r## lm(formula = pemax ~ weight)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -44.30 -22.69 2.23 15.91 48.41 ## ## Coefficients:\r## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 63.5456 12.7016 5.003 4.63e-05 ***\r## weight 1.1867 0.3009 3.944 0.000646 ***\r## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\r## ## Residual standard error: 26.38 on 23 degrees of freedom\r## Multiple R-squared: 0.4035, Adjusted R-squared: 0.3776 ## F-statistic: 15.56 on 1 and 23 DF, p-value: 0.0006457\r注意，一旦删除age和height变量，变量bmp就不再显著了。在原文献（Altman，1991）中，变量weight、feval和bmp在最终结果中对应的 p值都低于5%。然而，并非所有模型降阶过程都是如此。\n特别关注变量age、weight和height是个不错的想法，因为在处理儿童和青少年对应的数据时，这些变量表现出很强的相关性。\nsummary(lm(pemax~age+height+weight))\r## ## Call:\r## lm(formula = pemax ~ age + height + weight)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -43.675 -21.566 3.229 16.274 48.068 ## ## Coefficients:\r## Estimate Std. Error t value Pr(\u0026gt;|t|)\r## (Intercept) 64.65555 82.40935 0.785 0.441\r## age 1.56755 3.14363 0.499 0.623\r## height -0.07608 0.80278 -0.095 0.925\r## weight 0.86949 0.85922 1.012 0.323\r## ## Residual standard error: 27.41 on 21 degrees of freedom\r## Multiple R-squared: 0.4118, Adjusted R-squared: 0.3278 ## F-statistic: 4.901 on 3 and 21 DF, p-value: 0.009776\rsummary(lm(pemax~age+height))\r## ## Call:\r## lm(formula = pemax ~ age + height)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -44.817 -17.883 3.815 18.275 53.824 ## ## Coefficients:\r## Estimate Std. Error t value Pr(\u0026gt;|t|)\r## (Intercept) 17.8600 68.2493 0.262 0.796\r## age 2.7178 2.9325 0.927 0.364\r## height 0.3397 0.6900 0.492 0.627\r## ## Residual standard error: 27.43 on 22 degrees of freedom\r## Multiple R-squared: 0.3831, Adjusted R-squared: 0.3271 ## F-statistic: 6.832 on 2 and 22 DF, p-value: 0.00492\rsummary(lm(pemax~age))\r## ## Call:\r## lm(formula = pemax ~ age)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -48.666 -17.174 6.209 16.209 51.334 ## ## Coefficients:\r## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 50.408 16.657 3.026 0.00601 **\r## age 4.055 1.088 3.726 0.00111 **\r## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\r## ## Residual standard error: 26.97 on 23 degrees of freedom\r## Multiple R-squared: 0.3764, Adjusted R-squared: 0.3492 ## F-statistic: 13.88 on 1 and 23 DF, p-value: 0.001109\rsummary(lm(pemax~height))\r## ## Call:\r## lm(formula = pemax ~ height)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -43.876 -19.306 1.787 18.170 61.464 ## ## Coefficients:\r## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) -33.2757 40.0445 -0.831 0.41453 ## height 0.9319 0.2596 3.590 0.00155 **\r## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\r## ## Residual standard error: 27.34 on 23 degrees of freedom\r## Multiple R-squared: 0.3591, Adjusted R-squared: 0.3312 ## F-statistic: 12.89 on 1 and 23 DF, p-value: 0.001549\r从上面的结果可以看出，对于变量weight、height和age，没有证据表明哪个比另外两个好。上面所用的消元方法之所以在最后仅留下了weight作为自变量，完全是出于偶然。\n\r练习题\r在数据集secher中，对出生体重、腰围和二项骨的直径变量进行对数变换后可得到很好的数据分析结果。请拟合出生体重的预测表达式。在模型中同时纳入腹部直径和二项骨直径时，模型结果如何，模型中两个回归系数之和约为3，如何对其进行解释。\r数据集tlc有一个同名变量tlc，这不是一个很好的命名方式，请解释原因。用数据集中的其余变量来解释tlc变量，并对模型的有效性进行解释。\r数据集cystfibr的分析过程设计sex变量，它是一个二元变量，如何解释回归结果中对应的系数。\r考虑juul2数据集，并筛选出该数据集中年龄超过25岁的子集，用age变量对\\(\\sqrt{igfl}\\)变量进行回归分析。在扩展模型中加入变量height和变量weight，计算扩展模型对应的方差分析表，有没有意想不到的结果出现，为什么会这样呢。\r使用多远回归模型，分析冰结师kfmdata数据集中各个解释变量对牛奶摄入量的影响。注意，这里的sex变量是因子型变量，这对分析过程有什么影响？\r\r\r\r","date":1536537600,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1536537600,"objectID":"3588624af9f91bbcee51ed32e9dc638c","permalink":"/post/r%E8%AF%AD%E8%A8%80%E7%BB%9F%E8%AE%A1%E5%85%A5%E9%97%A8-%E7%AC%AC%E5%8D%81%E4%B8%80%E7%AB%A0/","publishdate":"2018-09-10T00:00:00Z","relpermalink":"/post/r%E8%AF%AD%E8%A8%80%E7%BB%9F%E8%AE%A1%E5%85%A5%E9%97%A8-%E7%AC%AC%E5%8D%81%E4%B8%80%E7%AB%A0/","section":"post","summary":"第十一章 多元回归 终于到了在统计中最常见的多元回归了~这本书之","tags":["R","统计"],"title":"R语言统计入门-第十一章","type":"post"},{"authors":null,"categories":["R","统计"],"content":"\r第十章 数据处理的高级技术\r10.1 变量的重编码\r10.1.1 cut函数\r有的时候可能需要将一个变量转换成一个分组因子。比如将数据分成5个年龄组进行展示，但是数据集中的年龄是一个定量变量，该变量的值对应的记录单位是整数年或者更细分的时间单位。这个时候就需要cut函数了。\n这个函数有两个基本参数：一个数值向量和一个节点向量。后者的作用是定义一系列数据区间以对变量进行分组。对于每一个区间，都得指定左右两个端点值——也就是说，节点的数目必须等于所有区间数目再加一。一个常见的错误是认为数据区间最外层的节点可以省略及所有区间外的点会被设定为NA。最外层的节点值可用-Inf和Inf来表示。\n默认情况下，数据区间是左开右闭的。也就是说，每个区间都包括右节点。除非设置include.lowest=TRUE使第一个区间成为闭区间，否则，第一个区间不会包含最小节点。\n在流行病学领域，人们可能更多地按照“40-49岁”这种年龄区间来对数据进行分组。这种与默认区间闭合方向相反的分组方式可以通过设置right=FALSE来得到。\n当然，当使用左闭右开类型的区间时，丢失最外区间端点的问题就转移到了最大节点那一端。此时，设定include.lowest事实上将使最大节点值包含到区间里面来。在下面的例子中，区别就在于区间结果是否包含两个年龄刚好16岁的样本。\nlibrary(ISwR)\rage \u0026lt;- subset(juul, age \u0026gt;= 10 \u0026amp; age \u0026lt;=16)$age\rrange(age)\r## [1] 10.01 16.00\ragegr \u0026lt;- cut(age, seq(10, 16, 2),right = F, include.lowest = T)\rlength(age)\r## [1] 502\rtable(agegr)\r## agegr\r## [10,12) [12,14) [14,16] ## 190 168 144\ragegr2 \u0026lt;- cut(age, seq(10, 16, 2), right = F)\rtable(agegr2)\r## agegr2\r## [10,12) [12,14) [14,16) ## 190 168 142\r有时候想要把数据进行等距分组。此时，可用4.1节中介绍过的quantile函数来生成区间节点。比如，可以运行如下的代码：\nq \u0026lt;- quantile(age, c(0, 0.25, 0.50, 0.75, 1))\rq\r## 0% 25% 50% 75% 100% ## 10.0100 11.3825 12.6400 14.2275 16.0000\rageQ \u0026lt;- cut(age, q, include.lowest = T)\rtable(ageQ)\r## ageQ\r## [10,11.4] (11.4,12.6] (12.6,14.2] (14.2,16] ## 126 125 125 126\r有时，cut函数返回的水平名字非常难看。好在可以方便地对其进行调整。如下：\nlevels(ageQ) \u0026lt;- c(\u0026quot;1st\u0026quot;, \u0026quot;2nd\u0026quot;, \u0026quot;3rd\u0026quot;, \u0026quot;4th\u0026quot;)\rlevels(agegr) \u0026lt;- c(\u0026quot;10-11\u0026quot;, \u0026quot;12-13\u0026quot;, \u0026quot;14-15\u0026quot;)\rtable(ageQ)\r## ageQ\r## 1st 2nd 3rd 4th ## 126 125 125 126\rtable(agegr)\r## agegr\r## 10-11 12-13 14-15 ## 190 168 144\r附：Hmisc包中有一个cut2函数，该函数能对上述操作进行简化。\n\r10.1.2 处理因子\r在1.2.8节中，使用levels \u0026lt;-…… 来改变因子的因子水平集合。\n本小节将继续讨论一些相关内容。\n首先，要注意到，将数值输入转化为因子以及对因子水平进行重命名的操作可以进一步完成：\npain \u0026lt;- c(0, 3, 2, 2, 1)\rfpain \u0026lt;- factor(pain, levels = 0:3, labels = c(\u0026quot;none\u0026quot;, \u0026quot;mild\u0026quot;, \u0026quot;medium\u0026quot;, \u0026quot;severe\u0026quot;))\r注意levels与labels之间的区别。后者指的是输出结果的因子水平，而前者对应的是对输入向量的编码（这里对应的是变量pain）。更准确地说，levels指代的是函数输入，而lables指代的是函数的输出。\n若未指明levels参数，函数会将向量中出现的剔除重复项的值排序后作为因子水平。这种操作有时不尽人意，比如，对于文本型变量，系统默认按照“字典顺序”对其进行排序。考虑下面的例子：\ntext.pain \u0026lt;- c(\u0026quot;none\u0026quot;, \u0026quot;severe\u0026quot;, \u0026quot;medium\u0026quot;, \u0026quot;medium\u0026quot;, \u0026quot;mild\u0026quot;)\rfactor(text.pain)\r## [1] none severe medium medium mild ## Levels: medium mild none severe\rfactor函数把因子当做字符型向量来处理，因而，，可以按照下面的方式来对因子水平的顺序进行重排。\nftpain \u0026lt;- factor(text.pain)\rftpain2 \u0026lt;- factor(ftpain, levels = c(\u0026quot;none\u0026quot;, \u0026quot;mild\u0026quot;, \u0026quot;medium\u0026quot;, \u0026quot;severe\u0026quot;))\rftpain\r## [1] none severe medium medium mild ## Levels: medium mild none severe\rftpain2\r## [1] none severe medium medium mild ## Levels: none mild medium severe\r另一种典型的操作是将两个或多个因子水平进行合并。当各个分组内样本数目太少，无法进行有效的统计分析时，长长需要这样做。比如，可能想将上例中的“medium”水平合并成一个叫“intermediate”的因子水平。为了实现这个目的，levels的赋值形式允许右边是一个列表。\nftpain3 \u0026lt;- ftpain2\rlevels(ftpain3) \u0026lt;- list(none = \u0026quot;none\u0026quot;, intermediate = c(\u0026quot;mild\u0026quot;, \u0026quot;medium\u0026quot;), severe = \u0026quot;severe\u0026quot;)\rftpain3\r## [1] none severe intermediate intermediate intermediate\r## Levels: none intermediate severe\r然而，直接改变水平名字，给不同的组赋予相同的名字常常更为便捷：\nftpain4 \u0026lt;- ftpain2\rlevels(ftpain4) \u0026lt;- c(\u0026quot;none\u0026quot;, \u0026quot;intermediate\u0026quot;, \u0026quot;intermediate\u0026quot;, \u0026quot;severe\u0026quot;)\rftpain4\r## [1] none severe intermediate intermediate intermediate\r## Levels: none intermediate severe\r\r10.1.3 日期的使用\r在流行病学和生存数据领域，经常要处理按日历日期格式表示的时间变量。世界上各地使用的日期格式不同，有时，需要读取一些与我们所在地区的时间不同的日期数据。R中的“Date”类以及相关的转换程序可以方便地处理这些问题。\n下面以爱沙尼亚的中风研究数据为例。一个经过预处理的数据保存在数据框stroke中。原始数据保存在ISwR包中的rawdata文件夹中，运行下面的代码可以读入原始数据：\nstroke \u0026lt;- read.csv2(\rsystem.file(\u0026quot;rawdata\u0026quot;, \u0026quot;stroke.csv\u0026quot;, package = \u0026quot;ISwR\u0026quot;),\rna.strings = \u0026quot;.\u0026quot;\r)\rnames(stroke) \u0026lt;- tolower(names(stroke))\rhead(stroke)\r## sex died dstr age dgn coma diab minf han\r## 1 1 7.01.1991 2.01.1991 76 INF 0 0 1 0\r## 2 1 \u0026lt;NA\u0026gt; 3.01.1991 58 INF 0 0 0 0\r## 3 1 2.06.1991 8.01.1991 74 INF 0 0 1 1\r## 4 0 13.01.1991 11.01.1991 77 ICH 0 1 0 1\r## 5 0 23.01.1996 13.01.1991 76 INF 0 1 0 1\r## 6 1 13.01.1991 13.01.1991 48 ICH 1 0 0 1\r在上面的数据集中，两个日期变量died和dstr（date of stroke）被存储为因子型变量，这是read.table函数的默认输出结果。使用函数as.Date将他们转换为“Date”类。这种做法简单明了，但需要特别注意日期的格式。\n本例中使用的格式是用点号分割的（日，月份，年份）格式，其中，年份是用四位数字表示的。这种格式非标准格式，因此，需要明确指出：\n#这里使用百分号表示日期的各个组成部分\r#%d表示某天\r#%m表示某月\r#%Y则是用四位数格式表示年份，注意Y是大写\rstroke \u0026lt;- transform(stroke, died = as.Date(died, format=\u0026quot;%d.%m.%Y\u0026quot;),\rdstr = as.Date(dstr, format = \u0026quot;%d.%m.%Y\u0026quot;))\r对日期可以进行算术操作，也就是说，它们的操作方式跟数值向量类似：\nsummary(stroke$died)\r## Min. 1st Qu. Median Mean 3rd Qu. ## \u0026quot;1991-01-07\u0026quot; \u0026quot;1992-03-14\u0026quot; \u0026quot;1993-01-23\u0026quot; \u0026quot;1993-02-15\u0026quot; \u0026quot;1993-11-04\u0026quot; ## Max. NA\u0026#39;s ## \u0026quot;1996-02-22\u0026quot; \u0026quot;338\u0026quot;\rsummary(stroke$dstr)\r## Min. 1st Qu. Median Mean 3rd Qu. ## \u0026quot;1991-01-02\u0026quot; \u0026quot;1991-11-08\u0026quot; \u0026quot;1992-08-12\u0026quot; \u0026quot;1992-07-27\u0026quot; \u0026quot;1993-04-30\u0026quot; ## Max. ## \u0026quot;1993-12-31\u0026quot;\rsummary(stroke$died-stroke$dstr)\r## Length Class Mode ## 829 difftime numeric\r#注意结果的单位是天\rhead(stroke$died-stroke$dstr)\r## Time differences in days\r## [1] 5 NA 145 2 1836 0\r在数据文件中，死亡日期对应为NA的记录表示病人没有在该项研究的结束日，即1996年1月1日前死亡。根据记录，共有6个病人死亡于该日期之后，然而，由于其他病人中很可能存在着死亡未被记录的情况，我们不得不舍弃这些死亡日期，将这些病人的状况记录为存活至研究结束日。 应当将上述数据进行转换，以使得每个病人都对应于一个结束日期以及显示病人在该结束日期时是存活还是死亡的指标。\n#pmin函数用于计算最小值，但与只返回一个值的min函数不同，它并行地对多个向量进行计算\r#na.rm参数允许函数在计算过程中忽略NA值\r#所以死亡信息缺失或在1996-1-1之后死亡的个体，其死亡日期被记录为1996-1-1，否则就记录病人真正的死亡日期\r#dead对象对应的表达式简单明了，但仍需检查缺失数据在处理过程中是否处理正确\rstroke \u0026lt;- transform(stroke,\rend = pmin(died, as.Date(\u0026quot;1991-1-1\u0026quot;, na.rm = T)),\rdead = !is.na(died) \u0026amp; died \u0026lt; as.Date(\u0026quot;1996-1-1\u0026quot;))\rhead(stroke)\r## sex died dstr age dgn coma diab minf han end dead\r## 1 1 1991-01-07 1991-01-02 76 INF 0 0 1 0 1991-01-01 TRUE\r## 2 1 \u0026lt;NA\u0026gt; 1991-01-03 58 INF 0 0 0 0 \u0026lt;NA\u0026gt; FALSE\r## 3 1 1991-06-02 1991-01-08 74 INF 0 0 1 1 1991-01-01 TRUE\r## 4 0 1991-01-13 1991-01-11 77 ICH 0 1 0 1 1991-01-01 TRUE\r## 5 0 1996-01-23 1991-01-13 76 INF 0 1 0 1 1991-01-01 FALSE\r## 6 1 1991-01-13 1991-01-13 48 ICH 1 0 0 1 1991-01-01 TRUE\r#最后，为了得到每个人的观测时长，运行如下代码\rstroke \u0026lt;- transform(stroke,\robstime= as.numeric(end - dstr, units = \u0026quot;days\u0026quot;)/365.25)\r\r10.1.4 多变量重编码\r有时候可能一个数据集包含了大量需要重新编码的变量（比如调查问卷中的数据，可能有很多基于5分打分制的项目）。此时，可以利用数据框具有的列表特性，对数据框应用lapply函数并结合下标选择对数据进行转换。比如，在处理原始中风数据时，可以按照下面的方式来处理数据。\nrawstroke \u0026lt;- read.csv2(\rsystem.file(\u0026quot;rawdata\u0026quot;, \u0026quot;stroke.csv\u0026quot;, package = \u0026quot;ISwR\u0026quot;),\rna.strings = \u0026quot;.\u0026quot;)\rix \u0026lt;- c(\u0026quot;DSTR\u0026quot;, \u0026quot;DIED\u0026quot;)\rrawstroke[ix] \u0026lt;- lapply(rawstroke[ix],\ras.Date, format = \u0026quot;%d.%m.%Y\u0026quot;)\rhead(rawstroke)\r## SEX DIED DSTR AGE DGN COMA DIAB MINF HAN\r## 1 1 1991-01-07 1991-01-02 76 INF 0 0 1 0\r## 2 1 \u0026lt;NA\u0026gt; 1991-01-03 58 INF 0 0 0 0\r## 3 1 1991-06-02 1991-01-08 74 INF 0 0 1 1\r## 4 0 1991-01-13 1991-01-11 77 ICH 0 1 0 1\r## 5 0 1996-01-23 1991-01-13 76 INF 0 1 0 1\r## 6 1 1991-01-13 1991-01-13 48 ICH 1 0 0 1\r类似的，也可以通过一步操作，将4个二进制变量转换成“No/Yes”型因子。\nix \u0026lt;- 6:9\rrawstroke[ix] \u0026lt;- lapply(rawstroke[ix],\rfactor, levels = 0:1, labels = c(\u0026quot;No\u0026quot;, \u0026quot;Yes\u0026quot;))\rhead(rawstroke)\r## SEX DIED DSTR AGE DGN COMA DIAB MINF HAN\r## 1 1 1991-01-07 1991-01-02 76 INF No No Yes No\r## 2 1 \u0026lt;NA\u0026gt; 1991-01-03 58 INF No No No No\r## 3 1 1991-06-02 1991-01-08 74 INF No No Yes Yes\r## 4 0 1991-01-13 1991-01-11 77 ICH No Yes No Yes\r## 5 0 1996-01-23 1991-01-13 76 INF No Yes No Yes\r## 6 1 1991-01-13 1991-01-13 48 ICH Yes No No Yes\r\r\r10.2 条件计算\rifelse函数允许对同一数据集的不同部分做不同计算。下面以10.1.3小节中讨论过的中锋数据的一个子集进行演示。但这里使用的是ISwR包中经过预处理的版本。\nstrokesub \u0026lt;- ISwR::stroke[1:10, 2:3]\rstrokesub\r## died dstr\r## 1 1991-01-07 1991-01-02\r## 2 \u0026lt;NA\u0026gt; 1991-01-03\r## 3 1991-06-02 1991-01-08\r## 4 1991-01-13 1991-01-11\r## 5 \u0026lt;NA\u0026gt; 1991-01-13\r## 6 1991-01-13 1991-01-13\r## 7 1993-12-01 1991-01-14\r## 8 1991-12-12 1991-01-14\r## 9 \u0026lt;NA\u0026gt; 1991-01-15\r## 10 1993-11-10 1991-01-15\r为计算存活模型需要的研究时间和时间/检查指数，可以运行下面的代码：\nstrokesub \u0026lt;- transform(strokesub,\revent = !is.na(died))\rstrokesub \u0026lt;- transform(strokesub,\robstime = ifelse(\revent, died-dstr, as.Date(\u0026quot;1996-1-1\u0026quot;)-dstr)\r)\rstrokesub\r## died dstr event obstime\r## 1 1991-01-07 1991-01-02 TRUE 5\r## 2 \u0026lt;NA\u0026gt; 1991-01-03 FALSE 1824\r## 3 1991-06-02 1991-01-08 TRUE 145\r## 4 1991-01-13 1991-01-11 TRUE 2\r## 5 \u0026lt;NA\u0026gt; 1991-01-13 FALSE 1814\r## 6 1991-01-13 1991-01-13 TRUE 0\r## 7 1993-12-01 1991-01-14 TRUE 1052\r## 8 1991-12-12 1991-01-14 TRUE 332\r## 9 \u0026lt;NA\u0026gt; 1991-01-15 FALSE 1812\r## 10 1993-11-10 1991-01-15 TRUE 1030\rifelse函数的工作机制是这样的：它有3个参数，test，yes，no。3个向量长度相同（如果长度不同，系统会自动循环补齐）。当test为真的时候，返回对应的YES的结果；当test为假的时候，返回对应的NO的结果；当条件为NA时，结果返回NA。该函数的操作结果就是YES和NO的拼接。\n\r10.3 合并与重构数据框\r这一节主要是对数据框进行增加记录（垂直）或增加变量合并（水平）的方法。\n10.3.1 追加数据框\r当有众多来自于不同数据源的数据框时，往往会需要将它们进行合并构造一个更大的数据框。在这一小节中，将进行“垂直”合并。所有将要合并的数据框必须有一样的变量，但这些变量在各个子数据框中的顺序不用完全一致。\n为模拟上述情况，可以假设juul数据集对应的数据是对男孩群体和女孩群体单独进行收集的。此时，数据框中可能不会包含变量sex，因为对于单独的全体，各个样本对应的性别是一样的。同时支队单独一个性别有意义的变量在另一个样本中也将被忽略。\nattach(juul)\r## The following object is masked _by_ .GlobalEnv:\r## ## age\r#注意subset函数中select参数的用法。该参数将数据框的列名替换为序列号，并以返回的序列号对数据框进行引用。负号的作用是移除相应的列，比如，上面的代码将删除juulgrl数据集中的testvol列和sex列。\rjuulgrl \u0026lt;- subset(juul, sex==2, select=-c(testvol,sex))\rjuulboy \u0026lt;- subset(juul, sex==1, select=-c(menarche,sex))\r为了将数据框合并在一起，必须先加入缺少的变量：\njuulgrl$sex \u0026lt;- factor(\u0026quot;F\u0026quot;)\rjuulgrl$testvol \u0026lt;- NA\rjuulboy$sex \u0026lt;- factor(\u0026quot;M\u0026quot;)\rjuulboy$menarche \u0026lt;- NA\r接着，对数据框使用rbind函数即可：\njuulall \u0026lt;- rbind(juulboy, juulgrl)\rnames(juulall)\r## [1] \u0026quot;age\u0026quot; \u0026quot;igf1\u0026quot; \u0026quot;tanner\u0026quot; \u0026quot;testvol\u0026quot; \u0026quot;sex\u0026quot; \u0026quot;menarche\u0026quot;\r注意，rbind函数在操作过程汇总使用了列名（因此，即使两个数据框中列顺序不同，该函数也不会对不相关的变量进行合并），并且以第一个数据框的变量顺序为参考。最终，结果的变量顺序与juulboy数据集的变量顺序一致。也请注意，rbind函数能够很好地处理合并后的因子水平。\nlevels(juulall$sex)\r## [1] \u0026quot;M\u0026quot; \u0026quot;F\u0026quot;\r\r10.3.2 合并数据框\r有时会拿到一些针对同一批病人的独立数据集。比如说，可能会拿到分别包含患者挂号信息、临床化验数据及问卷调查的数据集。使用cbind函数将数据集并排连在一起有时也可行，只不过这种做法有风险：如果数据集中的数据不够完整或者多出了不在某个数据集中的观测样本，想要避免这种情况发生，必须有一个独特的样本识别码。\nmerge函数就可以处理这类问题。它会比较每个数据集中的一个或多个变量。这组变量在两个数据集中默认具有相同的名字（一般而言，有一个叫做ID的变量标示测试者的身份）。假设在默认情况下，这两个数据集分别称为dfx和dfy，可以简单通过下面来计算合并的数据框：\n#这里只是举例子~~~并没有数据集~~~所以用#注释掉\r#merge(dfx, dfy)\r然而，有可能这两个数据集有多个名字相同的变量。此时，可以引入一个by参数，它指定了比较的变量名，如：\n#同上~这里只是举例子~~~\r#merge(dfx, dfy, by=\u0026quot;ID\u0026quot;)\r两个数据集中的任何其他变量都会在结果中的名字后加后缀.x或.y。为了安全，在任何时候都应该使用这种格式，这种做法也能增加可读性与明确性。如需要匹配的变量在两个数据框中有不用的名字，则可以使用by.x和by.y。\n下面用nickel数据集来解释上述概念。该数据描述了南威尔士一个镍冶炼工人队的信息。数据集ewrates则包含了按照年份和以5年间隔的年龄进行分组的人群死亡率表格。\nhead(nickel)\r## id icd exposure dob age1st agein ageout\r## 1 3 0 5 1889.019 17.4808 45.2273 92.9808\r## 2 4 162 5 1885.978 23.1864 48.2684 63.2712\r## 3 6 163 10 1881.255 25.2452 52.9917 54.1644\r## 4 8 527 9 1886.340 24.7206 47.9067 69.6794\r## 5 9 150 0 1879.500 29.9575 54.7465 76.8442\r## 6 10 163 2 1889.915 21.2877 44.3314 62.5413\rhead(ewrates)\r## year age lung nasal other\r## 1 1931 10 1 0 1269\r## 2 1931 15 2 0 2201\r## 3 1931 20 6 0 3116\r## 4 1931 25 14 0 3024\r## 5 1931 30 30 1 3188\r## 6 1931 35 68 1 4165\r假设想根据进入研究群体的日期值来合并这两个数据集。其中，年龄信息包含在变量agein中，进入数据集的日期可用dob + agein计算得出。可以用下面的代码计算ewrates对应的群体编码：\nhead(nickel)\r## id icd exposure dob age1st agein ageout\r## 1 3 0 5 1889.019 17.4808 45.2273 92.9808\r## 2 4 162 5 1885.978 23.1864 48.2684 63.2712\r## 3 6 163 10 1881.255 25.2452 52.9917 54.1644\r## 4 8 527 9 1886.340 24.7206 47.9067 69.6794\r## 5 9 150 0 1879.500 29.9575 54.7465 76.8442\r## 6 10 163 2 1889.915 21.2877 44.3314 62.5413\rnickel \u0026lt;- transform(nickel,\ragr = trunc(agein/5)*5,\rygr = trunc((dob + agein-1)/5)*5+1)\rhead(nickel)\r## id icd exposure dob age1st agein ageout agr ygr\r## 1 3 0 5 1889.019 17.4808 45.2273 92.9808 45 1931\r## 2 4 162 5 1885.978 23.1864 48.2684 63.2712 45 1931\r## 3 6 163 10 1881.255 25.2452 52.9917 54.1644 50 1931\r## 4 8 527 9 1886.340 24.7206 47.9067 69.6794 45 1931\r## 5 9 150 0 1879.500 29.9575 54.7465 76.8442 50 1931\r## 6 10 163 2 1889.915 21.2877 44.3314 62.5413 40 1931\rtrunc函数将变量的小数部分进行趋零取整。注意，年龄的每个组起始于可以被5整除的数，年份的每个组截止的时间榆次对应；这也就是在前面ygr的表达式中先减去1，再在结尾后加上1的原因（事实上，这个步骤并不重要，因为本例中所有录入日期都是1934、1939、1944或者1949年的4月1日）。需要注意的是，这里并没有使用与ewrates数据集中相同的变量名。这么做的原因在于，变量名age和year在nickel数据中不便于理解。\n定义了年龄和年份组之后，接下来的合并过程就很简单了。这里只需要注意一下两个数据框中变量名不同的问题。\nmrg \u0026lt;- merge(nickel, ewrates,\rby.x = c(\u0026quot;agr\u0026quot;, \u0026quot;ygr\u0026quot;), by.y = c(\u0026quot;age\u0026quot;, \u0026quot;year\u0026quot;))\rhead(mrg, 10)\r## agr ygr id icd exposure dob age1st agein ageout lung nasal\r## 1 20 1931 273 154 0 1909.500 14.6913 24.7465 55.9302 6 0\r## 2 20 1931 213 162 0 1910.129 14.2018 24.1177 63.0493 6 0\r## 3 20 1931 546 0 0 1909.500 14.4945 24.7465 72.5000 6 0\r## 4 20 1931 574 491 0 1909.729 14.0356 24.5177 70.6592 6 0\r## 5 20 1931 110 0 0 1909.247 14.0302 24.9999 72.7534 6 0\r## 6 20 1931 325 434 0 1910.500 14.0737 23.7465 43.0343 6 0\r## 7 25 1931 56 502 2 1904.500 18.2917 29.7465 51.5847 14 0\r## 8 25 1931 690 420 0 1906.500 17.2206 27.7465 55.1219 14 0\r## 9 25 1931 443 420 0 1905.326 14.5562 28.9204 65.7616 14 0\r## 10 25 1931 137 465 0 1905.386 19.0808 28.8601 74.2794 14 0\r## other\r## 1 3116\r## 2 3116\r## 3 3116\r## 4 3116\r## 5 3116\r## 6 3116\r## 7 3024\r## 8 3024\r## 9 3024\r## 10 3024\r\r10.3.3 重塑数据框\r纵向数据有两种格式，一是“宽”格式，其中每个时间点为单独的一列，但每个事件只有一个记录；另一种是“长”格式，其中每个事件都有多余记录，每个时间点有一条记录。因为不需要假设事件都是在相同的时间点被记录的，所以长格式使用更广泛，但在实际应用当中，使用宽格式可能会更容易，而且一些统计函数也需要这种格式的输入。\n在任何一种情况下，都需要从一个格式转换到另一个格式。这就是reshape函数的功用。\n例子如下，病人在罹患乳腺癌之后，采用莫西芬进行治疗。使用病人再次期间的骨代谢的随机化研究数据作为例子。治疗开始之后，碱性磷酸酶在基准日以及治疗开始后的第3、6、9、12、18以及24个月后的浓度数据都被记录了下来。\nhead(alkfos)\r## grp c0 c3 c6 c9 c12 c18 c24\r## 1 1 142 140 159 162 152 175 148\r## 2 1 120 126 120 146 134 119 116\r## 3 1 175 161 168 164 213 194 221\r## 4 1 234 203 174 197 289 174 189\r## 5 1 94 107 146 124 128 98 114\r## 6 1 128 97 113 203 NA NA NA\r在reshape函数最简单使用情况下，它会假设变量名包含了将数据重整为长格式数据所需的必要信息。它默认变量名和测量时间是由“.”来分开的，因此，需要强制修改名字格式来满足这一原则。\na2 \u0026lt;- alkfos\rnames(a2) \u0026lt;- sub(\u0026quot;c\u0026quot;, \u0026quot;c.\u0026quot;, names(a2))\rnames(a2)\r## [1] \u0026quot;grp\u0026quot; \u0026quot;c.0\u0026quot; \u0026quot;c.3\u0026quot; \u0026quot;c.6\u0026quot; \u0026quot;c.9\u0026quot; \u0026quot;c.12\u0026quot; \u0026quot;c.18\u0026quot; \u0026quot;c.24\u0026quot;\rsub函数的作用是在字符串内做替换操作。在这个例子中，其把“c”替换成了“c.”。另外一种方式是通过在reshape命令中加入seq=“”来改变原始名字格式(c0, …, c24)。\n命名好变量名之后，接下来唯一要做的就是指明数据重整的方向以及具有时变性特征的变量整合。这里有一个简介的功能，即后者可以用数据集的列下标来指定，这比使用变量名字引用变量更方便。\na.long \u0026lt;- reshape(a2, varying = 2:8, direction = \u0026quot;long\u0026quot;)\rhead(a.long)\r## grp time c id\r## 1.0 1 0 142 1\r## 2.0 1 0 120 2\r## 3.0 1 0 175 3\r## 4.0 1 0 234 4\r## 5.0 1 0 94 5\r## 6.0 1 0 128 6\rtail(a.long)\r## grp time c id\r## 38.24 2 24 95 38\r## 39.24 2 24 NA 39\r## 40.24 2 24 192 40\r## 41.24 2 24 94 41\r## 42.24 2 24 194 42\r## 43.24 2 24 129 43\r注意，结果的排列顺序是，先按照time变量继续排序，对每个time变量，再根据ID进行排序。从技术角度而言，这是最方便生成的格式。如果喜欢相反的排列顺序，可以运行下面的代码：\no \u0026lt;- with(a.long, order(id, time))\rhead(a.long[o,], 10)\r## grp time c id\r## 1.0 1 0 142 1\r## 1.3 1 3 140 1\r## 1.6 1 6 159 1\r## 1.9 1 9 162 1\r## 1.12 1 12 152 1\r## 1.18 1 18 175 1\r## 1.24 1 24 148 1\r## 2.0 1 0 120 2\r## 2.3 1 3 126 2\r## 2.6 1 6 120 2\r我们使用同一个数据集演示一遍相反的操作过程，这次数据集的初始存储格式是长格式。事实上，这个操作过程有点过于简单了，因为reshape已经在它的输出中给出了足够的信息，只需要运行reshape(a.long)命令即可实现向宽格式的转换。为模拟原始数据是长格式的情况，这里先去掉了这些数据当中的“reshape Long”的属性。同时，使用na.omit函数删除数据集中具有缺失数据的记录。\na.long2 \u0026lt;- na.omit(a.long)\rattr(a.long2, \u0026quot;reshapeLong\u0026quot;) \u0026lt;- NULL\r#使用下面的代码把a.long2转换为宽格式\ra.wide2 \u0026lt;- reshape(a.long2, direction = \u0026quot;wide\u0026quot;,\rv.names = \u0026quot;c\u0026quot;, idvar = \u0026quot;id\u0026quot;,\rtimevar = \u0026quot;time\u0026quot;)\rhead(a.wide2)\r## grp id c.0 c.3 c.6 c.9 c.12 c.18 c.24\r## 1.0 1 1 142 140 159 162 152 175 148\r## 2.0 1 2 120 126 120 146 134 119 116\r## 3.0 1 3 175 161 168 164 213 194 221\r## 4.0 1 4 234 203 174 197 289 174 189\r## 5.0 1 5 94 107 146 124 128 98 114\r## 6.0 1 6 128 97 113 203 NA NA NA\r注意，6号病人对应的缺失记录以NA进行了填充；对他而言，只有前四次的记录。\n参数idvar和timevar指定了结果中变量名包括每次观测对应的ID以及时间的变量名。如它们具有默认的名字，那么，也可以不用指定，但这么做是比较好的做法。参数v.names指明了随时间改变的变量。如果忽略了它，那么grp变量也将被当做时间改变的变量。\n\r\r10.4 数据的分组及分案例操作\r本节的例子包括计算某药物动力学试验中的累计剂量以及各种对数据进行归一化和标准化的方法。\n对于这类问题，最好将数据拆分为包含多个组的列表，接着分别对每个组中包含的列表进行计算，最后将结果放在一起。\n考虑将a.long数据集中碱性磷酸酶值以基准日的观测值为中心进行归一化。可以考虑用split函数生成一个对应于不同测量时间的列表。\n#这是小写的L不是数字1\rl \u0026lt;- split(a.long$c, a.long$id)\rl[1:3]\r## $`1`\r## [1] 142 140 159 162 152 175 148\r## ## $`2`\r## [1] 120 126 120 146 134 119 116\r## ## $`3`\r## [1] 175 161 168 164 213 194 221\r接下来，使用lapply函数对列表中的所有元素应用某个特定函数，并将数据保存。\n#同样是小写的L\rl2 \u0026lt;- lapply(l, function(x) x / x[1])\rl2[1:3]\r## $`1`\r## [1] 1.0000000 0.9859155 1.1197183 1.1408451 1.0704225 1.2323944 1.0422535\r## ## $`2`\r## [1] 1.0000000 1.0500000 1.0000000 1.2166667 1.1166667 0.9916667 0.9666667\r## ## $`3`\r## [1] 1.0000000 0.9200000 0.9600000 0.9371429 1.2171429 1.1085714 1.2628571\r最后，用split的逆操作函数unsplit将各个切片的结果拼回在一起。请注意，a.long对应的id在time的同一水平下进行了排序，因此，该操作并不是简单地把l2中的元素拼接在一起。第一名病人对应的数据如下：\na.long$c.adj \u0026lt;- unsplit(l2, a.long$id)\rsubset(a.long, id==1)\r## grp time c id c.adj\r## 1.0 1 0 142 1 1.0000000\r## 1.3 1 3 140 1 0.9859155\r## 1.6 1 6 159 1 1.1197183\r## 1.9 1 9 162 1 1.1408451\r## 1.12 1 12 152 1 1.0704225\r## 1.18 1 18 175 1 1.2323944\r## 1.24 1 24 148 1 1.0422535\r事实上，有一个将这种分割–修改–合并操作规范化的函数，即ave。它的默认功能是用组的平均值来替换数据。不过，基于该函数能够做很多更一般的转换。下面是另一种可得到上述操作结果的方法：\na.long$c.adj \u0026lt;- ave(a.long$c, a.long$id,\rFUN = function(x) x / x[1])\r在前面的代码中，支队a.long$c进行了操作。当然，也可以使用下面的代码对整个数据框进行切片处理：\nl \u0026lt;- split(a.long, a.long$id)\rl2 \u0026lt;- lapply(l, transform, c.adj = c / c[1])\ra.long2 \u0026lt;- unsplit(l2, a.long$id)\r请注意lapply的最后一个参数是如何被传递给transform函数的。我们实际上是对列表1中的每个数据框 x 调用了transform(x, c.adj = c / c[1])操作。这种做法比前一种低效，因为该操作设计太多数据的靠背过程，但它对更复杂的数据操作进行了一般性的概括。\n\r10.5 时间分割\r在10.3.2小节中，对nickel和ewrates进行的合并操作不具有太多统计上的意义：只是在死亡率表中并入了对应的个体进入研究群体的年龄。然而，该数据集是关于癌症的，癌症是一种慢性疾病，确诊之后，在20年或更久之后会面临日益增大的风险。加入实验对象一般在50岁左右死亡，那么，对30岁的人来将，群体死亡率几乎和他们无关。\n一个合理的统计研究需要考虑整个后续观察期间的群体死亡率。将这些个体分割成多个“子个体”。\n#在这个数据集中，前六个观测是：\rhead(nickel)\r## id icd exposure dob age1st agein ageout agr ygr\r## 1 3 0 5 1889.019 17.4808 45.2273 92.9808 45 1931\r## 2 4 162 5 1885.978 23.1864 48.2684 63.2712 45 1931\r## 3 6 163 10 1881.255 25.2452 52.9917 54.1644 50 1931\r## 4 8 527 9 1886.340 24.7206 47.9067 69.6794 45 1931\r## 5 9 150 0 1879.500 29.9575 54.7465 76.8442 50 1931\r## 6 10 163 2 1889.915 21.2877 44.3314 62.5413 40 1931\r考虑id==4的个体，该个体在48.2684岁时进入研究群体，死亡于63.2712岁（我去~好精确，怎么做到的）。时序分割方法把这个实验人员当成4个独立的研究对象，一个在46.2684岁时进入此项研究，并在50岁时离开（50岁生日）；其他的研究对象分别包括50-55岁，55-60岁以及60-63.2712岁的时间间隔。前三个对象都是需要被去掉的，因为研究对象并没有死亡。\n如果把这些数据与人口列表合并，就能计算出给定年龄区间中的期望死亡人数，并可以将它与实际死亡人数进行比较。\n利用R语言向量化运算的性质，可以通过对各个年龄区间做循环来很好地解决这个问题，同时，要将每个观测时期都“裁剪”到各个年龄区间内。\n为了将观测时期裁剪到年龄介于60-65岁之间，如果进出这个年龄段的时间在该年龄段范围之外，需要对其进行调整。可以删除那些在该年龄段内没有观测数据的案例。另外，如果擦拭对象在这个年龄段内没有死亡，对应的icd应设定为0.\n最简单的方法是“先射击再定靶”。调整后的进入和退出时间为：\nentry \u0026lt;- pmax(nickel$agein, 60)\rexit \u0026lt;- pmin(nickel$ageout, 65)\r然而，有时会出现观测对象在60岁前就离开了测试群体，也有人在65岁之后才进入测试群体。在这两种情况下，出错的原因就在于entry \u0026gt; exit，因此，可以通过计算下面的值来对此进行检查：\nvalid \u0026lt;- (entry \u0026lt; exit)\rentry \u0026lt;- entry[valid]\rexit \u0026lt;- exit[valid]\r#有效案例对应的审查指标是\rcens \u0026lt;- (nickel$ageout[valid] \u0026gt; 65)\r#下面的代码可以得到切割后的数据集\rnickel60 \u0026lt;- nickel[valid,]\rnickel60$icd[cens] \u0026lt;- 0\rnickel60$agein \u0026lt;- entry\rnickel60$ageout \u0026lt;- exit\rnickel60$agr \u0026lt;- 60\rnickel60ygr \u0026lt;- with(nickel60, trunc((dob + agein - 1)/5)*5+1)\r结果的第一行是：\nhead(nickel60)\r## id icd exposure dob age1st agein ageout agr ygr\r## 1 3 0 5 1889.019 17.4808 60 65.0000 60 1931\r## 2 4 162 5 1885.978 23.1864 60 63.2712 60 1931\r## 4 8 0 9 1886.340 24.7206 60 65.0000 60 1931\r## 5 9 0 0 1879.500 29.9575 60 65.0000 60 1931\r## 6 10 163 2 1889.915 21.2877 60 62.5413 60 1931\r## 7 15 334 0 1890.500 23.2836 60 62.0000 60 1931\r有几点需要注意：如有人恰好在65岁时死亡，则被记录为在年龄区间（60-65岁）内死亡。与此对应，我们不会将正好在60岁死亡的人纳入该区间，因为那属于55-60岁区间。因为ygr是基于原始的agein变量计算得出的。所以有必要重算ygr的值。\n为得到整个扩展的数据集，可以将每个年龄区间20-25，25-30等重复上述操作，并用rbind函数将结果返回的16个数据框拼接在一起。不过这太麻烦了，而且可能会出错。一个替代方案就是写一个单独的程序。\n#首先，将应用到每个组的处理方法封装成函数：\rtrim \u0026lt;- function(start)\r{\rend \u0026lt;- start + 5\rentry \u0026lt;- pmax(nickel$agein, start)\rexit \u0026lt;- pmin(nickel$ageout, end)\rvalid \u0026lt;- (entry \u0026lt; exit)\rcens \u0026lt;- (nickel$ageout[valid] \u0026gt; end)\rresult \u0026lt;- nickel[valid,]\rresult$icd[cens] \u0026lt;- 0\rresult$agein \u0026lt;- entry[valid]\rresult$ageout \u0026lt;- exit[valid]\rresult$agr \u0026lt;- start\rresult$ygr \u0026lt;- with(result, trunc((dob + agein - 1)/5)*5+1)\rresult\r}\r这是一个典型的专用程序。有雨这个函数依赖于已知的各种变量名，而且把间隔长度强制限制为5，因此，它不能用在别的地方（~这不废话吗）。\n在这个定义下，trim(60)等价于前文中计算过的nickel60：\nhead(trim(60))\r## id icd exposure dob age1st agein ageout agr ygr\r## 1 3 0 5 1889.019 17.4808 60 65.0000 60 1946\r## 2 4 162 5 1885.978 23.1864 60 63.2712 60 1941\r## 4 8 0 9 1886.340 24.7206 60 65.0000 60 1946\r## 5 9 0 0 1879.500 29.9575 60 65.0000 60 1936\r## 6 10 163 2 1889.915 21.2877 60 62.5413 60 1946\r## 7 15 334 0 1890.500 23.2836 60 62.0000 60 1946\r使用下面的代码，可得到所有间隔的结果：\nnickel.expand \u0026lt;- do.call(\u0026quot;rbind\u0026quot;, lapply(seq(20, 95, 5), trim))\rhead(nickel.expand)\r## id icd exposure dob age1st agein ageout agr ygr\r## 84 110 0 0 1909.247 14.0302 24.9999 25 20 1931\r## 156 213 0 0 1910.129 14.2018 24.1177 25 20 1931\r## 197 273 0 0 1909.500 14.6913 24.7465 25 20 1931\r## 236 325 0 0 1910.500 14.0737 23.7465 25 20 1931\r## 384 546 0 0 1909.500 14.4945 24.7465 25 20 1931\r## 400 574 0 0 1909.729 14.0356 24.5177 25 20 1931\r这里的do.call结构调用了rbind，并给了它一个参数列表。这里参数列表对应的是lapply函数的返回值。而lapply函数的作用是对20，25，……，95等值执行trim函数。上面的代码等价于：\n#这个只是演示~不能运行\r#rbind(trim(20), trim(25),.....,trim(95))\r例如，显示一个实验对象，得到的结果如下：\nsubset(nickel.expand, id==4)\r## id icd exposure dob age1st agein ageout agr ygr\r## 2 4 0 5 1885.978 23.1864 48.2684 50.0000 45 1931\r## 2100 4 0 5 1885.978 23.1864 50.0000 55.0000 50 1931\r## 2102 4 0 5 1885.978 23.1864 55.0000 60.0000 55 1936\r## 2104 4 162 5 1885.978 23.1864 60.0000 63.2712 60 1941\r最后一步，将死亡率表合并，这与10.3.2小节中的步骤一样：\nnickel.expand \u0026lt;- merge(nickel.expand, ewrates,\rby.x = c(\u0026quot;agr\u0026quot;, \u0026quot;ygr\u0026quot;), by.y = c(\u0026quot;age\u0026quot;, \u0026quot;year\u0026quot;))\rhead(nickel.expand)\r## agr ygr id icd exposure dob age1st agein ageout lung nasal\r## 1 20 1931 325 0 0 1910.500 14.0737 23.7465 25 6 0\r## 2 20 1931 273 0 0 1909.500 14.6913 24.7465 25 6 0\r## 3 20 1931 110 0 0 1909.247 14.0302 24.9999 25 6 0\r## 4 20 1931 574 0 0 1909.729 14.0356 24.5177 25 6 0\r## 5 20 1931 213 0 0 1910.129 14.2018 24.1177 25 6 0\r## 6 20 1931 546 0 0 1909.500 14.4945 24.7465 25 6 0\r## other\r## 1 3116\r## 2 3116\r## 3 3116\r## 4 3116\r## 5 3116\r## 6 3116\r\r练习题\r生成一个因子，其中thuesen数据中的变量blood.glucose被切分为区间(4,7]、(7,9]、(9,12]、(12,20]。同时，修改因子水平名称为“low”、“intermediate”、“high”和“very high”。\r在bcmort数据集中，四水平因子cohort可以看做两个双水平因子的乘积，比如period和area。如何生成这些变量。\r将ashina数据集转换为长格式。考虑如何编码才能判断vas测量值是是来自第一个还是第二个测量过程。\r将sroke数据按照obsmonths切分到中风后0-0.5、0.5-2、2-12以及12+的时间区间中。\r\r\r\r","date":1536278400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1536278400,"objectID":"005b0baabd281b2a65d16753f0f1e522","permalink":"/post/r%E8%AF%AD%E8%A8%80%E7%BB%9F%E8%AE%A1%E5%85%A5%E9%97%A8-%E7%AC%AC%E5%8D%81%E7%AB%A0/","publishdate":"2018-09-07T00:00:00Z","relpermalink":"/post/r%E8%AF%AD%E8%A8%80%E7%BB%9F%E8%AE%A1%E5%85%A5%E9%97%A8-%E7%AC%AC%E5%8D%81%E7%AB%A0/","section":"post","summary":"第十章 数据处理的高级技术 10.1 变量的重编码 10.1.1 cut函数 有的时候可","tags":["R","统计"],"title":"R语言统计入门-第十章","type":"post"},{"authors":null,"categories":["R","统计"],"content":"\r第八章 表格数据\r8.1 单比例\r对单比例的检验基于二项分布。在大样本的情况下，可以用一个均值为\\(Np\\)，方差为\\(Np(1-p)\\)的正态分布来很好的近似。有一个经验结论，在“成功”与“失败”的期望次数都大于5的时候能得到较好的近似。 令\\(x\\)表示“成功”的次数，则对假设\\(p=p_0\\)的检验可以基于下式： \\[\ru=\\frac{x-Np_0}{\\sqrt{Np_0(1-p_0)}}\r\\] 这个统计量近似服从一个均值为0，标准差为1的正态分布，或者说\\(u^2\\)近似服从一个自由度为1的卡方分布。 下面开始讲例子。215名病人的39名被观测到患有哮喘，然后对“随机病人”患有哮喘的概率是0.15这个假设做检验。采用函数prop.test。\n#这个函数的3个参数分别是，正观测数、总数以及想对其做检验的概率参数\r#最后这个参数默认值为0.5\rprop.test(39,215,0.15)\r## ## 1-sample proportions test with continuity correction\r## ## data: 39 out of 215, null probability 0.15\r## X-squared = 1.425, df = 1, p-value = 0.2326\r## alternative hypothesis: true p is not equal to 0.15\r## 95 percent confidence interval:\r## 0.1335937 0.2408799\r## sample estimates:\r## p ## 0.1813953\r也可以用函数binom.test在二项分布下做检验，这时能得到精确地检验概率，所以一般它比上一个函数更受欢迎。不过除了单比例检验，函数prop.test还能做其他事情。为了得到这个\\(p\\)值，先计算出\\(x\\)取每一个可能值的点概率，然后再将观测到的小于等于\\(x\\)的概率加起来。\nbinom.test(39,215,.15)\r## ## Exact binomial test\r## ## data: 39 and 215\r## number of successes = 39, number of trials = 215, p-value = 0.2135\r## alternative hypothesis: true probability of success is not equal to 0.15\r## 95 percent confidence interval:\r## 0.1322842 0.2395223\r## sample estimates:\r## probability of success ## 0.1813953\r\r8.2 两个独立的比例\r函数prop.test也能用于比较两个或多个比例。为达到这个目的，参数应该是两个向量，其中第一个表示正观测数，第二个表示每组总数。 以下是例子：\nlewitt.machin.success \u0026lt;- c(9,4)\rlewitt.machin.total \u0026lt;- c(12,13)\rprop.test(lewitt.machin.success,lewitt.machin.total)\r## ## 2-sample test for equality of proportions with continuity\r## correction\r## ## data: lewitt.machin.success out of lewitt.machin.total\r## X-squared = 3.2793, df = 1, p-value = 0.07016\r## alternative hypothesis: two.sided\r## 95 percent confidence interval:\r## 0.01151032 0.87310506\r## sample estimates:\r## prop 1 prop 2 ## 0.7500000 0.3076923\r这里给出的是比例之差的置信区间。 也可以不使用Yates连续型修正来计算这个检验，即加入参数correct=F。连续性修正一定程度上让所得置信区间变得更宽，不过注意到这里仍然不包含0。而双边假设检验显示两组之间没有显著差异，所以这里置信区间与其相矛盾。这是因为使用了不同的近似方法导致的，这对于稀疏如此的表尤为重要。 如果希望确认至少\\(p\\)值是正确的，可以用Fisher精确检验。用上一节的数据来展示它。这个检验在给定行和列的边际值的情况下计算\\(2\\times 2\\)表格的条件分布。这可能难以想象，不过可以这样来看：拿出13个白球和12个黑球（分别是成功与失败），然后不重复地从抽样中得到两个样本量分别为12和13的小组。第一组的白球数量显然足以确定整个表格，而它的分布可以完全转化为一个纯粹的组合问题。这个分布被称为超几何分布。 相关的检验是fisher.test，它要求输入的数据时矩阵形式的，如下：\nmatrix(c(9,4,3,9),2)\r## [,1] [,2]\r## [1,] 9 3\r## [2,] 4 9\rlewitt.machin \u0026lt;- matrix(c(9,4,3,9),2)\rfisher.test(lewitt.machin)\r## ## Fisher\u0026#39;s Exact Test for Count Data\r## ## data: lewitt.machin\r## p-value = 0.04718\r## alternative hypothesis: true odds ratio is not equal to 1\r## 95 percent confidence interval:\r## 0.9006803 57.2549701\r## sample estimates:\r## odds ratio ## 6.180528\r注意表格的第二列应该是负结果的次数，不是观测值的总数。 还需注意的是，这里给出了比值比（odds ratio）的置信区间，即是\\((p_1/(1-p_1))/(p_2/(1-p_2))\\)。可以发现，若\\(p_1\\neq p_2\\)，那么表格的条件分布只依赖于比值比，所以这是一个用于衡量Fisher检验中相关程度的自然指标。这个检验的精确分布在比值比不为1的时候可以精确地求出，不过这里与binom.test一样，双边95%置信区间是由两个单边97.5%置信区间并起来的。这导致它的结果与prop.test的不一致：检验的结果刚好显著，但是比值比的置信区间包含1在内。 和fisher.test一样，在chisq.test中的标准\\(\\chi^2\\)检验需要矩阵类型的数据。对于一个\\(2\\times 2\\)表格来说，这个检验与prop.test的结果是完全一样的。\nchisq.test(lewitt.machin)\r## ## Pearson\u0026#39;s Chi-squared test with Yates\u0026#39; continuity correction\r## ## data: lewitt.machin\r## X-squared = 3.2793, df = 1, p-value = 0.07016\r\r8.3 k 比例，检验趋势\r有时候想要比较多于两个部分。但有时数据的分类可能是有序的，所以希望找到一个随着分组序号递增或递减的趋势。 这一节的例子是，一组女性是否使用剖腹产生育孩子，以及鞋子码数的数据。数据集如下：\nlibrary(ISwR)\rcaesar.shoe\r## \u0026lt;4 4 4.5 5 5.5 6+\r## Yes 5 7 6 7 8 10\r## No 17 28 36 41 46 140\r#为在caesar.shoe这样的数据上使用prop.test函数\r#需要将其转换为一个“成功”的向量（在这里和相反的很像）和一个“实验”的向量\rcaesar.shoe.yes \u0026lt;- caesar.shoe[\u0026quot;Yes\u0026quot;,]\rcaesar.shoe.total \u0026lt;- margin.table(caesar.shoe,2)\rcaesar.shoe.yes\r## \u0026lt;4 4 4.5 5 5.5 6+ ## 5 7 6 7 8 10\rcaesar.shoe.total\r## \u0026lt;4 4 4.5 5 5.5 6+ ## 22 35 42 48 54 150\r#这样就很容易进行检验\rprop.test(caesar.shoe.yes,caesar.shoe.total)\r## Warning in prop.test(caesar.shoe.yes, caesar.shoe.total): Chi-squared\r## approximation may be incorrect\r## ## 6-sample test for equality of proportions without continuity\r## correction\r## ## data: caesar.shoe.yes out of caesar.shoe.total\r## X-squared = 9.2874, df = 5, p-value = 0.09814\r## alternative hypothesis: two.sided\r## sample estimates:\r## prop 1 prop 2 prop 3 prop 4 prop 5 prop 6 ## 0.22727273 0.20000000 0.14285714 0.14583333 0.14814815 0.06666667\r可以看出，这个检验的结果是不显著的。但是从细节上说，剖腹产一组的数字太少，让人感觉这有些巧妙的不合理，此外，注意那条警告，它是因为一些格子的期望数小于5。 可以用prop.trend.test来检测不同部分的趋势。这个检测的本质是一个用每组的分数对不同部分进行的加权线性回归，其中对领斜率进行检验，就成为了一个自由度为1的\\(\\chi^2\\)检验。\n#这个函数有三个参数，x，n，score\r#前两个与prop.test中的一致\r#最后一个是赋予每组的分数，默认是简单的1,2，……，k\rprop.trend.test(caesar.shoe.yes,caesar.shoe.total)\r## ## Chi-squared Test for Trend in Proportions\r## ## data: caesar.shoe.yes out of caesar.shoe.total ,\r## using scores: 1 2 3 4 5 6\r## X-squared = 8.0237, df = 1, p-value = 0.004617\r所以，若假设鞋子码数是线性的，那么可以看到一个显著的区别。这样的假设并不是为了保证检验的合理所必需的。反之，它表示了这个检验所对应得备择假设。\n\r8.4 r×c表格\r为了分析两边都多于两个类的表格数据，可以用函数chisq.test或fisher.test，不过要注意后者在每一铬数字比较大而且超过两行或两列时的计算量非常大。在一个简单的例子里，已经介绍了chisq.test，不过对于更大的表而言，还有一些其他有趣的特征。 一个\\(r\\times c\\)表格看起来像这样：\n\\[\r\\begin{array}{cccc|c}\rn_{11} \u0026amp; n_{12} \u0026amp; \\cdots \u0026amp; n_{1c} \u0026amp; n_{1.}\\\\\rn_{21} \u0026amp; n_{22} \u0026amp; \\cdots \u0026amp; n_{2c} \u0026amp; n_{2.}\\\\\r\\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \u0026amp; \\vdots\\\\\rn_{r1} \u0026amp; n_{r2} \u0026amp; \\cdots \u0026amp; n_{rc} \u0026amp; n_{r.}\\\\ \\hline\rn_{.1} \u0026amp; n_{.2} \u0026amp; \\cdots \u0026amp; n_{.c} \u0026amp; n_{..}\\\\\r\\end{array}\r\\]\n这样的一个表会导致几种不同的抽样方法，从而对应的表述“行和列之间没有关系”也有不同的含义了。每一行的总和可能是事先确定的，此时可能会检验每列的分布是否在每行上都一样。反之，如果每列的和是固定的，也可能是每一个个体随机地根据行或列来分组的。在后一种情况中，你应该会对检验统计独立性这个假设感兴趣，即一个个体掉入第\\(ij\\)个格子的概率是边际概率的乘积：\\(p_{i.}p{.j}\\)。不过，这些不同的情况最后都使用了同样的分析方法。 如果行和列之间没有关系，那么每一格的期望值应该是： \\[\rE_{ij}=\\frac{n_{i.}\\times n_{.j}}{n_{..}}\r\\] 这可以理解为把每一行的总数按照每一列总数的比例（或者反过来）进行分布，或者是将整个表格的总数按照行和列的比例进行分布。 检验统计量 \\[\rX^2=\\sum{\\frac{(O-E)^2}{E}}\r\\] 服从一个自由度为\\((r-1)\\times (c-1)\\)近似的\\(\\chi^2\\)分布。这里是对整个表格求和，然后下标\\(ij\\)被省略了。这里\\(O\\)表示观测值，而\\(E\\)表示前文所述的期望值。 下面用4.5节提到的婚姻状况与咖啡因消费情况的表格来计算这个\\(\\chi^2\\)检验：\ncaff.matital \u0026lt;- matrix(c(652,1537,598,242,36,46,28,21,218\r,327,106,67),\rnrow = 3,byrow = T)\rcolnames(caff.matital) \u0026lt;- c(\u0026quot;0\u0026quot;,\u0026quot;1-150\u0026quot;,\u0026quot;151-300\u0026quot;,\u0026quot;\u0026gt;300\u0026quot;)\rrownames(caff.matital) \u0026lt;- c(\u0026quot;Married\u0026quot;,\u0026quot;Prev.married\u0026quot;,\u0026quot;Single\u0026quot;)\rcaff.matital\r## 0 1-150 151-300 \u0026gt;300\r## Married 652 1537 598 242\r## Prev.married 36 46 28 21\r## Single 218 327 106 67\rchisq.test(caff.matital)\r## ## Pearson\u0026#39;s Chi-squared test\r## ## data: caff.matital\r## X-squared = 47.386, df = 6, p-value = 1.567e-08\r检验结果高度显著，所以可以放心地拒绝独立性的假设。不过，一般来说，也会想知道偏差的程度。为了这个目的，可以仔细查看函数chisq.test的一些额外的返回值。 注意，函数chisq.test（就像函数lm一样）的返回值实际上比显示出来的信息更丰富：\nchisq.test(caff.matital)$expected\r## 0 1-150 151-300 \u0026gt;300\r## Married 707.65188 1491.84889 571.74523 257.7540\r## Prev.married 30.60495 64.52037 24.72718 11.1475\r## Single 167.74317 353.63074 135.52759 61.0985\rchisq.test(caff.matital)$observed\r## 0 1-150 151-300 \u0026gt;300\r## Married 652 1537 598 242\r## Prev.married 36 46 28 21\r## Single 218 327 106 67\r#接下来便可以对这两个表格进行彻底检查，看看差别在哪里\r#检查每个格子对整体χ2的贡献通常是有用的\r#这样的表格不能直接被析取，但很容易计算出来\rE \u0026lt;- chisq.test(caff.matital)$expected\rO \u0026lt;- chisq.test(caff.matital)$observed\r(O-E)^2/E\r## 0 1-150 151-300 \u0026gt;300\r## Married 4.3766322 1.366507 1.2056296 0.9628887\r## Prev.married 0.9510407 5.316215 0.4331815 8.7079428\r## Single 15.0572411 2.005471 6.4332189 0.5700246\r这里有一些格子有很大的贡献，特别是很多“戒除咖啡因”的单身者，同时曾经结过婚的分布方向则被转换为朝向更多的摄入——他们摄入的更多。不过，要在这些数据里找到一个偏离独立性的简单描述仍然是不容易的。 也可以对原始（没有成为列表）数据使用chisq.test，这里用4.5节提到的juul数据。\nattach(juul)\rchisq.test(tanner,sex)\r## ## Pearson\u0026#39;s Chi-squared test\r## ## data: tanner and sex\r## X-squared = 28.867, df = 4, p-value = 8.318e-06\r对这两个变量检验独立性或许没什么意义，因为Tanner Stage的定义就是与性别有关的。\n\r练习题\r再来考虑练习题3.3中的情况。其中有连续10个病人进行了手术都没有并发症，而其期望的概率是20%。通过二项分布计算相关的单边检验。需要多大的样本量（仍然完全没有并发症）来使得检验结果变成统计上显著的？\r在美国西部的洛杉矶斑疹热事件中，747例病患死亡了210人，而东部的661例病患中死亡了122人。这个差异在统计上是显著的吗？\r对两种治疗胃溃疡的药物进行比较，结果如下\r\r\r\r\r治愈\r未治愈\r总计\r\r\r\rpirenzepin（哌仑西平）\r23\r7\r30\r\rTrithiozine（三甲硫吗啉）\r18\r13\r31\r\r总计\r41\r20\r61\r\r\r\r计算\\(\\chi^2\\)检验和Fisher精确检验，并讨论它们的不同点。给出治愈率之差的95%置信区间。\n从1968年9月20日至1969年2月1日，一位老师买了254个蛋。他每天都记录在蒸的过程中有多少个蛋破裂到蛋清流出来的程度，以及有多少个蛋破裂但是蛋清没有流出。此外，他还记录了这个蛋尺寸A还是尺寸B。从1969年2月4日至1969你那4月10日，他还买了130个蛋，但是这次他用一个开孔器在蛋上开了个小孔，以防破裂。结果如下：\r\r\r\r周期\r大小\r总计\r破损\r破裂\r\r\r\r9月20日-2月1日\rA\r54\r4\r8\r\r9月20日-2月1日\rB\r200\r15\r28\r\r2月4日-4月10日\rA\r60\r4\r9\r\r2月4日-4月10日\rB\r70\r1\r7\r\r\r\r分析一下这样做是否有效果。\n对于15次试验中有3个成功的现象，在成功概率是\\(x\\)的时候进行双边检验，让\\(x\\)从0到1以0.001为间隔进行变化，并且对检验的\\(p\\)值作图。解释为什么对双边置信区间的定义比较困难。\r\r\r\r","date":1522540800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1522540800,"objectID":"e616932ffc7c551c03bc9143581f0c2d","permalink":"/post/r%E8%AF%AD%E8%A8%80%E7%BB%9F%E8%AE%A1%E5%85%A5%E9%97%A8-%E7%AC%AC%E5%85%AB%E7%AB%A0/","publishdate":"2018-04-01T00:00:00Z","relpermalink":"/post/r%E8%AF%AD%E8%A8%80%E7%BB%9F%E8%AE%A1%E5%85%A5%E9%97%A8-%E7%AC%AC%E5%85%AB%E7%AB%A0/","section":"post","summary":"第八章 表格数据 8.1 单比例 对单比例的检验基于二项分布。在大样本的","tags":["R","统计"],"title":"R语言统计入门-第八章","type":"post"},{"authors":null,"categories":["R","统计"],"content":"\r第七章 方差分析与Kruskal-Wallis检验\r7.1 单因素方差分析\r首先说下单因素方差分析的理论。令\\(x_{ij}\\)表示第\\(i\\)组的第\\(j\\)个观测，\\(\\bar x_i\\)是第\\(i\\)组的均值，而\\(\\bar x_.\\)是所有观测值的均值。 能将一个观测值分解为： \\[\rx_{ij}=\\bar x_.+(\\bar x_i-\\bar x_.)+(x_{ij}-\\bar x_i)\r\\] 其中，\\((\\bar x_i-\\bar x_.)\\)为组内均值与全局均值的差，\\((x_{ij}-\\bar x_i)\\)为观测值与组内均值的差。可以不严格地认为这个公式与下面的模型联系起来： \\[\rX_{ij}=\\mu+\\alpha_i+\\epsilon_{ij}, \\epsilon \\sim N(0,\\sigma^2)\r\\] 假设所有组别的均值都是一样的，那么所有的\\(\\alpha_i\\)都应该是0.注意，假设这里的误差项\\(\\epsilon_{ij}\\)是独立且方差相等的。 现在考虑一下括号这一项的平方和，它被成为组内方差： \\[\rSSD_W=\\sum_{i}\\sum_{j}(x_{ij}-\\bar x_i)^2\r\\] 与组内方差： \\[\rSSD_B=\\sum_{i}\\sum_{j}(\\bar x_i-\\bar x_.)^2=\\sum_{i}n_i(\\bar x_i-\\bar x_.)^2\r\\] 可以证明： \\[\rSSD_B+SSD_W=SSD_{total}=\\sum_{i}\\sum_{j}(x_{ij}-\\bar x_.)^2\r\\] 这意味着全局的方差能够被分解为描述组件均值的部分与描述组内数值的部分。 实际上，在组间没有任何系统差距的情况下，应该期望平方和的分割按照每一项的自由度来进行。\\(SSD_B\\)的自由度为\\(k-1\\)，而\\(SSD_W\\)的自由度为\\(N-k\\)，其中\\(k\\)是组数，\\(N\\)是所有的观测数。 据此，可以计算平均平方来正则化平方和：\n\\[\rMS_W=SSD_W/(N-k)\\\\\rMS_B=SSD_B/(k-1)\r\\] \\(MS_W\\)是将独立的组内方差集成起来的方差，也就是对\\(\\sigma^2\\)的估计。在没有真正的组间差异时，\\(MS_B\\)也是一个对\\(\\sigma^2\\)的估计，单如果出现了组间差异，那么组件均值的差异和\\(MS_B\\)都会变得更大。所以，这可以成为一个通过对两个估计方差的比较来检查组间均值是否有显著差异的检验。这就是我们的目标是比较各组均值，但是名字称为方差分析的原因。 简单的方差分析能在R中通过函数lm来做到，这也是回归分析里面的函数。同时，R也提供了函数aov和lme（linear mixed effects models，即线性混合效应模型，来自于nlime包）。 本节主要用来自于Altman的“红细胞叶酸盐”数据。\nlibrary(ISwR)\rattach(red.cell.folate)\rsummary(red.cell.folate)\r## folate ventilation\r## Min. :206.0 N2O+O2,24h:8 ## 1st Qu.:249.5 N2O+O2,op :9 ## Median :274.0 O2,24h :5 ## Mean :283.2 ## 3rd Qu.:305.5 ## Max. :392.0\r其中，变量ventilation中的属性名称分别表示“24 h内的O2与N2O含量”，“手术中的O2与N2O含量”，以及“24 h内的O2含量”。 接下来要开始做方差分析。通过函数lm得到一个模型对象，然后用函数anova将方差分析表析取出来。\nanova(lm(folate~ventilation))\r## Analysis of Variance Table\r## ## Response: folate\r## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## ventilation 2 15516 7757.9 3.7113 0.04359 *\r## Residuals 19 39716 2090.3 ## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\r在结果第一行找到\\(SSD_B\\)和\\(MS_B\\)，在第二行可以找到\\(SSD_W\\)和\\(MS_W\\)。 值得注意的是，在R中，组间方差用分组属性变量的名字（ventilation）来称呼，而组内方差被称为Residual。 接下来用4.1节提到的juul数据集做下一个例子。\n#这个数据中的变量tanner是数值向量，而不是属性向量\r#对于列出表格而言，这几乎没影响\r#但是这可能造成方差分析出现严重错误\rattach(juul)\ranova(lm(igf1~tanner))\r## Analysis of Variance Table\r## ## Response: igf1\r## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## tanner 1 10985605 10985605 686.07 \u0026lt; 2.2e-16 ***\r## Residuals 790 12649728 16012 ## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\r这并没有描述对数据的分组，而是一个对于分组编号的线性回归。变量tanner的自由度为1，这是在提醒我们。 改正如下：\n#重新板顶数据集juul以便使用新的定义\rjuul$tanner \u0026lt;- factor(juul$tanner,\rlabels = c(\u0026quot;Ⅰ\u0026quot;,\u0026quot;Ⅱ\u0026quot;,\u0026quot;Ⅲ\u0026quot;,\u0026quot;Ⅳ\u0026quot;,\u0026quot;Ⅴ\u0026quot;))\rdetach(juul)\rattach(juul)\rsummary(tanner)\r## Ⅰ Ⅱ Ⅲ Ⅳ Ⅴ NA\u0026#39;s ## 515 103 72 81 328 240\ranova(lm(igf1~tanner))\r## Analysis of Variance Table\r## ## Response: igf1\r## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## tanner 4 12696217 3174054 228.35 \u0026lt; 2.2e-16 ***\r## Residuals 787 10939116 13900 ## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\r一个被绑定的数据框是它本身的一个复制品，Df这一列为tanner分配了4个自由度，这是它应得的。\n7.1.1 成对比较和多重检验\r如果 F 检验告诉我们组间有差异，那么问题马上升为找出差异在哪里。这时候就有必要对单个组进行比较。 能通过summary析取出回归系数以及它们的标准误和 t 检验统计量。这些系数的意义并不是通常的回归线斜率，而是有如下的特定解释：\nsummary(lm(folate~ventilation))\r## ## Call:\r## lm(formula = folate ~ ventilation)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -73.625 -35.361 -4.444 35.625 75.375 ## ## Coefficients:\r## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 316.62 16.16 19.588 4.65e-14 ***\r## ventilationN2O+O2,op -60.18 22.22 -2.709 0.0139 * ## ventilationO2,24h -38.62 26.06 -1.482 0.1548 ## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\r## ## Residual standard error: 45.72 on 19 degrees of freedom\r## Multiple R-squared: 0.2809, Adjusted R-squared: 0.2052 ## F-statistic: 3.711 on 2 and 19 DF, p-value: 0.04359\r这些估计值应该这样理解： 截距这一项是第一组（N2O+O2，24 h）的均值，而另外两个是相应组均值与第一组均值的差。 如果比较所有的组别，应该进行多重检验的修正。进行多次检验，会增加其中出现一个显著结果的概率，也就是说，这个 p 值会变得夸张。一个常用的调整方法是Bonferroni修正法。它基于这个事实：在 n 个时间里至少观测到一个事件的概率小于每个事件的概率之和。所以，让显著性水平去除或是等价地用 p 值去乘检验次数，能够得到一个保守的检验，其中显著的结果会少于或等于之前的显著性水平。 函数pairwise.t.test能计算所有的两组比较。它也能针对多重检验做调整，比如这样：\npairwise.t.test(folate,ventilation,p.adj=\u0026quot;bonferroni\u0026quot;)\r## ## Pairwise comparisons using t tests with pooled SD ## ## data: folate and ventilation ## ## N2O+O2,24h N2O+O2,op\r## N2O+O2,op 0.042 - ## O2,24h 0.464 1.000 ## ## P value adjustment method: bonferroni\r输出结果是一个成对比较的 p 值表。这里的 p 值已经通过Bonferroni修正过了，即通过未修正的 p 值乘上检验的次数3而得到的。如果得到一个大于1的结果，那么调整过程会将调整过的 p 值设为1。 函数pairwise.t.test的默认设置不是Bonferroni调整法，而是Holm提出的一个变形。在这个方法中，只有最小的 p 值需要乘以所有检验的次数，而第二小的则乘以\\(n-1\\)，以此类推，除非这一步骤让它比前一个数更小了，因为 p 值的顺序不应该被调整而改变。\npairwise.t.test(folate, ventilation)\r## ## Pairwise comparisons using t tests with pooled SD ## ## data: folate and ventilation ## ## N2O+O2,24h N2O+O2,op\r## N2O+O2,op 0.042 - ## O2,24h 0.310 0.408 ## ## P value adjustment method: holm\r\r7.1.2 放宽对方差的假设\r传统的单因素方差分析需要假设所有的组方差相等。不过，有另一个不需要这个假设的方法。函数oneway.test可以实现。\noneway.test(folate~ventilation)\r## ## One-way analysis of means (not assuming equal variances)\r## ## data: folate and ventilation\r## F = 2.9704, num df = 2.000, denom df = 11.065, p-value = 0.09277\r在这个例子中，p值增大到了一个不显著的值，可能是因为看起来与另外两组不等的组别也有着最大的方差。 也可以进行成对 t检验，使得它们不需要用一个综合的标准差。可以通过参数pool.sd来控制。\npairwise.t.test(folate, ventilation, pool.sd = F)\r## ## Pairwise comparisons using t tests with non-pooled SD ## ## data: folate and ventilation ## ## N2O+O2,24h N2O+O2,op\r## N2O+O2,op 0.087 - ## O2,24h 0.321 0.321 ## ## P value adjustment method: holm\r可以再一次看到，结果在去除对方差的限制后就变得不显著了。\n\r7.1.3 图像表示\r#这这里展示一个图形，原始数据用条形图\r#然后叠加上均值与SEM的值\rxbar \u0026lt;- tapply(folate,ventilation,mean)\rs \u0026lt;- tapply(folate,ventilation,sd)\rn \u0026lt;- tapply(folate,ventilation,length)\rsem \u0026lt;- s/sqrt(n)\r#在stripchart函数中设定为小圆点，即pch=16\r#并通过vertical=T使长条变成垂直的\rstripchart(folate~ventilation,method=\u0026quot;jitter\u0026quot;,\rjitter=0.05,pch=16,vert=T)\r#误差线用arrows来添加，这个函数在图上添加箭头，修改下就可以了\r#前四个参数表示断点（x1，y1，x2，y2）\r#参数angle指的是箭头与箭柄之间的角度，这里为90°\r#参数code=3表示两端都要有箭头\r#参数length值得是箭头的长度（打印时的尺寸）\rarrows(1:3,xbar+sem,1:3,xbar-sem,angle = 90,code = 3,length = .1)\r#显示均值与连接线可以通过函数lines来表示\r#参数type=“b”表示同时画出点和线，然后在线与线之间给符号留下空间\r#参数pch=4是一个交叉十字\r#参数cex=2让这些符号变成两倍大\rlines(1:3,xbar,pch=4,type = \u0026quot;b\u0026quot;,cex=2)\r\r7.1.4 Bartlett检验\r可以用Bartlett检验来看看某个变量的分布是否在所有组中都有一样的方差。虽然与 F 检验一样都能比较两个方差，但它对正态分布的假设是不稳定的。与函数var.test一样，它假设了来自不同组的数据时独立的。\nbartlett.test(folate~ventilation)\r## ## Bartlett test of homogeneity of variances\r## ## data: folate by ventilation\r## Bartlett\u0026#39;s K-squared = 2.0951, df = 2, p-value = 0.3508\r\r\r7.2 Kruskal-Wallis检验\rKruskal-Wallis是方差分析的非参数版本。基本上与Wilcoxon一样，不过这次检验的计算基于各组与平均秩的离差平方和。我们又一次能够利用分组独立性的假设，这样检验统计量的分布可以变成一个组合的问题，即对一组固定的数字抽样而得的组内秩。\nkruskal.test(folate~ventilation)\r## ## Kruskal-Wallis rank sum test\r## ## data: folate by ventilation\r## Kruskal-Wallis chi-squared = 4.1852, df = 2, p-value = 0.1234\r可以看出，这个检验没有表现出显著的差异。另外Kruskal-Wallis检验在假设成立的情况下没有参数方法那么高效，虽然它并不总是会给出较大的 p 值。\n\r7.3 双因素方差分析\r令\\(x_{ij}\\)表示一个\\(m\\times n\\)表的第\\(i\\)行第\\(j\\)列的观测值。这与单因素方差分析的记号一样，不过现在同一个\\(j\\)对应的观测之间都有联系，所以自然会查看每行的均值\\(\\bar x_{i.}\\)与每列的均值\\(\\bar x_{.j}\\)。 接着，可以查看行间方差： \\[\rSSD_R=n\\sum_{i}(\\bar x_{i.}-\\bar x_{..})^2\r\\] 与列间方差： \\[\rSSD_C=m\\sum_{j}(\\bar x_{.j}-\\bar x_{..})^2\r\\] 从总的方差中减去这两部分，就得到了残差方差： \\[\rSSD_{res}=\\sum_{i}\\sum_{j}(x_{ij}-\\bar x_{i.}-\\bar x_{.j}+\\bar x_{..})\r\\] 这可以表达为一个统计模型，其中观测由整体水平，行效应，列效应以及噪声项四部分组成： \\[\rX_{ij}=\\mu+\\alpha_i+\\beta_j+\\epsilon_{ij} \\qquad \\epsilon_{ij}\\sim N(0,\\sigma^2)\r\\] 除非引入一些对参数的限制，否则这个模型中的参数并不是唯一定义的。如果引入\\(\\sum \\alpha_i=0\\)和\\(\\sum\\beta_j=0\\)，那么对\\(\\alpha_i\\)，\\(\\beta_j\\)和\\(\\mu\\)的估计就变成了\\(\\bar x_{i.}-\\bar x_{..}\\)，\\(\\bar x_{.j}-\\bar x_{..}\\)和\\(\\bar x_{..}\\)。 将平方和项厨艺各自的自由度：SSDR的是\\(m-1\\)，SSDC的是 \\(n-1\\)，SSDres的是\\((m-1)(n-1)\\)：然后我们就得到了一系列平均平方。行影响和列影响的 F 检验可以通过用对应的平均平方除以残差平均平方进行。 双因素方差分析需要将数据放在一个向量中，以及与其平行的两个分类属性。以一个使用enalaprilate之后的心率数据作为例子，即数据集heart.rate。\nattach(heart.rate)\rheart.rate\r## hr subj time\r## 1 96 1 0\r## 2 110 2 0\r## 3 89 3 0\r## 4 95 4 0\r## 5 128 5 0\r## 6 100 6 0\r## 7 72 7 0\r## 8 79 8 0\r## 9 100 9 0\r## 10 92 1 30\r## 11 106 2 30\r## 12 86 3 30\r## 13 78 4 30\r## 14 124 5 30\r## 15 98 6 30\r## 16 68 7 30\r## 17 75 8 30\r## 18 106 9 30\r## 19 86 1 60\r## 20 108 2 60\r## 21 85 3 60\r## 22 78 4 60\r## 23 118 5 60\r## 24 100 6 60\r## 25 67 7 60\r## 26 74 8 60\r## 27 104 9 60\r## 28 92 1 120\r## 29 114 2 120\r## 30 83 3 120\r## 31 83 4 120\r## 32 118 5 120\r## 33 94 6 120\r## 34 71 7 120\r## 35 74 8 120\r## 36 102 9 120\r如果打开程序包ISwR里data路径下的heart.rate.R文件，就会看到数据框的实际定义是这样的：\nheart.rate \u0026lt;- data.frame(hr = c(96,110,89,95,128,100,72,79,100,\r92,106,86,78,124,98,68,75,106,\r86,108,85,78,118,100,67,74,104,\r92,114,83,83,118,94,71,74,102),\rsubj=gl(9,1,36),\rtime=gl(4,9,36,labels=c(0,30,60,120)))\r函数gl（generate levels）能生成模式属性，专门为平衡的试验涉及而出现。它有3个参数：水平的数目，每块长度（每一水平重复多少次），以及结果的总长度。所以数据框的两个模式就是：\ngl(9,1,36)\r## [1] 1 2 3 4 5 6 7 8 9 1 2 3 4 5 6 7 8 9 1 2 3 4 5 6 7 8 9 1 2 3 4 5 6 7 8\r## [36] 9\r## Levels: 1 2 3 4 5 6 7 8 9\rgl(4,9,36,labels=c(0,30,60,120))\r## [1] 0 0 0 0 0 0 0 0 0 30 30 30 30 30 30 30 30 ## [18] 30 60 60 60 60 60 60 60 60 60 120 120 120 120 120 120 120\r## [35] 120 120\r## Levels: 0 30 60 120\r一旦变量被定义好了，双因素方差分析就可以简单地如下计算：\nanova(lm(hr~subj+time))\r## Analysis of Variance Table\r## ## Response: hr\r## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## subj 8 8966.6 1120.82 90.6391 4.863e-16 ***\r## time 3 151.0 50.32 4.0696 0.01802 * ## Residuals 24 296.8 12.37 ## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\r在模式方程（hr~subj+time）中交换subj和time能产生一模一样的分析结果，除了方差分析表中两行的顺序有变化。这是因为在处理一个平衡的设计（一个没有缺失值的完全双因素表）。在不平衡的情况下，属性的顺序会有很大影响。\n7.3.1 重复试验的图像\r在给自己用的时候，做一个意大利面图是很有用的。在这种图中，来自同一个个体的数据被线段连在了仪器。可以使用函数interaction.plot。\n#interaction.plot这个函数以一个属性为横轴，将另一个属性的数据画出来并用线段标记轨迹\rinteraction.plot(time,subj,hr)\r#实际上还有第四个参数，用来指示程序怎么处理不止一个观测的格子\r#默认情况下，它会选择去平均数\r#这就是为什么这个图中y周意义为hr均值\r#如果更喜欢依照擦亮的时序来画图，可以修改如下：\rinteraction.plot(ordered(time),subj,hr)\r\r\r7.4 Friedman检验\r双因素方差分析在每格含有一个观测的情况下有一个非参数版本。Friedman的检验基于每行观测的秩。如果没有列间效应的影响，那么每一行的秩应该都是一样的。一个基于每列平方和的检验可以通过计算与正规化变为一个服从卡方分布的统计量。 在两列的情况下，Friedman检验与符号检验是等价的，这时可以通过二项分布来检验正号对以及负号对的概率是否相等\n#注意，区组属性在模型方程中用垂直线标明了，这种记法可被读成在subj情况下的time\rfriedman.test(hr~time | subj,data = heart.rate)\r## ## Friedman rank sum test\r## ## data: hr and time and subj\r## Friedman chi-squared = 8.5059, df = 3, p-value = 0.03664\r\r7.5 回归分析中的方差分析表\r单因素方差分析中的组间和组内波动可以被推广为模型方差和残差方差： \\[\rSSD_{model}=\\sum_{i}(\\hat y_i-\\hat y_.)^2 \\\\\rSSD_{res}=\\sum_{i}(y_i-\\hat y_i)^2\r\\] 这两部分分割了整体的波动\\(\\sum_{i}(\\hat y_i-\\hat y_.)^2\\)。这仅在模型含有一个截距项的时候成立。 与7.1节中的相似，可以用一个 F* 检验对模型的显著性做检验。在简单线性回归中，这与检验回归系数是否为0是等价的。 与单因素和双因素方差分析一样，能用函数anova将一个回归分析的方差分析表导出来。在thuesen中，可以这样操作：\nattach(thuesen)\rlm.velo \u0026lt;- lm(short.velocity~blood.glucose)\ranova(lm.velo)\r## Analysis of Variance Table\r## ## Response: short.velocity\r## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## blood.glucose 1 0.20727 0.207269 4.414 0.0479 *\r## Residuals 21 0.98610 0.046957 ## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\r\r练习题\r数据zelazo的格式是一个由向量构成的列表，它们分别代表四个组。将这个数据转化为函数lm可用的形式，然后进行相关性检验。考虑用 t检验比较选择的两个组，或者是先将组合并。\r在数据lung中，三种不同的测量方法是否给出了系统性不同的结果，如果是，那么是哪个组表现的不同。\r用非参数方法对数据zelazo和lung重复前两个练习。\r数据juul中的变量igf1有明显的偏斜，并且与Tanner组的方差不一样，尝试通过对数变换与平方根变换来补偿这一点，以及使用Welch检验，即便如此，这个分析仍有问题，为什么？\r\r\r\r","date":1522368000,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1522368000,"objectID":"aa67001c76d5fdc43fddf302e84a4c19","permalink":"/post/r%E8%AF%AD%E8%A8%80%E7%BB%9F%E8%AE%A1%E5%85%A5%E9%97%A8-%E7%AC%AC%E4%B8%83%E7%AB%A0/","publishdate":"2018-03-30T00:00:00Z","relpermalink":"/post/r%E8%AF%AD%E8%A8%80%E7%BB%9F%E8%AE%A1%E5%85%A5%E9%97%A8-%E7%AC%AC%E4%B8%83%E7%AB%A0/","section":"post","summary":"第七章 方差分析与Kruskal-Wallis检验 7.1 单因素方差","tags":["R","统计"],"title":"R语言统计入门-第七章","type":"post"},{"authors":null,"categories":["R","统计"],"content":"\r第六章 回归于相关性\r6.1 简单线性回归\r线性回归模型是如下定义的： \\[\ry_i=\\alpha+\\beta x_i+\\epsilon_i\r\\] 其中，假设\\(\\epsilon_i\\)是独立的，并且来自于\\(N(0,\\sigma^2)\\)。这个方程非随机的部分用一条直线描述\\(y_i\\)。这条直线的斜率（回归系数）是\\(\\beta\\)，即\\(x\\)的每变化一单位给\\(y\\)所带来的增长。这条线与\\(y\\)轴交于截距点\\(\\alpha\\)。\n系数\\(\\alpha\\)，\\(\\beta\\)和\\(\\sigma^2\\)都能用最小二乘法来估计。找到让残差平方和最小的\\(\\alpha\\)，\\(\\beta\\)： \\[\rSS_{res}=\\sum_{i}[y_i-(\\alpha+\\beta x_i)]^2\r\\] 对于这些参数，能够推出使得SSres最小的显式表达式： \\[\r\\hat \\beta=\\frac{\\sum(x_i-\\bar x)(y_i-\\bar y)}{\\sum(x_i-\\bar x)^2}\r\\]\n\\[\r\\hat\\alpha =\\bar y-\\hat \\beta\\bar x\r\\]\n残差的方差可以通过SSres/(n-2)来估计，标准差自然是这个值的平方根。\n本节使用thuesen作为例子\nlibrary(ISwR)\rattach(thuesen)\r#使用函数lm（线性模型）进行线性回归分析\r#lm里面的参数是模型方程，波浪号~读作通过……来描述\rlm(short.velocity ~ blood.glucose)\r## ## Call:\r## lm(formula = short.velocity ~ blood.glucose)\r## ## Coefficients:\r## (Intercept) blood.glucose ## 1.09781 0.02196\r函数lm的原始输出格式非常简单，只有估计出来的截距α和斜率β。可以看到最优拟合直线为short.velocity=1.098+0.0220*blood.glucose，但是没有给出任何像显著性检验之类的其他信息。\nlm的输出结果是一个模型对象。能够通过用析取函数来得到想要的结果。\n#一个基本的析取函数是summary\rsummary(lm(short.velocity ~ blood.glucose))\r## ## Call:\r## lm(formula = short.velocity ~ blood.glucose)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -0.40141 -0.14760 -0.02202 0.03001 0.43490 ## ## Coefficients:\r## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 1.09781 0.11748 9.345 6.26e-09 ***\r## blood.glucose 0.02196 0.01045 2.101 0.0479 * ## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\r## ## Residual standard error: 0.2167 on 21 degrees of freedom\r## (1 observation deleted due to missingness)\r## Multiple R-squared: 0.1737, Adjusted R-squared: 0.1343 ## F-statistic: 4.414 on 1 and 21 DF, p-value: 0.0479\r下面对输出结果进行解剖：\ncall：\nlm(formula = short.velocity ~ blood.glucose)\n与t.test中相似，输出的开头本质上在重复一个函数调用，若用户只是在R中将其输出，那么这部分意义不大。但是如果结果被保存在一个变量中，之后查看输出的时候，这部分就很有用了。\nResiduals:\n\u000bmin 1Q Median 3Q Max\n\u000b-0.40141 -0.14760 -0.02202 0.03001 0.43490\n这部分简单的描述了残差的分布，可以帮助用户对分不行的假设做快速检查。根据定义，残差的均值是0，所以中位数应该离0不远，然后最大值、最小值的绝对值也应该大致相当。这个例子中，第三分位数明显过于接近0，不过考虑到这里样本量不多，所以无须太过担心。\nCoefficients:\n\u000bEstimate Std. Error t value Pr(\u0026gt;|t|)\n(Intercept) 1.09781 0.11748 9.345 6.26e-09 ***\nblood.glucose 0.02196 0.01045 2.101 0.0479 *\n这里再次见到了回归系数和截距，不过这次还伴随着标准误， t 检验和 p 值。最右边的符号是显著性水平。这个符号可以通过options(show.signif.stars=FALSE)来关闭。\nResidual standard error: 0.2167 on 21 degrees of freedom\n(1 observation deleted due to missingness)\n这是残差的波动情况，通过观测值在回归线附近的波动情况来估计模型参数σ。因为short.velocity有一个缺失值，所以这个模型并没有对整个数据集进行拟合。\nMultiple R-squared: 0.1737， Adjusted R-squared: 0.1343\n第一个是R2，在简单线性回归中能将其理解为Person相关参数的平方，即R2=r2。另一个是修正后R2；如果将其乘上100%，它就可以被理解为“方差降低的百分率”。\nF-statistic: 4.414 on 1 and 21 DF, p-value: 0.0479\n这是对假设回归系数是0而进行的F检验。这个检验在简单线性回归中并不特别，因为它只是对已有信息的重复——它在解释变量不止一个时就变得更有意义了。注意，这里的结果与斜率的 t 检验结果一模一样。实际上，F 检验是 t 检验的平方：4.414=(2.101)2。\n#这里展示如何画出残差图\r#首先把数据点和回归线画出来\rplot(blood.glucose, short.velocity)\rabline(lm(short.velocity ~ blood.glucose))\r#abline函数就是(a,b)-线段的意思。根据截距α和斜率β画一条直线\r#它能够接受数值参数，比如abline(1.1, 0.022)\r\r6.2 残差与回归值\r已经用summary从回归分析的结果中提取更多信息。另外两个进一步的析取函数是fitted和resid。它们的用法如下。为了方便，将lm的返回值存入变量lm.velo中。\nlm.velo \u0026lt;- lm(short.velocity ~ blood.glucose)\r#函数fitted返回的是回归值\r#即根据最佳拟合直线与给定的x值计算出来的y值\r#对于这个结果就是1.098+0.0220*blood.glucose\rfitted(lm.velo)\r## 1 2 3 4 5 6 7 8 ## 1.433841 1.335010 1.275711 1.526084 1.255945 1.214216 1.302066 1.341599 ## 9 10 11 12 13 14 15 17 ## 1.262534 1.365758 1.244964 1.212020 1.515103 1.429449 1.244964 1.190057 ## 18 19 20 21 22 23 24 ## 1.324029 1.372346 1.451411 1.389916 1.205431 1.291085 1.306459\r#函数resid显示的残差是short.velocity的回归值与观测值之差\rresid(lm.velo)\r## 1 2 3 4 5 ## 0.326158532 0.004989882 -0.005711308 -0.056084062 0.014054962 ## 6 7 8 9 10 ## 0.275783754 0.007933665 -0.251598875 -0.082533795 -0.145757649 ## 11 12 13 14 15 ## 0.005036223 -0.022019994 0.434897199 -0.149448964 0.275036223 ## 17 18 19 20 21 ## -0.070057471 0.045971143 -0.182346406 -0.401411486 -0.069916424 ## 22 23 24 ## -0.175431237 -0.171085074 0.393541161\r注意的是，回归值与残差都带着数据框thuesen的行名。同时，都没有第16个观测值的信息，因为原数据在这里缺少相应变量的值。\n在这里有必要讨论缺少数据时出现的一些问题。\n虽然用abline(lm.velo)更方便，可能仍会想到用lines将回归线画在图上，不过：\n#plot(blood.glucose,short.velocity)\r#lines(blood.glucose,fitted(lm.velo))\r#Error in xy.coords(x, y) : \u0026#39;x\u0026#39; and \u0026#39;y\u0026#39; lengths differ\r#Calls: local ... eval -\u0026gt; lines -\u0026gt; lines.default -\u0026gt; plot.xy -\u0026gt; xy.coords\r就会出现这个情况，一共有24个观测值，但其中只有23个回归值，因为short.velocity的值是NA。碰巧的是，这个错误在一串交织在一起的函数调用中出现，它们都在报错信息中标出来以便于理解。\n我们需要的是blood.glucose，但是需要病人的short.velocity也被记录了才行。\n#函数is.na能够产生一个向量，在参数为NA的对应位置上标记为TRUE\r#这个方法的好处之一就是回归线不会超过数据的范围\r#lines(blood.glucose [!is.na(short.velocity)],fitted(lm.velo))\r#但是在许多个变量中都有缺失值的时候就变得很繁琐\r#...blood.glucose[!is.na(short.velocity) \u0026amp; !is.na(blood.glucose)]...\r#用函数complete.cases更简单\r#它能够筛选出在若干个变量甚至是整个数据框中都没有缺失值的观测\rcc \u0026lt;- complete.cases(thuesen)\r#然后就能用thuesen[cc,]来进行分析了\r#不过有更好的方法\r#可以用na.exclude方法处理缺失值\r#它既可以作为lm的一个参数，也可以作为一个选项\roptions(na.action=na.exclude)\rlm.velo \u0026lt;- lm(short.velocity ~ blood.glucose)\rfitted(lm.velo)\r## 1 2 3 4 5 6 7 8 ## 1.433841 1.335010 1.275711 1.526084 1.255945 1.214216 1.302066 1.341599 ## 9 10 11 12 13 14 15 16 ## 1.262534 1.365758 1.244964 1.212020 1.515103 1.429449 1.244964 NA ## 17 18 19 20 21 22 23 24 ## 1.190057 1.324029 1.372346 1.451411 1.389916 1.205431 1.291085 1.306459\r#注意的是，第16个观测带有一个缺失值出现了\r#在改变了选项后，有必要重新计算lm.velo\r#为了在一幅图中通过将观测值与对应的回归值连起来而显示出残差\r#函数segments用来画线段，它的参数是两端断点的坐标（x1,y1,x2,y2）\r#但需要注意，segments函数不能单独使用，需要先plot一个图\r#以下的plot与abline前文中已经有了，但是在RMD中最好还是重新调用下\rplot(blood.glucose,short.velocity)\rabline(lm(short.velocity ~ blood.glucose))\rsegments(blood.glucose,fitted(lm.velo),\rblood.glucose,short.velocity)\r#也能通过Q-Q图的线性性来检验残差的正态性\rqqnorm(resid(lm.velo))\r\r6.3 预测与置信带\r回归线通常与不确切的边界带一起展示。一般有两种边界带，通常被称为“窄”边界和“宽”边界。 窄边界，又叫置信带，反映了这条线本身的不确定性，就像SEM反映了一个已知均值的准确度。如果观测数量很多的话，这个边界会很窄，这意味着这是一个比较准确的线。这个边界通常有明显的弧度，因为回归线在点阵的中心通常更准确。 宽边界，又叫预测带，包含了未来观测值的不确定性。这些边界关心大部分数据，同时不会随着观测数量的增加而缩成一条线。这个边界是由回归线±2倍的标准差（95%的水平）而得到的。在小样本情况下，这个边界也是有弧度的，因为它们包含了这条直线本身的不确定性，只不过这个弧度没有置信带的那么明显。很显然，这些边界十分依赖残差正态性以及方差齐性的假设，所以如果你的数据不太满足这些性质，那么最好不要用这个边界。 无论是否计算了置信带与预测带，我们都能用函数predict析取出预测值。不加其他参数的话，它就只会输出回归值。\npredict(lm.velo)\r## 1 2 3 4 5 6 7 8 ## 1.433841 1.335010 1.275711 1.526084 1.255945 1.214216 1.302066 1.341599 ## 9 10 11 12 13 14 15 16 ## 1.262534 1.365758 1.244964 1.212020 1.515103 1.429449 1.244964 NA ## 17 18 19 20 21 22 23 24 ## 1.190057 1.324029 1.372346 1.451411 1.389916 1.205431 1.291085 1.306459\r#如果加上参数，interval=\u0026quot;confidence\u0026quot;或者interval=\u0026quot;prediction\u0026quot;\r#那么就能在预测值向量的基础上获得边界的值。这个补充描述也可以用缩写\rpredict(lm.velo,int=\u0026quot;c\u0026quot;)\r## fit lwr upr\r## 1 1.433841 1.291371 1.576312\r## 2 1.335010 1.240589 1.429431\r## 3 1.275711 1.169536 1.381887\r## 4 1.526084 1.306561 1.745607\r## 5 1.255945 1.139367 1.372523\r## 6 1.214216 1.069315 1.359118\r## 7 1.302066 1.205244 1.398889\r## 8 1.341599 1.246317 1.436881\r## 9 1.262534 1.149694 1.375374\r## 10 1.365758 1.263750 1.467765\r## 11 1.244964 1.121641 1.368287\r## 12 1.212020 1.065457 1.358583\r## 13 1.515103 1.305352 1.724854\r## 14 1.429449 1.290217 1.568681\r## 15 1.244964 1.121641 1.368287\r## 16 NA NA NA\r## 17 1.190057 1.026217 1.353898\r## 18 1.324029 1.230050 1.418008\r## 19 1.372346 1.267629 1.477064\r## 20 1.451411 1.295446 1.607377\r## 21 1.389916 1.276444 1.503389\r## 22 1.205431 1.053805 1.357057\r## 23 1.291085 1.191084 1.391086\r## 24 1.306459 1.210592 1.402326\rpredict(lm.velo,int=\u0026quot;p\u0026quot;)\r## Warning in predict.lm(lm.velo, int = \u0026quot;p\u0026quot;): predictions on current data refer to _future_ responses\r## fit lwr upr\r## 1 1.433841 0.9612137 1.906469\r## 2 1.335010 0.8745815 1.795439\r## 3 1.275711 0.8127292 1.738693\r## 4 1.526084 1.0248161 2.027352\r## 5 1.255945 0.7904672 1.721423\r## 6 1.214216 0.7408499 1.687583\r## 7 1.302066 0.8411393 1.762993\r## 8 1.341599 0.8809929 1.802205\r## 9 1.262534 0.7979780 1.727090\r## 10 1.365758 0.9037136 1.827802\r## 11 1.244964 0.7777510 1.712177\r## 12 1.212020 0.7381424 1.685898\r## 13 1.515103 1.0180367 2.012169\r## 14 1.429449 0.9577873 1.901111\r## 15 1.244964 0.7777510 1.712177\r## 16 NA NA NA\r## 17 1.190057 0.7105546 1.669560\r## 18 1.324029 0.8636906 1.784367\r## 19 1.372346 0.9096964 1.834996\r## 20 1.451411 0.9745421 1.928281\r## 21 1.389916 0.9252067 1.854626\r## 22 1.205431 0.7299634 1.680899\r## 23 1.291085 0.8294798 1.752690\r## 24 1.306459 0.8457315 1.767186\r结果中fit变量表示了期望得到的值，在这里就等于回归值，而lwr和upr就分别是下界和上界，即对那些blood.glucose取此值的病人预测short.velocity时的边界。警告信息并不是说有什么做错了，而是提醒这里有一个陷阱：这个边界不能被用来考量我们用来做回归的已观测数据。因为在x的极值处，数据影响力更大，所以这会导致这些地方的边界离回归线更近，也就是说，预测带弯向了错误的方向。 将置信带与预测带加到散点图上的最好方法是通过函数matlines，它能将矩阵的每一列以某一个向量作为x轴画出来。 不过，有几个小障碍： + blood.glucose的值是随机排列的，不希望置信曲线上的线段杂乱无章的排列； + 下方的预测区间超出了画图区域； + matlines的命令需要放置不停更迭的线段样式和颜色。 解决方法是用合适的x（这里是blood.glucose）生成一个新数据框，然后在新数据框上进行预测：\n#用希望进行预测的blood.glucose值生成了一个新的数据框\rpred.frame \u0026lt;- data.frame(blood.glucose=4:20)\r#pp和pc用来记录predict函数在pred.frame上的结果，并且保留了预测带和置信带\rpp \u0026lt;- predict(lm.velo, int=\u0026quot;p\u0026quot;, newdata = pred.frame)\rpc \u0026lt;- predict(lm.velo, int=\u0026quot;c\u0026quot;, newdata = pred.frame)\r#先plot画一个标准的散点图，并为预测带预留了足够的空间，即参数ylim\r#函数range返回一个长度为2的向量，其中是传入参数的最大值和最小值\r#并需要使用na.rm=T在计算中忽略缺失值\rplot(blood.glucose,short.velocity,\rylim = range(short.velocity,pp,na.rm = T))\rpred.gluc \u0026lt;- pred.frame$blood.glucose\rmatlines(pred.gluc,pc,lty = c(1,2,2),col = \u0026quot;black\u0026quot;)\rmatlines(pred.gluc,pp,lty = c(1,3,3),col = \u0026quot;green\u0026quot;)\r\r6.4 相关性\r相关系数是一个对称并且不随尺度变化的量，用于衡量两个随机变量之间的关联程度。它的值域是-1到1，这两个极端表示完美的相关，0则表示没有相关性。一个变量的较大值与另一个变量的较小值有关联时，相关系数是负的；如果两个变量有同时变大或减小的趋势，那么相关系数是负的。\n6.4.1 皮尔逊相关系数\r皮尔逊相关系数扎根于二维正态分布中，其中理论上的相关性描述了密度函数的椭圆等高线。如果两个变量的方差都变换成了1，那么相关系数为0就对应圆形的等高线，其他情况下，椭圆变得越来越窄，最后在相关系数等于±1的时候坍缩成一条直线。 经验相关系数是： \\[\rr=\\frac{\\sum(x_i-\\bar x)(y_i-\\bar y)}{\\sqrt{\\sum(x_i-\\bar x)^2\\sum(y_i-\\bar y)}}\r\\] 可以证明，在\\(x_i\\)和\\(y_i\\)没有完美线性相关的情况下，\\(\\left| r \\right|\\)恒小于1，皮尔逊相关系数也因此又是被称为“线性相关系数”。 函数cor能计算两个或多个向量之间的相关系数。但如果对thuesen中的两个向量也这样操作，就会出现下面情况：\ncor(blood.glucose,short.velocity)\r## [1] NA\r#Error in cor(blood.glucose,short.velocity):\r# missing observations in cov/cor\rR中所有的基本统计函数都要求输入的参数没有缺失值，或者要明确指定如何处理缺失值。对于函数mean，var，sd以及类似的单向量函数，可以传递na.rm=T这个参数告诉它们在计算之前应该移除缺失值。对于函数cor，可以写成：\ncor(blood.glucose,short.velocity,use = \u0026quot;complete.obs\u0026quot;)\r## [1] 0.4167546\r函数cor不使用na.rm=T，因为在移除缺失值与计算出错之外还有很多其他可能性。如果要对超过两个变量进行计算，也能用所有非缺失值对的信息来进行计算。 可以通过如下代码得到一个数据框中所有变量的相关系数矩阵：\ncor(thuesen,use = \u0026quot;complete.obs\u0026quot;)\r## blood.glucose short.velocity\r## blood.glucose 1.0000000 0.4167546\r## short.velocity 0.4167546 1.0000000\r但是，上面的计算并没有告诉我们这个相关系数是不是显著不为0的。为做到这点，需要使用cor.test，可以通过指定两个变量来使用它：\ncor.test(blood.glucose,short.velocity)\r## ## Pearson\u0026#39;s product-moment correlation\r## ## data: blood.glucose and short.velocity\r## t = 2.101, df = 21, p-value = 0.0479\r## alternative hypothesis: true correlation is not equal to 0\r## 95 percent confidence interval:\r## 0.005496682 0.707429479\r## sample estimates:\r## cor ## 0.4167546\r\r6.4.2 斯皮尔曼相关系数\r同样也有非参数的方法。即斯皮尔曼秩相关系数\\(\\rho\\)。它将观测值替换为它们的秩，再计算相关系数。在两变量独立的零假设下，可以计算出\\(\\rho\\)的精确分布。 与之前一个函数对应一个检验不同，相关性检验的集中方法都打包进了cor.test中。\ncor.test(blood.glucose,short.velocity,method = \u0026quot;spearman\u0026quot;)\r## Warning in cor.test.default(blood.glucose, short.velocity, method =\r## \u0026quot;spearman\u0026quot;): Cannot compute exact p-value with ties\r## ## Spearman\u0026#39;s rank correlation rho\r## ## data: blood.glucose and short.velocity\r## S = 1380.4, p-value = 0.1392\r## alternative hypothesis: true rho is not equal to 0\r## sample estimates:\r## rho ## 0.318002\r\r6.4.3 肯德尔等级相关系数τ\r第三个可供选择的算法是肯德尔等级相关系数，这个算法基于统计一致对和不一致对的数量。如果x坐标之差的符号与y坐标之差是一致的，那么这一对点是个一致对。在一个完美的单调关系中，所有的点对要么都是一致的；要么都是不一致的。在独立的情况下，一致对和不一致对的数量应该一样多。 相关系数\\(\\tau\\)的一大优点是其意义比斯皮尔曼更好解释，但是除此之外，就没有什么优于对方的特点了。\ncor.test(blood.glucose,short.velocity,method = \u0026quot;kendall\u0026quot;)\r## Warning in cor.test.default(blood.glucose, short.velocity, method =\r## \u0026quot;kendall\u0026quot;): Cannot compute exact p-value with ties\r## ## Kendall\u0026#39;s rank correlation tau\r## ## data: blood.glucose and short.velocity\r## z = 1.5604, p-value = 0.1187\r## alternative hypothesis: true tau is not equal to 0\r## sample estimates:\r## tau ## 0.2350616\r\r\r练习题\r在rmr数据集中，画出代谢率关于体重的散点图。对这个关系拟合一个曲线。这个模型预测70 kg的体重对应的代谢率是多少？对这条线的斜率给出一个95%置信区间。\r在juul数据集中，拟合一个IGF-I集中度的平方根关于25岁以上人群年龄的线性回归模型。\r在malaria数据集中，分析对数变换后的antibody水平关于年龄的关系。画出一个关系图。\r一个人能够这样对指定\\(\\rho\\)的二维正态分布中生成模拟数据：（a）以均值为0，标准差为1的正态分布生成\\(X\\);（b）以均值为\\(\\rho X\\)，标准差为\\(\\sqrt{1-\\rho^2}\\)的正态分布生成\\(Y\\)。对于指定的相关系数，用这个方法画出模拟数据的散点图。计算部分数据的斯皮尔曼相关系数与肯德尔等级相关系数。\r\r\r\r","date":1521504000,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1521504000,"objectID":"7b8f628b797cc2e71d91ef2f709a92b5","permalink":"/post/r%E8%AF%AD%E8%A8%80%E7%BB%9F%E8%AE%A1%E5%85%A5%E9%97%A8-%E7%AC%AC%E5%85%AD%E7%AB%A0/","publishdate":"2018-03-20T00:00:00Z","relpermalink":"/post/r%E8%AF%AD%E8%A8%80%E7%BB%9F%E8%AE%A1%E5%85%A5%E9%97%A8-%E7%AC%AC%E5%85%AD%E7%AB%A0/","section":"post","summary":"第六章 回归于相关性 6.1 简单线性回归 线性回归模型是如下定义的： \\[","tags":["R","统计"],"title":"R语言统计入门-第六章","type":"post"},{"authors":null,"categories":["R","统计"],"content":"\r第五章 单样本与双样本检验\r\u000b本章的主题是进行连续型数据的比较，可能是比较两组数据，或者是一组数据与一个预设值。\n\u000b首先介绍两个函数，用来进行 t 检验的t.test和进行Wilcoxon检验的wilcox.test。它们都能够对单样本、双样本与配对样本进行检验。注意的是，双样本Wilcoxon检验在许多教科书中也叫作Mann-Whitney检验。\n5.1 单样本 t 检验\r\u000bt 检验假设数据来自一个正态分布。在单样本的情况下，假设\\(x_1,...,x_n\\)来自于服从\\(N(\\mu,\\sigma^2)\\)的独立随机变量，其中\\(N(\\mu,\\sigma^2)\\)表示均值为\\(\\mu\\)、方差为\\(\\sigma\\)的正态分布。希望对假设\\(\\mu=\\mu_0\\)进行检验。我们能用样本的均值\\(\\overline{x}\\)与标准差\\(s\\)来估计真实参数\\(\\mu\\)与\\(\\sigma\\)。\n\u000b下面讲下均值的标准误，即SEM（Standard Error of the Mean），对\\(n\\)个均值为\\(\\mu\\)、方差为\\(\\sigma\\)的随机变量求平均值，SEM便用来描述这个平均值的波动性，它的表达式是： \\[\rSEM=\\sigma/\\sqrt{n}\r\\] 这个值能告诉我们观察到的均值偏离真实值多远是比较合适的。对于服从正态分布的数据，有一条一般性准则：有95%的数据会落在\\(\\mu\\pm2\\sigma\\)这个区间里。所以如果\\(\\mu_0\\)是真实的平均值，那么\\(\\overline{x}\\)就应该落在\\(\\mu_0\\pm2SEM\\)中。也就是说，可以通过计算： \\[\rt=\\frac{\\overline{x}-\\mu_0}{SEM}\r\\] 来判断 t 是否落在了一个接受域中。t 应该以一定的概率落在这个接受域之外，这个概率被称为显著性水平。显著性水平一般被设为5%，此时接受域大致是-2到2的区间。\n\u000b如果 t 落在接受域之外，那么就在预设的显著性水平上拒绝零假设。另一种（等价的）的方法是计算 p 值，它指的是得到一个绝对值上大于或等于当前 t 值的概率，我们能在 p 值小于显著性水平的情况下拒绝零假设。\n\u000b下面是一个具体例子，反映11个女性的每日摄入能量（千焦）记录。\ndaily.intake \u0026lt;- c(5260,5470,6180,6390,6515,6805,7515,7515,8230,8770)\r#先看下简单的描述性统计\rmean(daily.intake)\r## [1] 6865\rsd(daily.intake)\r## [1] 1139.213\rquantile(daily.intake)\r## 0% 25% 50% 75% 100% ## 5260.0 6232.5 6660.0 7515.0 8770.0\r#现在想检验一下这些数据是否与推荐值7725千焦相差甚远，假设这些数据来自于正态分布\r#那么目的就是检验这个分布是否满足μ=7725\r#下面用t.test进行\rt.test(daily.intake,mu=7725)\r## ## One Sample t-test\r## ## data: daily.intake\r## t = -2.3872, df = 9, p-value = 0.04074\r## alternative hypothesis: true mean is not equal to 7725\r## 95 percent confidence interval:\r## 6050.056 7679.944\r## sample estimates:\r## mean of x ## 6865\r#t.test函数还有其他参数。这里用mu来指定零假设的均值（默认mu=0）\r#此外，还可以用alternative=\u0026quot;greater\u0026quot;来检验均值是否大于μ\r#或者是alternative=\u0026quot;less\u0026quot;来检验均值是否小于μ\r#还可以通过conf.level=0.99来得到一个99%置信区间\r\u000b下面是对这个结果的解释：\n\u000bOne Sample t-test\n\u000b这是对所做检验的描述。注意看函数的调用格式，t.test会自动发现用户需要进行一个单样本检验\n\u000bdata：daily.intake\n\u000b这个是被检验的数据。\n\u000bt=-2.8208, df=10, p-value=0.01814\n\u000b这里显示了 t 统计量，相应的自由度df以及准确的 p 值。这里不用拿着一张 t 分布表来查这个统计量落在了那两个分位数之间，就能够立刻看到 p \u0026lt;0.05，于是在自定义的5%显著性水平下，数据显著偏离了原假设中的均值7725千焦。\n\u000balternative hypothesis：true mean is not equal to 7725\n\u000b这里有两个重要的信息：（a）原假设中均值；（b）这是一个双边检验（“not equal to 7725”）。\n\u000b95 percent confidence interval:\n\u000b5986.348 7520.925\n\u000b这是真实均值的95%置信区间：这个区间是一个集合，如果原假设的值来自于这个集合，那么数据便不会显著的偏离。对 t 检验的步骤进行逆向求解，可以得到使得 t 统计量会落在接受域中的一组\\(\\mu_0\\)。 \\[\r\\overline{x}-t_{0.975}(f)\\times SEM\\lt\\mu\\lt\\overline{x}+t_{0.975}(f)\\times SEM\r\\] sample estimates:\n\u000bmean of x\n\u000b6753.636\n\u000b位于最后的这部分是观测值的均值，也就是对真实均数的（点）估计。\n\r5.2 Wilcoxon符号秩检验\r\u000bt 检验在用于那些不来自于正态分布的数据时比较稳定，尤其是在大样本情况下。不过有的时候会避免做出这种假设（即非正态分布数据），这时最好用不依赖于分布的方法，这些方法通常都把数据替换成了相应的顺序统计量。\n\u000b对Wilcoxon秩和检验的实际应用基本上与 t 检验相同。\n#与t.test一样，wilcox.test有mu和alternative两个参数\r#此外，还有correct这个参数，用来指示是否需要进行连续型修正，比如correct=F表示不用\r#还有exact，用来指示是否需要进行精确的计算，也用TRUE和FALSE这两个逻辑值来控制\rwilcox.test(daily.intake, mu=7725)\r## Warning in wilcox.test.default(daily.intake, mu = 7725): cannot compute\r## exact p-value with ties\r## ## Wilcoxon signed rank test with continuity correction\r## ## data: daily.intake\r## V = 8, p-value = 0.05263\r## alternative hypothesis: true location is not equal to 7725\r\u000b这里比t.test的输出更短些，因为一个分参数检验不会出现类似于参数估计以及置信边界等概念。\n\u000b结果里面的V是检验统计量，表示的是正数对应的秩和，在这个例子中，因为存在两个7515，所以p值是通过正态近似的方法来计算的。\n\r5.3 两样本 t 检验\r\u000b两样本 t 检验主要用来检验两个样本是否来自于均值相等的分布。\n\u000b两样本检验和单样本检验的理论基础差别不大。现在从两个组别中抽出数据\\(x_{11}...,x_{1n_1}\\)和\\(x_{21},...,x_{2n_2}\\)，假设它们是从\\(N(\\mu_1,\\sigma_1^2)\\)与\\(N(\\mu_2,\\sigma_2^2)\\)两个分布中抽取的样本，并希望检验零假设\\(\\mu_1=\\mu_2\\)。接着计算： \\[\rt=\\frac{\\overline{x}_2-\\overline{x}_1}{SEDM}\r\\] SEDM（Standard Error of Difference of Means）是均值差的标准误，被定义为： \\[\rSEDM=\\sqrt{SEM_1^2+SEM^2_2}\r\\] 对于是否假设两组数据的方差相等，SEDM有两种相应计算的方法。“经典”的方法假设方差相等。在这个方法下，先根据两组的标准差计算一个综合性的 s ，然后将它代入SEM。零假设下的 t 值服从自由度为\\(n_1+n_2-2\\)的 t 分布。\n\u000b另一种方法由Welch提出，即以两组各自的标准差\\(s_1\\)和\\(s_2\\)来计算SEM。这个方法算出来 t 统计量已经不满足 t 分布了，不过可以通过一个 t 分布来近似。这个近似分布的自由度能够通过\\(s_1,s_2\\)与样本量来得到，一般不是整数。\n\u000b回头看看每日消耗鞥能量的数据（见1.2.14小节），来比较一下两组女性每日消耗的能量是否有差别。\nlibrary(ISwR)\rattach(energy)\renergy\r## expend stature\r## 1 9.21 obese\r## 2 7.53 lean\r## 3 7.48 lean\r## 4 8.08 lean\r## 5 8.09 lean\r## 6 10.15 lean\r## 7 8.40 lean\r## 8 10.88 lean\r## 9 6.13 lean\r## 10 7.90 lean\r## 11 11.51 obese\r## 12 12.79 obese\r## 13 7.05 lean\r## 14 11.85 obese\r## 15 9.97 obese\r## 16 7.48 lean\r## 17 8.79 obese\r## 18 9.69 obese\r## 19 9.68 obese\r## 20 7.58 lean\r## 21 9.19 obese\r## 22 8.11 lean\r\u000b这个数据框的两列包含了所有我们需要的信息。属性变量satrure包含了分组信息，而数值变量expend包含了以兆焦耳为单位的能量消耗。我们只要传递一个模型方程，就能通过R中的t.test和wilcox.test来分析这种格式的数据。\n\u000b我们的目的是两组的水平是否有差异，所以我们用一个 t 检验。\n#~波浪号是致命expend是通过stature来描述的\rt.test(expend~stature)\r## ## Welch Two Sample t-test\r## ## data: expend by stature\r## t = -3.8555, df = 15.919, p-value = 0.001411\r## alternative hypothesis: true difference in means is not equal to 0\r## 95 percent confidence interval:\r## -3.459167 -1.004081\r## sample estimates:\r## mean in group lean mean in group obese ## 8.066154 10.297778\r\u000b输出的内容和单样本检验中的基本一致。其中均值之差的置信区间不包含0，与 p 值的结果相统一，意味着在5%的置信水平下差异是显著的。\n\u000bR中的 t 检验默认采用Welch的变种算法，当不假设两组方差相等时就应该用它，这也会导致非整数的自由度。\n\u000b为进行平常的 t 检验，应该明确方差相等这个假设，可以通过使参数var.equal=T来达到这一点：\nt.test(expend~stature, var.equal=T)\r## ## Two Sample t-test\r## ## data: expend by stature\r## t = -3.9456, df = 20, p-value = 0.000799\r## alternative hypothesis: true difference in means is not equal to 0\r## 95 percent confidence interval:\r## -3.411451 -1.051796\r## sample estimates:\r## mean in group lean mean in group obese ## 8.066154 10.297778\r\r5.4 比较方差\r\u000b虽然在R中不需要假设方差相等也能进行两样本 t 检验，但仍可能对这个假设本身是否正确感兴趣。为此，R提供了var.test函数来做到这一点。这个函数的主要功能是对两样本的方差进行 F 检验。它的使用方法和t.test一样：\nvar.test(expend~stature)\r## ## F test to compare two variances\r## ## data: expend by stature\r## F = 0.78445, num df = 12, denom df = 8, p-value = 0.6797\r## alternative hypothesis: true ratio of variances is not equal to 1\r## 95 percent confidence interval:\r## 0.1867876 2.7547991\r## sample estimates:\r## ratio of variances ## 0.784446\r\u000b这里检验结果不显著，所以不能拒绝方差相等这个假设，但是置信区间非常宽。\n\r5.5 两样本Wilcoxon检验\r\u000b如果对正态分布假设有所怀疑，那么可能更需要使用一个非参数检验。两样本Wilcoxon检验用数据的秩（不考虑分组）代替数据本身，然后计算某一组中的秩和。这样便简化成了从1~ n1+n2\u000b中不重复地抽出n1个数字的问题。\nwilcox.test(expend~stature)\r## Warning in wilcox.test.default(x = c(7.53, 7.48, 8.08, 8.09, 10.15, 8.4, :\r## cannot compute exact p-value with ties\r## ## Wilcoxon rank sum test with continuity correction\r## ## data: expend by stature\r## W = 12, p-value = 0.002122\r## alternative hypothesis: true location shift is not equal to 0\r\u000b统计量 W 是第一组数据的秩和减去理论最小值（如果最小的n1个数都在第一组中，那么 W 就等于0）。\n\r5.6 配对 t 检验\r\u000b在同一个实验单位中有着两个度量值时使用配对检验。该检验主要通过做差来将问题简化为单样本检验。不过这种方法意味着我们要假设这个差值与不同水平的度量值是独立的。我们可以将每一对数构成的点与直线y=x画在同一幅图上，或是将每一对数的差与它们的均值画在同一幅图上（即Bland~Altman图），这是有效的图形检查方法。\n#还是月经前后能量摄入\rattach(intake)\rintake\r## pre post\r## 1 5260 3910\r## 2 5470 4220\r## 3 5640 3885\r## 4 6180 5160\r## 5 6390 5645\r## 6 6515 4680\r## 7 6805 5265\r## 8 7515 5975\r## 9 7515 6790\r## 10 8230 6900\r## 11 8770 7335\r#这里的关键是11位女性都被测量了2次，所以查看个人数据的差值是合理的\rpost-pre\r## [1] -1350 -1250 -1755 -1020 -745 -1835 -1540 -1540 -725 -1330 -1435\r#基本上都是负数\r#这意味着月经后有更低的能量摄入\r#t检验中paired=T表示希望进行一个配对检验\rt.test(pre, post, paired = T)\r## ## Paired t-test\r## ## data: pre and post\r## t = 11.941, df = 10, p-value = 3.059e-07\r## alternative hypothesis: true difference in means is not equal to 0\r## 95 percent confidence interval:\r## 1074.072 1566.838\r## sample estimates:\r## mean of the differences ## 1320.455\rt.test(pre, post)\r## ## Welch Two Sample t-test\r## ## data: pre and post\r## t = 2.6242, df = 19.92, p-value = 0.01629\r## alternative hypothesis: true difference in means is not equal to 0\r## 95 percent confidence interval:\r## 270.5633 2370.3458\r## sample estimates:\r## mean of x mean of y ## 6753.636 5433.182\r#后者的t明显变小了，虽然在5%的水平下显著\r#置信区间几乎是配对检验中的4倍\r#从这两个可以看出，如果没有对比同一个人测量的前后信息，那么准确性就会降低\r#当然也可以得出这样的结论\r#在同一个人上进行两次测量，比对两组分别处于月经前、后的女性进行测量，效率更高\r\r5.7 配对Wilcoxon检验\r#与t.test函数相同\rwilcox.test(pre, post, paired = T)\r## Warning in wilcox.test.default(pre, post, paired = T): cannot compute exact\r## p-value with ties\r## ## Wilcoxon signed rank test with continuity correction\r## ## data: pre and post\r## V = 66, p-value = 0.00384\r## alternative hypothesis: true location shift is not equal to 0\r\u000b这个结果与 t 检验没有多大差别。p 值没有那么极端。\n\u000b又一次，在由数据相等的情况下无法精确的计算 p 值，这里有两个相等的差值都是-1540。\n\u000b对当前数据很容易计算精确的 p 值。这是11个正差值的概率，加上11个负差值的概率，即\\(2\\times(\\frac{1}{2})^{11}=\\frac{1}{1024}=0.00098\\)，所以近似计算的p 值差不多是真实值的4倍。\n\r练习题\r数据集react（注意这是一个向量）的值看起来是正态分布的吗，它的均值在 t 检验下显著地不等于0吗\r在数据集vitcap中使用 t 检验比较两组肺活量，并计算99%置信区间。这个比较结果可能会产生误导，为什么\r用非参数方法对react和vitcap两个数据做分析。\r使用图像法检查intake数据集的配对 t 检验的建设是否合理。\r函数shapiro.test基于Q-Q图的线性性来检验正态性。对react数据进行这个检验，它对移除异常值有帮助吗。\r如果忽略潜在的时间因素影响，能通过简单的方法（怎么做）送ashina里的交叉实验中分析药物效果。提示，考虑个体内部的差异，如果只出现了时间因素的影响，两组差异会有什么表现\r在10个含有25个观测值的模拟正态分布数据上分别做单样本 t 检验。用不同的分布再重复这个实验；尝试自由度为2的t 分布，以及指数分布（在后一种情况下对均值为1的分布做检验）。你能自动化这个实验从而重复更多次吗。\r\r\r\r","date":1520985600,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1520985600,"objectID":"a2c125d34424e84bc5ec5f6c9684bd1c","permalink":"/post/r%E8%AF%AD%E8%A8%80%E7%BB%9F%E8%AE%A1%E5%85%A5%E9%97%A8-%E7%AC%AC%E4%BA%94%E7%AB%A0/","publishdate":"2018-03-14T00:00:00Z","relpermalink":"/post/r%E8%AF%AD%E8%A8%80%E7%BB%9F%E8%AE%A1%E5%85%A5%E9%97%A8-%E7%AC%AC%E4%BA%94%E7%AB%A0/","section":"post","summary":"第五章 单样本与双样本检验 本章的主题是进行连续型数据的比较，可","tags":["R","杂"],"title":"R语言统计入门-第五章","type":"post"},{"authors":null,"categories":["R","统计"],"content":"\r第四章 描述性统计和图形\r4.1 单组的汇总统计量\r#计算均值、标准差、方差和中位数\r#比如x为50个来自于正态分布的数值的向量\rx \u0026lt;- rnorm(50)\rmean(x)\r## [1] -0.1020794\rsd(x)\r## [1] 0.7992287\rvar(x)\r## [1] 0.6387666\rmedian(x)\r## [1] -0.09860993\r#经验后分位数\rquantile(x)\r## 0% 25% 50% 75% 100% ## -2.27594629 -0.51963199 -0.09860993 0.52209912 1.33801565\r#看看如何取得十分位数\r#可以增加一个包含十分位数的参数\rpvec \u0026lt;- seq(0, 1, 0.1)\rpvec\r## [1] 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0\rquantile(x, pvec)\r## 0% 10% 20% 30% 40% 50% ## -2.27594629 -1.03235747 -0.57501258 -0.45242250 -0.33083825 -0.09860993 ## 60% 70% 80% 90% 100% ## 0.03587906 0.35254339 0.55122580 0.93672980 1.33801565\r如果有缺失值，那么问题会复杂一些，下面讲个例子。\n数据集juul，包含在ISwR包中。是Anders Juul的报告中的数据。该报告是关于健康人群，主要是学龄儿童的血清IGF-l的。现在只使用igfl。\n#当试着计算igfl的均值时，出现一个问题\rlibrary(ISwR)\rattach(juul)\rmean(igf1)\r## [1] NA\r#R不能跳过缺失值\r#然而可以用na.rm参数来移除未知值\rmean(igf1,na.rm=T)\r## [1] 340.168\r#但有个例外，length函数不识别na.rm\r#所以不能用它来确定非缺失观测的个数\r#可以用下面的语句来实现\r#这个结构说明，逻辑值若用于算数计算，那么TRUE转换为1，FALSE转换为0\rsum(!is.na(igf1))\r## [1] 1018\r#summary函数可以汇总数字变量\r#其中，1stQu.和3rdQu.分别指经验四分位数（0.25，0.75）\rsummary(igf1)\r## Min. 1st Qu. Median Mean 3rd Qu. Max. NA\u0026#39;s ## 25.0 202.2 313.5 340.2 462.8 915.0 321\r#也可以对整个数据集进行汇总\rsummary(juul)\r## age menarche sex igf1 ## Min. : 0.170 Min. :1.000 Min. :1.000 Min. : 25.0 ## 1st Qu.: 9.053 1st Qu.:1.000 1st Qu.:1.000 1st Qu.:202.2 ## Median :12.560 Median :1.000 Median :2.000 Median :313.5 ## Mean :15.095 Mean :1.476 Mean :1.534 Mean :340.2 ## 3rd Qu.:16.855 3rd Qu.:2.000 3rd Qu.:2.000 3rd Qu.:462.8 ## Max. :83.000 Max. :2.000 Max. :2.000 Max. :915.0 ## NA\u0026#39;s :5 NA\u0026#39;s :635 NA\u0026#39;s :5 NA\u0026#39;s :321 ## tanner testvol ## Min. :1.00 Min. : 1.000 ## 1st Qu.:1.00 1st Qu.: 1.000 ## Median :2.00 Median : 3.000 ## Mean :2.64 Mean : 7.896 ## 3rd Qu.:5.00 3rd Qu.:15.000 ## Max. :5.00 Max. :30.000 ## NA\u0026#39;s :240 NA\u0026#39;s :859\r#其中menarche、sex、tanner被编码为数值变量\r#虽然它们显然是分类变量\r#可以进行如下改进\rdetach(juul)\rjuul$sex \u0026lt;- factor(juul$sex, labels=c(\u0026quot;M\u0026quot;,\u0026quot;F\u0026quot;))\rjuul$menarche \u0026lt;- factor(juul$menarche, labels=c(\u0026quot;No\u0026quot;,\u0026quot;Yes\u0026quot;))\rjuul$tanner \u0026lt;- factor(juul$tanner, labels=c(\u0026quot;Ⅰ\u0026quot;,\u0026quot;Ⅱ\u0026quot;,\u0026quot;Ⅲ\u0026quot;,\u0026quot;Ⅳ\u0026quot;,\u0026quot;Ⅴ\u0026quot;))\rattach(juul)\rsummary(juul)\r## age menarche sex igf1 tanner ## Min. : 0.170 No :369 M :621 Min. : 25.0 Ⅰ :515 ## 1st Qu.: 9.053 Yes :335 F :713 1st Qu.:202.2 Ⅱ :103 ## Median :12.560 NA\u0026#39;s:635 NA\u0026#39;s: 5 Median :313.5 Ⅲ : 72 ## Mean :15.095 Mean :340.2 Ⅳ : 81 ## 3rd Qu.:16.855 3rd Qu.:462.8 Ⅴ :328 ## Max. :83.000 Max. :915.0 NA\u0026#39;s:240 ## NA\u0026#39;s :5 NA\u0026#39;s :321 ## testvol ## Min. : 1.000 ## 1st Qu.: 1.000 ## Median : 3.000 ## Mean : 7.896 ## 3rd Qu.:15.000 ## Max. :30.000 ## NA\u0026#39;s :859\r#变量sex、menarche和tanner被转换为辅以适当水平名称的因子变量\r#在原始数据中，它们以数字代码显示\r#这些转化后的变量重新放回数据集juul中，从而替代原来的sex等\r#也可以用transformf函数（或within）\rjuul \u0026lt;- transform(juul,\rsex=factor(sex,labels=c(\u0026quot;M\u0026quot;,\u0026quot;F\u0026quot;)),\rmenarche=factor(menarche,labels=c(\u0026quot;No\u0026quot;,\u0026quot;Yes\u0026quot;)),\rtanner=factor(tanner,labels=c(\u0026quot;Ⅰ\u0026quot;,\u0026quot;Ⅱ\u0026quot;,\u0026quot;Ⅲ\u0026quot;,\u0026quot;Ⅳ\u0026quot;,\u0026quot;Ⅴ\u0026quot;)))\r\r4.2 分布的图形显示\r4.2.1 直方图\r#绘制x的直方图\rhist(x)\r在hist函数中调用breaks=n，可以在直方图中得到大约n个条，这是因为算法会尽力创建“合适”的分割点。亦可以通过指定breaks为一个向量而不仅是数字完成区间分割的完全控制。\nmid.age \u0026lt;- c(2.5,7.5,13,16.5,17.5,19,22.5,44.5,70.5)\racc.count \u0026lt;- c(28,46,58,20,31,64,149,316,103)\rage.acc \u0026lt;- c(0,5,10,16,17,18,20,25,60,80)\rbrk \u0026lt;- c(0,5,10,16,17,18,20,25,60,80)\rhist(age.acc, breaks=brk)\r#可以在hist函数中，用freq=T指定列高为数据数量，freq=F可以得到密度显示\r\r4.2.2 经验累计分布\r经验累计分布函数定义为小于等于x的数据占总数据的比例，可以作图如下：\nn \u0026lt;- length(x)\r#type=\u0026quot;s\u0026quot;给出一个阶梯函数，其中(x,y)是步长额左端点，ylim是两个元素的向量，用于指定y坐标的边界点\rplot(sort(x),(1:n)/n,type=\u0026quot;s\u0026quot;,ylim=c(0,1))\r\r4.2.3 Q-Q图\r计算经验累积分布函数的目的之一，是观察数据是否能被假设成来自正态分布。为更好地评估，可以画出第k个最小观测值和来自标准正态分布的n个值中第k个最小观测值的图形。关键之处是，用这种方法，如果数据是来自任何均值和标准差的正态分布，应该得到一条直线。\n#可以用qqnorm函数来做这个\rqqnorm(x)\r\r4.2.4 箱式图\r#两个按行并列图的布局使用mfrow作图参数指定\r#mfcol参数用来绘制按排列的图形\r#值得注意的是，最后把布局参数重新设定回c(1,1)是必要的\r#除非希望继续画此种并列图\rpar(mfrow=c(1,2))\rboxplot(IgM)\rboxplot(log(IgM))\rpar(mfrow=c(1,1))\r\r\r4.3 分组数据的汇总统计量\r当处理分组数据的时候，经常会希望得到一些按组计算的不同的总结统计量，比如均值和标准差的一张表格。为此目的，可以使用tapply函数。\nattach(red.cell.folate)\r#tapply函数提取folate变量，根据ventilation分组\r#然后对每一组计算均值\rtapply(folate,ventilation,mean)\r## N2O+O2,24h N2O+O2,op O2,24h ## 316.6250 256.4444 278.0000\r#同样的方法，可以计算标准差和数目\rtapply(folate,ventilation,sd)\r## N2O+O2,24h N2O+O2,op O2,24h ## 58.71709 37.12180 33.75648\rtapply(folate,ventilation,length)\r## N2O+O2,24h N2O+O2,op O2,24h ## 8 9 5\r#可以像下面这样更好的显示\rxbar \u0026lt;- tapply(folate,ventilation,mean)\rs \u0026lt;- tapply(folate,ventilation,sd)\rn \u0026lt;- tapply(folate,ventilation,length)\r#对于juul数据集来说，希望求按tanner对igfl分组后的均值\r#但是又遇到了缺失值的问题\rtapply(igf1,tanner,mean)\r## Ⅰ Ⅱ Ⅲ Ⅳ Ⅴ ## NA NA NA NA NA\r#可以用na.rm排除缺失值\rtapply(igf1,tanner,mean,na.rm=T)\r## Ⅰ Ⅱ Ⅲ Ⅳ Ⅴ ## 207.4727 352.6714 483.2222 513.0172 465.3344\r#函数aggregate和by是同一个主题的变形。\r#前者非常类似于tapply，只是它对整个数据集操作并把结果作为一个数据框显示\r#同时显示多个变量是很有用的\raggregate(juul[c(\u0026quot;age\u0026quot;,\u0026quot;igf1\u0026quot;)],\rlist(sex=juul$sex),mean,na.rm=T)\r## sex age igf1\r## 1 M 15.38436 310.8866\r## 2 F 14.84363 368.1006\r#索引变量不是数据框中必须被汇总的部分，没有像在subset中进行的“智能评价”尝试\r#所以必须拼出juul$sex\r#也可以使用数据框类似于列表的事实\r#技巧是使用单引号索引一个数据框，产生一个座位结果的数据框\raggregate(juul[c(\u0026quot;age\u0026quot;,\u0026quot;igf1\u0026quot;)],juul[\u0026quot;sex\u0026quot;],mean,na.rm=T)\r## sex age igf1\r## 1 M 15.38436 310.8866\r## 2 F 14.84363 368.1006\r#by函数也是类似的，但有所不同\r#不同之处在于取整个（子）数据框作为它的变量，所以可以用性别总结juul数据\rby(juul, juul[\u0026quot;sex\u0026quot;],summary)\r## sex: M\r## age menarche sex igf1 tanner ## Min. : 0.17 No : 0 M:621 Min. : 29.0 Ⅰ :291 ## 1st Qu.: 8.85 Yes : 0 F: 0 1st Qu.:176.0 Ⅱ : 55 ## Median :12.38 NA\u0026#39;s:621 Median :280.0 Ⅲ : 34 ## Mean :15.38 Mean :310.9 Ⅳ : 41 ## 3rd Qu.:16.77 3rd Qu.:430.2 Ⅴ :124 ## Max. :83.00 Max. :915.0 NA\u0026#39;s: 76 ## NA\u0026#39;s :145 ## testvol ## Min. : 1.000 ## 1st Qu.: 1.000 ## Median : 3.000 ## Mean : 7.896 ## 3rd Qu.:15.000 ## Max. :30.000 ## NA\u0026#39;s :141 ## -------------------------------------------------------- ## sex: F\r## age menarche sex igf1 tanner ## Min. : 0.25 No :369 M: 0 Min. : 25.0 Ⅰ :224 ## 1st Qu.: 9.30 Yes :335 F:713 1st Qu.:233.0 Ⅱ : 48 ## Median :12.80 NA\u0026#39;s: 9 Median :352.0 Ⅲ : 38 ## Mean :14.84 Mean :368.1 Ⅳ : 40 ## 3rd Qu.:16.93 3rd Qu.:483.0 Ⅴ :204 ## Max. :75.12 Max. :914.0 NA\u0026#39;s:159 ## NA\u0026#39;s :176 ## testvol ## Min. : NA ## 1st Qu.: NA ## Median : NA ## Mean :NaN ## 3rd Qu.: NA ## Max. : NA ## NA\u0026#39;s :713\r\r4.4 分组数据作图\r这一节主要是在同一页为几组数据进行作图。\n4.4.1 直方图\r这个例子使用1.2.14节的关于两组妇女24 h能量消耗的energy数据集，选择了0.5 MJ的倍数作为分割点。\n#先获得数据集\rattach(energy)\r#分割向量\rexpend.lean \u0026lt;- expend[stature==\u0026quot;lean\u0026quot;]\rexpend.obese \u0026lt;- expend[stature==\u0026quot;obese\u0026quot;]\r#开始作图\r#设置par(mfrow=c(2,1))，从而在一个图中得到两个直方图\rpar(mfrow=c(2,1))\rhist(expend.lean,breaks=10,xlim=c(5,13),ylim=c(0,4),col=\u0026quot;white\u0026quot;)\rhist(expend.obese,breaks=10,xlim=c(5,13),ylim=c(0,4),col=\u0026quot;grey\u0026quot;)\rpar(mfrow=c(1,1))\r\r4.4.2 并联箱式图\r#创建图形\r#符号y~x表示用x表达的y\rboxplot(expend ~ stature)\r#也可以用expend.lean和expend.obese作图\rboxplot(expend.lean,expend.obese)\r\r4.4.3 带状图\r刚刚介绍的箱式图并没有很好的显示“Laurel \u0026amp; Hardy”效应。原因在于一组数据的四分位点内距比另一组大很多，使箱式图变得很胖。使用这么小的分组数据四分位数的确定变得很不准确，因此对原始数据作图可能是更合适的。\n#mex设置减少行间距，mar减少图形区域周边线的数量\r#将这些设置的原始值储存在opar中，用par(opar)重新调出\ropar \u0026lt;- par(mfrow=c(2,1),mex=0.8,mar=c(3,3,2,1)+.1)\rstripchart(expend ~ stature)\rstripchart(expend ~ stature,method=\u0026quot;stack\u0026quot;)\rstripchart(expend ~ stature,method=\u0026quot;jitter\u0026quot;)\rstripchart(expend ~ stature,method=\u0026quot;jitter\u0026quot;,jitter=.03)\rpar(opar)\r\r\r4.5 表格\r4.5.1 生产表格\r本文主要处理双向表格（two-way）。它可以作为一个矩阵对象输入。\n#matrix函数中，函数用nrow设置，一般默认是按列输入，byrow=T表示按行输入\r#也可以用ncol给出列数\rcaff.marital \u0026lt;- matrix(c(652,1537,598,242,36,46,38,21,218,327,106,67),\rnrow=3, byrow=T)\rcaff.marital\r## [,1] [,2] [,3] [,4]\r## [1,] 652 1537 598 242\r## [2,] 36 46 38 21\r## [3,] 218 327 106 67\r#若ncol和nrow中的一个被给出，那么R将计算相应的那个，从而与输入的值的数目相匹配\r#若都给出，但是与值得数目不匹配，那么，值将被循环使用\rcolnames(caff.marital) \u0026lt;- c(\u0026quot;0\u0026quot;,\u0026quot;1-150\u0026quot;,\u0026quot;151-300\u0026quot;,\u0026quot;\u0026gt;300\u0026quot;)\rrownames(caff.marital) \u0026lt;- c(\u0026quot;Married\u0026quot;,\u0026quot;Prev.married\u0026quot;,\u0026quot;Single\u0026quot;)\rcaff.marital\r## 0 1-150 151-300 \u0026gt;300\r## Married 652 1537 598 242\r## Prev.married 36 46 38 21\r## Single 218 327 106 67\r#此外，也可以如下命名行和列的名称\rnames(dimnames(caff.marital)) \u0026lt;- c(\u0026quot;martial\u0026quot;,\u0026quot;consumption\u0026quot;)\rcaff.marital\r## consumption\r## martial 0 1-150 151-300 \u0026gt;300\r## Married 652 1537 598 242\r## Prev.married 36 46 38 21\r## Single 218 327 106 67\r#一般来说，可以在需要两维表格的地方可以用矩阵\r#在确实需要表格的时候可以用as.table\ras.data.frame(as.table(caff.marital))\r## martial consumption Freq\r## 1 Married 0 652\r## 2 Prev.married 0 36\r## 3 Single 0 218\r## 4 Married 1-150 1537\r## 5 Prev.married 1-150 46\r## 6 Single 1-150 327\r## 7 Married 151-300 598\r## 8 Prev.married 151-300 38\r## 9 Single 151-300 106\r## 10 Married \u0026gt;300 242\r## 11 Prev.married \u0026gt;300 21\r## 12 Single \u0026gt;300 67\r#在实际中，更常见的情形是对一个数据集中的每一个人，都有一个带变量的数据框\r#这时可以用table，xtabs或ftable做一个表列\rattach(juul)\r## The following objects are masked from juul (pos = 5):\r## ## age, igf1, menarche, sex, tanner, testvol\rtable(sex)\r## sex\r## M F ## 621 713\rtable(sex,menarche)\r## menarche\r## sex No Yes\r## M 0 0\r## F 369 335\rtable(menarche,tanner)\r## tanner\r## menarche Ⅰ Ⅱ Ⅲ Ⅳ Ⅴ\r## No 221 43 32 14 2\r## Yes 1 1 5 26 202\r#xtabs类似于table，只不过它使用模型公式借口\r#最常用的是一个单边公式，只要列出分类变量，用+分割\rxtabs(~tanner + sex, data=juul)\r## sex\r## tanner M F\r## Ⅰ 291 224\r## Ⅱ 55 48\r## Ⅲ 34 38\r## Ⅳ 41 40\r## Ⅴ 124 204\r#从table或xtabs得到的多向量表形式并不是很好\rxtabs(~dgn + diab + coma, data=stroke)\r## , , coma = No\r## ## diab\r## dgn No Yes\r## ICH 53 6\r## ID 143 21\r## INF 411 64\r## SAH 38 0\r## ## , , coma = Yes\r## ## diab\r## dgn No Yes\r## ICH 19 1\r## ID 23 3\r## INF 23 2\r## SAH 9 0\r#当增加维度时，会得到更多的二维子表格，这就是ftable的用武之地\r#这个函数创建一个扁平的表格\rftable(coma + diab ~ dgn, data=stroke)\r## coma No Yes ## diab No Yes No Yes\r## dgn ## ICH 53 6 19 1\r## ID 143 21 23 3\r## INF 411 64 23 2\r## SAH 38 0 9 0\r#可以用t函数转置表格，对于多维表格，可以用aperm来转置\rt(caff.marital)\r## martial\r## consumption Married Prev.married Single\r## 0 652 36 218\r## 1-150 1537 46 327\r## 151-300 598 38 106\r## \u0026gt;300 242 21 67\r\r4.5.2 边际表格和相对频数\r经常会需要计算边际表格，即沿着表格的一个或另一个维度求和。\n#首先生成表格\r#tanner.sex是为一个交叉表任意选取的名称\rtanner.sex \u0026lt;- table(tanner,sex)\rtanner.sex\r## sex\r## tanner M F\r## Ⅰ 291 224\r## Ⅱ 55 48\r## Ⅲ 34 38\r## Ⅳ 41 40\r## Ⅴ 124 204\r#然后计算边际表格\r#margin.table中的参数1和2分别表示按行或按列进行求和\rmargin.table(tanner.sex,1)\r## tanner\r## Ⅰ Ⅱ Ⅲ Ⅳ Ⅴ ## 515 103 72 81 328\rmargin.table(tanner.sex,2)\r## sex\r## M F ## 545 554\r#相对频数的表格可以用prop.table构建，参数1表示按行\rprop.table(tanner.sex,1)\r## sex\r## tanner M F\r## Ⅰ 0.5650485 0.4349515\r## Ⅱ 0.5339806 0.4660194\r## Ⅲ 0.4722222 0.5277778\r## Ⅳ 0.5061728 0.4938272\r## Ⅴ 0.3780488 0.6219512\r\r\r4.6 表格的图形显示\r4.6.1 条形图\rtotal.caff \u0026lt;- margin.table(caff.marital,2)\rtotal.caff\r## consumption\r## 0 1-150 151-300 \u0026gt;300 ## 906 1910 742 330\rbarplot(total.caff, col=\u0026quot;white\u0026quot;)\r#如果要创建的对象是一个矩阵，那么barplot将默认创建一个堆积条形图\r#其中列根据表中不同行的贡献而被分割，beside=T表示把行的贡献放在旁边\rpar(mfrow=c(2,2))\rbarplot(caff.marital, col=\u0026quot;white\u0026quot;)\rbarplot(t(caff.marital), col=\u0026quot;white\u0026quot;)\rbarplot(t(caff.marital), col=\u0026quot;white\u0026quot;,beside=T)\rbarplot(prop.table(t(caff.marital),2),col=\u0026quot;white\u0026quot;,beside=T)\rpar(mfrow=c(1,1))\r#可以美化一下\rbarplot(prop.table(t(caff.marital),2),beside=T,\rlegend.text=colnames(caff.marital),\rcol=c(\u0026quot;white\u0026quot;,\u0026quot;grey80\u0026quot;,\u0026quot;grey50\u0026quot;,\u0026quot;black\u0026quot;))\r\r4.6.2 点图\rCleveland点图，可以用来同时从两侧研究一个表格。\ndotchart(t(caff.marital), lcolor=\u0026quot;black\u0026quot;)\r\r4.6.3 饼图\ropar \u0026lt;- par(mfrow=c(2,2),mex=0.8,mar=c(1,1,2,1))\rslices \u0026lt;- c(\u0026quot;white\u0026quot;,\u0026quot;grey80\u0026quot;,\u0026quot;grey50\u0026quot;,\u0026quot;black\u0026quot;)\rpie(caff.marital[\u0026quot;Married\u0026quot;,],main=\u0026quot;Married\u0026quot;,col=slices)\rpie(caff.marital[\u0026quot;Prev.married\u0026quot;,],\rmain=\u0026quot;Previously married\u0026quot;,col=slices)\rpie(caff.marital[\u0026quot;Single\u0026quot;,],main=\u0026quot;Single\u0026quot;,col=slices)\rpar(opar)\r\r\r4.7 思考题\r探索不同类型的线和点图的可能性。变化图形的符号、线型、线宽和颜色。\r如果用标定的线和点绘制一个图形，比如plot(rnorm(10),type=“o”)，线将在画图符号内课件，怎样避免这一点。\r怎样把两个qqnorm图放在同一绘图区域，若试着用type=“1”生成一幅图，将出现什么错误，怎样避免。\r对react数据集画直方图。由于这些数据高度分散化，所以直方图会是有偏的。为什么。也许会希望用MASS包中的truehist作为替代。\r从均匀分布中生成有5个随机数的一个样本向量z，作为x的函数绘制quantile(z,x)（比如可以用curve）。\r\r\r\r","date":1519776000,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1519776000,"objectID":"6f95bf1c41d716b480a6916a7946d106","permalink":"/post/r%E8%AF%AD%E8%A8%80%E7%BB%9F%E8%AE%A1%E5%85%A5%E9%97%A8-%E7%AC%AC%E5%9B%9B%E7%AB%A0/","publishdate":"2018-02-28T00:00:00Z","relpermalink":"/post/r%E8%AF%AD%E8%A8%80%E7%BB%9F%E8%AE%A1%E5%85%A5%E9%97%A8-%E7%AC%AC%E5%9B%9B%E7%AB%A0/","section":"post","summary":"第四章 描述性统计和图形 4.1 单组的汇总统计量 #计算均值、标准差、","tags":["R","统计"],"title":"R语言统计入门-第四章","type":"post"},{"authors":null,"categories":["R","统计"],"content":"\r第三章 概率与分布\r3.1 随机抽样\r#在R中，如果想进行随机抽样，比如从1-40中随机抽取5个数字\r#sample函数中，第一个参数1:40表示被抽样的值向量\r#第二个参数5是抽样大小\rsample(1:40,5)\r## [1] 37 16 30 21 18\r#值得注意的是，sample函数默认是无放回抽样\r#如果想进行有放回抽样，需要加上参数replace=TRUE\r#有放回抽样适用于投硬币或掷骰子模型\r#比如模拟10次投硬币\rsample(c(\u0026quot;H\u0026quot;,\u0026quot;T\u0026quot;),10,replace=T)\r## [1] \u0026quot;H\u0026quot; \u0026quot;H\u0026quot; \u0026quot;T\u0026quot; \u0026quot;T\u0026quot; \u0026quot;H\u0026quot; \u0026quot;H\u0026quot; \u0026quot;T\u0026quot; \u0026quot;T\u0026quot; \u0026quot;H\u0026quot; \u0026quot;H\u0026quot;\r#可以用prob参数来模拟那种结果具有不相等概率的数据\r#比如成功的几率是90%\rsample(c(\u0026quot;succ\u0026quot;,\u0026quot;fail\u0026quot;),10,replace=T,prob=c(0.9,0.1))\r## [1] \u0026quot;succ\u0026quot; \u0026quot;succ\u0026quot; \u0026quot;succ\u0026quot; \u0026quot;succ\u0026quot; \u0026quot;succ\u0026quot; \u0026quot;fail\u0026quot; \u0026quot;succ\u0026quot; \u0026quot;succ\u0026quot; \u0026quot;succ\u0026quot; \u0026quot;succ\u0026quot;\r\r3.2 概率计算与排列组合\r#使用prod函数，进行连乘\r#比如36×37×38×39×40\rprod(40:36)\r## [1] 78960960\r#如果这是一种类似于乐透彩票的游戏，需要正确猜对5个数字\r#第一个数字有5种可能，第二个有4种可能，以此类推\r#那么赢奖的概率为\rprod(5:1)/prod(40:36)\r## [1] 1.519738e-06\r#计算从40个数字中选取5个的所有可能\r#可以用choose函数\rchoose(40,5)\r## [1] 658008\r#那么概率即为\r1/choose(40,5)\r## [1] 1.519738e-06\r\r3.3 离散分布\r\u000b当观察一个独立重复二项实验时，通常对每次实验的成功或失败并不感兴趣，更感兴趣的是成功或失败的总数。显然，这个总数是随机的，因为它依赖于每一次随机结果，因此被称为随机变量。\n\u000b它是一个可以取值0,1,2,3，……，n的离散值的随机变量。\n\u000b随机变量\\[X\\]具有概率分布，可以用点概率\\[f(x)=P(X=x)\\]或累计分布函数\\[F(x)=P(X=x)\\]描述。在上述二项分布情形下，分布可以用点概率来得到： \\[\rf(x)=(\\begin{matrix}\rn\\\\\rx\\\\\r\\end{matrix})p^x(1-p)^{n-x}\r\\]\n\u000b其中 \\[\r(\\begin{matrix}\rn\\\\\rx\\\\\r\\end{matrix})\r\\] 被称为二项系数。参数P是一次独立实验中成功地概率。\n\r3.4 连续分布\r\u000b有些数据来自于对实质连续尺度的测量，比如温度什么的。这种测量通常包含随机变化的因素，这使得测量很难被完全重复。然而，这种随机波动会遵循某种模式：它会集中在某个中心值附近，大的偏差比小的要少得多。\n\u000b为了连续数据建模，需要定义能包含任意实数值的随机变量。因为有无穷的数字无限接近，任何特定值的概率是0，所以这里没有像离散型随机变量那样的点概率的说法，取而代之的是密度的概念。\n\u000b它是指x的一个小邻域的无穷小概率除以区域的大小。累计分布函数的定义如前，并且有下面的关系： \\[\rF(x)=\\int_{-\\infty}^\\infty{f(x)dx}\r\\] 在统计理论中有许多常见的分布，可以在R中使用。先看下面几个例子。\n\u000b均匀分布是在一个特定的区间（默认是[0,1]）上有常数密度。\n\u000b正态分布（也成为高斯分布）具有密度： \\[\rf(x)=\\frac{1}{\\sqrt{{2\\pi\\sigma}}}exp(-\\frac{(x-\\mu)^2}{2\\sigma^2})\r\\] 依赖于均值\\[\\mu\\]和标准差\\[\\sigma\\]。正态分布具有标志性的钟形曲线。\n\r3.5 R中的内置分布\r\u000b与建模和统计检验有关的常用标准分布都已经嵌入到R中，因此可以完全取代传统的统计表格。下面只看一下正态分布和二项分布。\n\u000b对一个统计分布可以计算4项基本内容：\n密度或点概率；\n\r累计概率分布函数\n\r分位数\n\r伪随机数\n\r\r\u000b对R中所有的分布，关于上面列出的4项都对应一个相应的函数，比如对于正态分布，它们分别为dnorm，pnorm，qnorm和rnorm（分别对应密度，概率、分位数和随机数）。\n3.5.1 密度\r\u000b连续分布的密度是“得到一个接近x的值”的相对可能性的度量。在一个特定区间得到一个值得概率是在相应曲线下的面积。\n\u000b离散分布，密度用于点概率——恰好得到x值得概率。\n#对于密度函数，可以如下进行\r#函数seq用于产生等距数值，这里是从-4到4，步长为0.1\r#type=“l“参数可以使函数在点与点之间划线而不是只画出点。\rx \u0026lt;- seq(-4,4,0.1)\rplot(x,dnorm(x),type=\u0026quot;l\u0026quot;)\r#创建图形的另外一种方法是用curve\rcurve(dnorm(x), from=-4, to=4)\r#对于离散分布，变量只能取明确值，更倾向于画针形图\r#下面是n=50，p=0.33的二项分布图，type=“h”指定画出针形图\rx \u0026lt;- 0:50\rplot(x, dbinom(x,size=50, prob=.33),type=\u0026quot;h\u0026quot;)\r\r3.5.2 累计分布函数\r\u000b累计分布函数描述的是对一个给定分布小于或等于x的分布的概率。相应R函数按惯例以“p”开头。\n\u000b比如，一种生化指标可以用均值132，标准差13的正态分布描述，而某个患者的该指标为160，则：\n1-pnorm(160,mean=132,sd=13)\r## [1] 0.01562612\r\u000b另一个典型应用与统计检验有关。考虑简单的符号检验：\n\u000b20个病人每人进行2中治疗（以随机顺序治疗），问治疗A还是治疗B更好。结果表明16人认为A好。问题是这是否能作为A确实更好的充分证据，还是说这个结果也可能只是偶然发生的，即使两种治疗效果同样好。如果两种治疗没有差别，可以认为喜欢A的人数服从n=20，p=0.5的二项分布。那么所观测到的结果有多少种可能呢，如同在正态分布下，需要一个尾部概率。\npbinom(16,size=20,prob=.5)\r## [1] 0.9987116\r\u000b然后用1减去它得到上尾概率，但这是不对的。我们需要的是观测到的或更极端的概率，pbinom给出了16或更少数量的概率。此处用“15或更少”来代替：\n1-pbinom(15,size=20,prob=.5)\r## [1] 0.005908966\r\u000b如果因为没有关于哪种治疗方法更好的假设，而希望进行双侧检验，那么必须加上得到在另一侧同样极端结果的概率。这意味着4个或更少的人喜欢A的概率。下面给出总的概率：\n1-pbinom(15,20,.5)+pbinom(4,20,.5)\r## [1] 0.01181793\r\r3.5.3 分位数\r\u000b分位数函数是累计分布函数的反函数。具有这样的性质：得到小于等于它的概率为p。根据定义，中位数即50%分位数。\n\u000b理论分位数通常用于置信区间的计算，以及与设计试验有关的势函数的计算。下面给出一个置信区间计算的简单例子。\n\u000b如果有来自具有共同均值μ和标准差σ的正态分布的n个观测，均值\\[ \\overline{X}\\]服从均值为\\[\\mu\\]、标准差为\\[\\sigma/\\sqrt{n}\\]的正态分布，\\[\\mu\\]的95%置信区间为： \\[\r\\overline{x}+\\sigma/\\sqrt{n}\\times N_{0.025}\\leq\\mu\\leq\\overline{x}+\\sigma/\\sqrt{n}\\times N_{0.025}\r\\] 其中\\[N_{0.025}\\]是正态分布的2.5%分位数。如果\\[\\sigma=12\\]，观测了\\[n=5\\]个人，得到均值\\[\\overline{x}=83\\]，那么可以计算相关分位数如下：（sem表示standard error of the mean）\nxbar \u0026lt;- 83\rsigma \u0026lt;- 12\rn \u0026lt;- 5\rsem \u0026lt;- sigma/sqrt(n)\rsem\r## [1] 5.366563\rxbar + sem + qnorm(0.025)\r## [1] 86.4066\rxbar + sem + qnorm(0.975)\r## [1] 90.32653\r\u000b因此得到了一个\\[\\mu\\]的置信度为95%的置信区间，从72.48到93.52。\n\u000b由于正态分布是对称的，所以有\\[N_{0.025}=-N_{0.975}\\]，通常把置信区间公式写成\\[\\overline{x}\\pm\\sigma/\\sqrt{n}\\times N_{0.975}\\]。这个分位数通常被记为\\[\\Phi^{-1}(0.975)\\]。此处\\[\\Phi\\]是标准正态分布（pnorm）函数的标准符号。\n\r3.5.4 随机数字\r\u000b使用随机数产生函数非常简单。第一个参数指定用于计算的随机数的数量，后续参数类似于其他与相同分布有关的函数中相应位置的参数，例如：\nrnorm(10)\r## [1] 0.04684732 -0.02948123 -0.75005173 -0.56389955 0.19080283\r## [6] -0.61748503 2.71935500 0.20708539 0.40252155 0.17880460\rrnorm(10)\r## [1] -0.08673014 -1.43452132 0.79059235 -0.44031861 0.99937695\r## [6] 0.43162762 0.44075596 -1.40122629 2.15570131 0.36923848\rrnorm(10,mean=7,sd=5)\r## [1] 1.9246116 8.4571563 5.2999963 1.2818234 9.7980067 -1.9064289\r## [7] 13.5556810 3.3486614 6.5230462 0.3127788\rrbinom(10,size=20,prob=.5)\r## [1] 7 10 6 7 9 11 7 12 9 12\r\r\r\r","date":1519759301,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1519759301,"objectID":"6899b1a21db51fbc392dfc1cd553a258","permalink":"/post/2018-02-27-r%E8%AF%AD%E8%A8%80%E7%BB%9F%E8%AE%A1%E5%85%A5%E9%97%A8-%E7%AC%AC%E4%B8%89%E7%AB%A0/","publishdate":"2018-02-27T19:21:41Z","relpermalink":"/post/2018-02-27-r%E8%AF%AD%E8%A8%80%E7%BB%9F%E8%AE%A1%E5%85%A5%E9%97%A8-%E7%AC%AC%E4%B8%89%E7%AB%A0/","section":"post","summary":"第三章 概率与分布 3.1 随机抽样 #在R中，如果想进行随机抽样，比如","tags":["R","统计"],"title":"R语言统计入门-第三章","type":"post"},{"authors":null,"categories":["生物信息学"],"content":"第二章 序列比对 第一节 引言 1. 名词  序列比对：序列比对对于发现生物序列中有关功能、结构和进化的信息具有非常重要的意义，其主要思想就是运用特定的算法找出两个或多个序列之间产生最大相似性得分的空格插入和序列排列方案。  在实际操作中，序列比对是计算生物学中解决序列装配、进化树重构及分析基因功能等众多问题的第一步。 根据同时比对的序列数量的不同，一般将序列比对分成双序列比对和多序列比对。 与双序列比对相比，多序列比对能有效发掘多个序列中的相似性信息。  当两个序列不能很好地比对并借此揭示序列的变化所蕴含的意义时，通过引入更多的序列，多序列比对可有效地使这两个原本难以直接比对的序列合理地关联起来。 其次，多序列比对常常用于分析种系距离很大的多个序列，揭示这些序列中保守的和非保守的区段、保守区段的分布特征以及序列变化的进化趋势，这对于研究生物系统的进化是必不可少的。 再者，许多预测RNA和蛋白质结构与功能的算法立足于相应的多序列比对，通过比较未知分子的序列和已知分子的序列来预测前者的结构与功能。 因此，多序列比对是基因组分析和蛋白质组分析的最常用手段之一。     同源、相似与距离  同源：如果两个序列享有一个共同的进化上的祖先，则这两个序列是同源的。 同源是个定性的概念，没有“度”的差异。 与同源相关但不同的两个概念是相似和距离，它们都是定量的概念，基于对序列中字符的精确比较，既可以说两个序列高度相似，也可以说它们之间的跟离非常小。 相似性与距离是两个定量描述多个序列相似程度的度量。 使用相似性时，比对计分给出被比对序列间的相似程度，使用距离时，比对计分给出被比对序列间的差异程度。 相似性既可用于全局比对也可用于局部比对，而距离一般仅用于全局比对，因为它反映了把一个序列转换成另一个序列所需的字符替换的耗费。 同源可进一步分作垂直同源和水平同源。  垂直同源是指在种系形成过程中起源于一个共同祖先的不同种系中的DNA或蛋白质序列，其关系可用一棵倒置的树说明。 水平同源主要是由序列复制事件产生的，例如人alpha-1球蛋白和alpha-2球蛋自是水平同源的，人alpha-1球蛋白和beta球蛋白也是水平同源的。 一般假定，同源序列具有相同的功能。例如，与血红蛋白同源的人和鼠的肌球蛋白都能在肌肉中运输氧，但应注意，垂直同源和水平同源基因未必总有相同的功能。     相似与距离的定量描述   相似性可定量地定义为两个序列的函数，即它可有多个值，值的大小取决于两个序列对应位置上相同字符的个数，值越大则表示两个序列越相似。\n  编辑距离也可定量地定义为两个序列的函数，其值取决于两个序列对应位置上差异字符的个数，值越小则表示两个序列越相似。\n  可以看出，相似性和编辑距离是一对相反的定量描述序列相似性的度量。这样，相似性有两种定量表达的方式：编辑距离和相似性得分。\n  使用相似性描述两个序列相似程度，是以某种计分规则计算两个序列相似性所得的分值。\n  计分一般是字符位置无关的（字符列无关的），即计算对应字符两两比较的分数，然后将所有字符的分数累加得到两条序列的相似性得分。\n  显然，存在许多不同的计分规则可对两两字符比较进行计分。明显地，除了在两个字符上不同的计分规则可以产生差异，序列间排列的不同也影响相似性得分。例如，如果seql与seq2交错一位再比对，则计分结果将显著受到影响。\n     seq1= ATC AGGCT GCTAGCTA       seq2= TAC ACCTT CGTGAGCA   打分规则1 p(a,a)=1        p(a,b)=0,(a≠b) 相似性得分= 1 2 3   打分规则2 p(a,a)=0.8        p(a,b)=0.2,(a≠b) 相似性得分= 1.2 2.2 2.8   打分规则BLAST   -3 -2 -6    A T C G    A 5 -4 -4 -4    T -4 5 -4 -4    C -4 -4 5 -4    G -4 -4 -4 5           编辑距离一般用海明（Hamming）距离表示，对于两条长度相等的序列，它们的海明距离等于对应位置不同字符的个数。\n| seq1= | ATC | AGGCT | GCTAGCTA |\r| ---------------------------- | ---- | ----- | -------- |\r| seq2= | TAC | ACCTT | CGTGAGCA |\r| Hamming Distance(seq1,seq2)= | 2 | 3 | 6 |\r   算法实现的比对  比对两个序列就是找出两个序列的最长公共子序列，它反映了两个序列的最高相似度。 序列v的子序列是v中一个有序但末必连续的字符序列。 例如，若v=ATTGCTA，则AGCA和ATTA都是v的子序列，而TGTT和TCG则不是。再如，若v=ATCTGAT, w=TGCATA，则v和w存在多个共同子序列，包括TCTA；显然，其中一些共同子序列要比另外一些共同子序列长。但问题是，如何找出最长的共同子序列常常并不是显而易见的。 寻找两个序列的最长共同子序列的一个简单方法是，先计算出所有可能的共同子序列，然后找出最长的那个。但此方法不具有实际的可行性，因为当序列较长时计算所有可能的共同子序列极其费时。   序列比对的作用： 相比于双序列比对，多序列比对具有更广泛的重要应用，包括以下几个方面。  获得共性序列：由多序列比对所得到的与所有序列距离最近的序列称为这此序列的共有序列（也称一致序列），共性序列常用于数据库搜索和芯片探针设计，用于识别只有高相似度的序列。 序列测序：如一个DNA或蛋白质序列被多个机构测序，则测序结果在某些核苷酸或氨基酸上可能存在差异，对这些测序结果进行全局多序列比对，可发现这些差异之处，形成的共性序列理论上最为接近真实的序列。其次，对包含重叠区的多个测序序列进行局部多序列比对可发现这些重叠区，实现测序序列的拼接。 突变分析：同一种系不同个体的基因组存在因突变而产生的差异，最常见的是单核苷酸多态性，指不同个体基因组中单个核苷酸的包括置换、缺失和插入在内的变异，这些差异可通过多序列比对进行揭示。 种系分析：相近种系动植物的基因和基因组由于源自共同的直接祖先而具有高度的相似性，反之，远距种系动植物的基因和基因组由于源自不同的直接祖先而享有更少的相似性，这一事实使得多序列比对常常用于根据基因或基因组序列的差异判断种系关系，多序列比对通常是构造种系树的第一步。 保守区段分析：基因组中功能不同的区段在进化中面对不同的选择压力，即重要的区段不易接受突变而非重要的区段易于接受突变。任何基因组都包含大量不同的在选择压力下保持进化上稳定的保守区段，多序列比对是找出进化上保守的这此区段的基本方法。 基因和蛋白质功能分析：在大量基因和蛋白质的功能得以揭示和更多基因和蛋白质的序列得以测定后，根据与功能已知的同源基因和蛋白质进行多序列比对来推断新基因和蛋白质的功能已成为越来越普遍的一个研究手段。    2. 英文及缩写  双序列比对：pairwaise alignment； 多序列比对：multiple alignment； 同源：homolog； 相似：similarity； 距离：distance； 趋同进化：convergent evolution； 垂直同源：ortholog； 水平同源：paralog； 编辑距离：edit distance； 最长公共子序列：longest common subsequence，LCS； 共有序列：consensus sequence；  第二节 比对算法概要 1.名词  替换计分矩阵：对于序列中单个字符的插入和缺失引起的失配，序列比对采用插入空格来处理，使得原本对应的字符仍}日能够对应；而对于序列中单个字符的替换引起的失配，需要考虑不同替换的意义。在双序列比对中对于这类失配应该怎么计分（实际上是罚分）是本节的内容。合理而精确的计分需要考虑替换的各种情形。对于DNA和RNA序列，情况特别简单，施用于4种碱基和6种彼此间替换关系的计分规则可用简单的替换计分矩阵来描述。对于蛋白质序列，因为蛋白质由20种氨基酸构成，且不同的氨基酸具有不同的理化性质，情况较为复杂，存在许多不同的替换计分矩阵。  通过点矩阵对序列比较进行计分： “矩阵作图法”或“对角线作图”由Gibb首先提出。将两条待比较的序列分别放在矩阵的X/Y轴上，从下往上和从左到右比较，当对应行与列的字符匹配时，则在矩阵对应的位置上打点。逐个比较所有的字符对，最终形成一个点矩阵。如果两条序列完全相同，则点矩阵的主对角线各位置都被标记；如果两条序列存在相同的子串，则对每一个子串对有一条与对角线平行的由一系列点组组成的斜线；而对于两条互为反向的序列，则在反对角线方向上有由点组成的斜线。这种反映序列比对的方法在直观地揭示多个相配的子串对时尤其有用，一直被使用到现在。 DNA序列比对的替换计分矩阵： 借鉴上面点矩阵的方法，可以为不同字符间的替换建立替换计分矩阵，它们或依据相应碱基或氨基酸的理化性质而确定，或依据突变实际发生的概率而确定，因此相当客观和固定。  等价矩阵：是最简单的一种替换计分矩阵，其中，相同核苷酸间的匹配得分为1，不同核苷酸间的替换得分为0。尽管含义清晰明了，由于不含有碱基的任何理化信息和不区别对待不同的替换，在实际的序列比对中较少使用。 转换-颠换矩阵：核酸的碱基按照环结构特征被划分为嘌呤（腺嘌呤A，鸟嘌呤G，它们有两个环）和嘧啶（胞嘧啶C，胸腺嘧啶T，它们只有一个环）。如果DNA碱基的替换保持环数不变，则称为转换，如A→G，C→T；如果环数发生变化，则称为颠换，如A→C，A→T等。在进化过程中，转换发生的频率远比颠换高，其中转换的得分为-1. 而颠换的得分为-5 BLAST矩阵：经过实际比对发现，如令被比对的两个核苷酸相同时得分为+5，反之得分为-4，则比对效果较好。这个矩阵广泛地被DNA序列比对所采用，称为BLAST矩阵。   蛋白质序列比对的替换计分矩阵： 蛋白质序列可由20个氨基酸组成，它们具有不同的生物化学特性，这此特性会影响它们在进化过程中的相互替换性。例如，与体积差异大的氨基酸相比，体积相似的氨基酸更易于彼此并换。另外，与水的亲和性也影响相互替换的概率。再者，生物学家己观察到天冬酰胺（Asn），天冬氨酸（Asp）、谷氨酸（Glu）和丝氨酸（Ser）属于最容易突变的氨基酸，而半胱氨酸（Cys）和色氨酸（Trp）则属于最不易突变的氨基酸。因此，在比较蛋白质序列时，简单的计分系统（例如+1表示匹配，0表示失配，-1表示空格）是不够的，必须使用一个能够充分反映氨基酸的相互替换性的计分系统。下面介绍多个不同的氨基酸替换计分矩阵。  等价矩阵； 遗传密码矩阵； 疏水性矩阵； PAM矩阵； BLOSUM矩阵；     双序列全局比对：对于两条序列的比对问题，人们提出了很多算法。其中基于动态规划的算法是目前最基本的算法。 双序列局部比对： 多序列全局比对：主要涉及四个要素：① 选择一组能进行比对的序列（要求是同源序列）；② 选择一个实现比对与计分的算法与软件；③ 确定软件的参数；④ 合理地解释比对的结果。 多序列局部比对： 比对的显著统计性：  2. 英文及缩写  计分矩阵：substitution matrix； 等价矩阵：unitary matrix； 转换-颠换矩阵：transition-transversion matrix； 转换：transition； 颠换：transversion； 遗传密码矩阵：genetic code matrix，GCM； 疏水性矩阵：hydrophobic matrix； PAM矩阵：可接受点突变point accepted mutation，或可接受突变百分比percent of accepted mutation； BLOSUM矩阵：BLOck SUbstitution Matrix； 动态规划：dynamic programming； 渐进多序列比对：progressive multiple alignment； 指导树：guide tree； 离异度：divergence； 空缺：gap； 引入空缺：gap open； 扩展空缺：gap extend； 分层聚类法：hierarchical clustering；  第三节 数据库检索 1. 名词  经典BLAST：是目前最常用的数据库搜索程序。 它的要点是片段对的概念，它是指两个给定序列中的一对子序列，它们的长度相等，且可以形成无空格的完全匹配。 BLAST首先找出查询序列和目标序列间所有匹配程度（以得分计）超过一定阈值的片段对，然后对片段对根据给定的相似性阈值进行延伸，得到一定长度的相似性片段，最后给出高分值片段对。 BLAST在线服务实际上包含一组程序，不仅可用于直接对蛋白质序列数据库和核酸序列数据库进行搜索，而且可以将查询序列翻译成蛋自质后再进行搜索，以提高搜索结果的灵敏度。  BLAS下的应用：BLAST具有非常厂泛的应用： (1)确定一个蛋白质或核酸序列有哪些垂直同源或水平同源序列。 (2)确定哪些蛋白质或基因在特定的物种中出现。 (3)发现新基因。 (4)确定一个基因或蛋自质的变种。 (5)寻找对于一个蛋白质的功能或结构起关键作用的片段。 搜索步骤： (1)选择感兴趣的序列，可以是FASTA格式的序列，也可以是访问编号。 (2)选择BLAST程序，包括blastp，blastn，blastx，tblastn，tblastx。 (3)选择数据库。 (4)选择参数。 常用的输入与输出参数： (1) -p ProgramName：p代表program，可带的选项是blastp，blastn，blastx，tblastn和tblastx。\n(2) -i QueryFile：用于指定包含查询序列的查询文件。 (3) -d DatabaseName：选择待搜索的数据库，可以选择多个数据库。 (4) -o OutputFileName：数据库搜索输出文件的名称，默认的计算机屏幕。 (5) -e ExpectedValue：E期望值，这一参数控制搜索的敏感性。 (6) -m SpecifiesAlignmentView：设定搜索结果的显示格式，选项有12个，其中0是默认参数，显示查询序列和目标序列两两比对的信息。 (7) -F FiIterQuerySequence：屏蔽简单重复和低复杂度序列的参数，有T（选上）和F（不选）两个选项。 (8) -E CostToExtendGap：给出空位延伸罚分。 BLAST程序的参数有搜索参数，包括字长（word size）、期望值E、空格罚分、替换计分矩阵、阈值、窗口尺寸（window size）等，以及统计学显著性参数，包括λ和K。   衍生BLAST  PSI-BLAST：即Position-Specific Iterated BLAST是一个专门化的搜索工具。 PHI-BLAST：即Pattern-Hit Initiated BLAST。能用来帮助判断这个蛋白质属于哪个家族。 BLASTZ：是在比对人和鼠的基因组中发展起来的，它适合于比对非常长的序列。   BLAT： RNA序列搜索： 数据库搜索的统计显著性：  2. 英文及缩写  BLAST：Basic Local Alignment Search Tool； 片段对：segment pair； 高分值片段对：high-scoring pairs； 位点特异性计分矩阵：position-specific scoring matrix, PSSM； BLAT：The BLAST-Like Alignment Tool；  ","date":1519084800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1519084800,"objectID":"aba6ccbd19a3e4597faea4381e3e55b6","permalink":"/post/%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF%E5%AD%A6-%E6%9D%8E%E9%9C%9E%E7%AC%AC%E4%BA%8C%E7%89%88-%E7%AC%AC%E4%BA%8C%E7%AB%A0/","publishdate":"2018-02-20T00:00:00Z","relpermalink":"/post/%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF%E5%AD%A6-%E6%9D%8E%E9%9C%9E%E7%AC%AC%E4%BA%8C%E7%89%88-%E7%AC%AC%E4%BA%8C%E7%AB%A0/","section":"post","summary":"第二章 序列比对 第一节 引言 1. 名词 序列比对：序列比对对于发现生物","tags":["生信"],"title":"生物信息学-李霞第二版-第二章","type":"post"},{"authors":null,"categories":["生物信息学"],"content":"第一章 生物序列资源 第一节 引言 1. 英文及缩写  DNA序列：DNA sequence； RNA序列：RNA sequence； 微阵列数据和基因表达：microarray data and gene expression； 蛋白质序列：protein sequence； 分子结构：structure； 蛋白质组学和蛋白质互作：proteomics and interaction； 代谢和信号通路：metabolic and signaling pathways； 人类基因与疾病：human genes and diseases； 生理与病理：physiology and pathology； 药物与药物靶标：drug and drug targets； 细胞器与细胞生物学：organelle and cell biology； 人类及其他脊椎动物基因组：human and other vertebrate genomics； 非脊椎动物基因组：non-vertebrate genomics； 植物基因组：plants genomics；  第二节 NCBI数据库与数据资源 1. 名词  三大生物序列信息数据库：GenBank，EMBL，DDBJ； NCBI中较重要的数据子库：  GenBank：GenBank是NIH遗传序列数据库，集成了所有公开可获得的已注释DNA序列。 GenBank收录的核酸序列数据根据其不同的研究属性，分属于Nucleotide、GSS和EST三个子库。  Nucleotide：收录绝大多数常规的核酸序列； GSS：Genome Survey Sequence，收录测序起始阶段用来进行序列或基因示踪、重复序列或基因数量预判等的各种短读长（reads）序列； EST：Expression Sequence Tag，收录cDNA及cDNA特征序列信息。   RefSeq：GenBank中的数据是由用户提交数据构成，具有较高的冗余度和差错率，为更好实现特征序列的查询，NCBI在GenBank数据基础上针对每个基因不同的数据类别提取一个可靠的注释条目作为参考条件，组成RefSeq（reference sequence）数据库。 其数据标识类似于NM_000572.2，“NM_”代表特异的数据类型，“.2”表示更新版本。 Gene数据库：基因数据库收录全部已测序五中的基因注释信息，包括基因的名称、染色体定位、基因序列和编码产物（mRNA，蛋白质）情况、基因功能和相关文献信息等。 基因数据库标识符即Entrez gene ID，依据基因的发现顺序由1到多位数字组成，如IL10基因的标识符为3586。 Genome：NCBI收录了超过1000中已经完成测序的生物体全部基因组序列和定位数据，以及正在进行测序的物种阶段性发布的基因组信息。 遗传多态数据库：NCBI中的dbSNP、dbVar、dbGap和ClinVar四个子库涉及DNA多态或变异信息。  dbSNP：收录了所有物种中发现的短序列多态和突变信息，包括单核苷酸多态、微卫星、小片段插入\\删除多态（in/del）等定位、侧翼序列和功能、频率信息。收录的SNP条目一般以“rs+数字”的形式表示； dbVar：主要收录较大规模的基因组变异，包括大片段的插入、遗失、易位、倒置和拷贝数多态等信息资源； dbGap：收录大量以遗传多态为分子标记物的基因型和表型（疾病）关联性研究数据； ClinVar：收录临床中发现或报导的有证据支持的与人类疾病或健康状态有段的变异位点，并与多个疾病和卫生系统数据库进行交互引用。   GEO：Gene Expression Omnibus：接受和管理各研究机构提交的基因芯片或测序技术获得的不同生理、病理状态个体或细胞系基因（包括非编码基因）表达数据。 蛋白质数据库：NCBI蛋白质数据库收录来源于GenPept、RefSeq、Swiss-Prot、PIR、PRF及PDB等蛋白质数据资源的蛋白质序列和注释数据。  Protein Cluster数据库：提供存在一定联系的蛋白质集合信息，并与蛋白质注释、结构、结构域、家族相关数据库之间交互访问； Structure数据库：是由蛋白质三维结构数据库PDB衍生出来的大分子模建数据库，提供蛋白质三维结构信息及相关的可视化和结构比对工具。   Epigenomics：是一个表观基因组数据查询和浏览相结合的数据库。提供DNA甲基化、组蛋自修饰等表观遗传学数据集下载，基因序列、表观遗传状态的定位比较和可视化等。 Unigene数据库：针对每一个基因建立一个独立的数据体系，分别将不同来源的基因序列、蛋白质相似性（与模式生物比较）、基因表达（不同组织或发育状态）、染色体定位、cDNA序列、mRNA序列（选择性剪接）、EST序列等进行罗列和比较，旨在为研究者提供全面、丰富的信息资源，更好地对基因的功能和注释信息的可靠性进行梳理。 与生物医学相关的重要数据库：  OMIM数据库：在文献检索基础上，分别以疾病和基因为中心，阐述遗传变异介导的疾病（表型）相关基因情况，及变异介导的基因参与不同疾病（表型）情况； GdbMHC：Database of Major Histocompatibility Complex，收录人类主要组织相容性复合体数据及其相关的分子标记物信息； HIV-1与人类蛋白质互作数据库：收录HIV-1蛋自与人类宿主蛋自相互作用信息。NCBI中还包括大量病毒相关信息（如病毒基因组序列，流感. SARS等特种病毒解析，病毒基因组变异等）、药物化学信息和文献数据信息等。   NCBI提供的重要支持工具：  BLSAT，是由NCBI开发的序列相似性搜索程序，检索速度快，有助于识别基因和基因特征(详见第二章)。 Primer-BLAST工具： Primer-BLAST链接地址，可用于多方面生物医学研究过程的核酸引物设计。 由NCBI提供的其他软件工具还包括:开放阅读框搜索（ORF Finder）、电子PCR和序列提交工具Sequin和BankIt等。      2. 英文及缩写  美国国家健康研究所：NIH； 国家医学图书馆：NLM； 人类拉丁种名：Homo Sapiens； 包括单核苷酸多态：single nucleotide polymorphysm，SNP； 微卫星：microsatelite； 拷贝数多态：copy number variation，CNV； 基因组范围关联分析：GWAS；  第三、四节 UCSC基因组浏览器与数据资源、EMBL-EBI数据库与数据资源 1. 名词  UCSC基因组浏览器： UCSC基因组浏览器链接，重要的基因组数据收集、整理、检索、可视化和辅助研究的重要工具；  导航栏和工具栏提供多种便利的基因组查询和注释工具  Browser可以缩放和滚动的方式查看染色体的注释； Blat可以快速将用户输入的序列以图像的方式在基因组中显示； Tables提供便捷的入口链接到基础数据库； Gene Sorter展示表达、同源性和以多种方式关联的其他基因组信息； VisiGene可以让用户浏览大量的检测小鼠和青蛙表达模式的原位图像； Genome Graphs允许用户上传或显示基因组范围的数据集等。     EMBL-EBI数据库：  Ensembl基因组序列数据资源：EMBL-EBI中有Ensembl和Ensembl Genmoes基因组序列资源数据库；  Ensembl数据库：提供高质量、综合注释的脊椎动物基因组数据； Ensembl Genmoes数据库：提供非脊椎动物全基因组数据；   ENA欧洲核苷酸数据库：提供世界范围的核酸测序原始数据、序列拼接和功能注释信息的维护和下载，并记录和存储数据集测序全过程的技术应用情况：样品分离和材料准备，使用的仪器设备和配置，实验过程的主要环节，数据输出后的序列读取和质量评价，数据的生物信息学拼接、制图、功能注释等。 ENA数据包括机构或个人提交的原始数据，序列拼接和小规模测序注释数据，欧洲各大测序中心提供的测序数据，国际核酸序列数据库协作组织的合作伙伴的定期交换数据等。 UniProt蛋白质数据资源：  UniProt数据库包括：UniProtKnowledgebase（UniProrKB）、UniProt Reference Clusters（UniRef），UniProt Archive（UniParc）三个主要部分，及用于专门存放元基因组和环境基因组数据信息的UniProt Meta-genomic和Environmental Sequences（UniMES）数据库。 门户链接或 EBI链接。 UniProrKB：UniProtKB是UniProt的核心资源，主要包括Swiss-Prot和TrEMBL两部分核心数据。  UniProt/Swiss-Prot：收录非冗余的、高质量的专家手工注释数据。注释过程针对每一个蛋白质可用的序列信息进行分析、比较、整合，严格审核与本条目相关的文献发表的实验和计算分析。 对于每一条记录，UniProt/Swiss-Prot期望从文献、其他数据库中搜集每一个物种每一个蛋白质的所有注释信息，以及与蛋白质相关的选择性剪接、多态、翻译后修饰、蛋自质家族等信息。 UniProtKB/TrEMBL：收录的蛋白质信息是经高质量计算分析获得的自动化注释和分类信息，也是Swiss-Prot的资源储备库，一经手工注释后即转入Swiss-Prot。 概括起来看，UniProtKB收录的蛋白质序列信息包括:① DDBJ/ENA/GenBank来源的编码序列（CDS）翻译；② PDB中存储了结构信息的蛋自质序列；③ Ensembl和RefSeq提供的序列；④ 直接提交到UniProtKB或文献检索到的氨基酸序列。        2. 英文及缩写  加州大学圣克鲁兹分校：University of California，Santa Cruz，UCSC； 欧洲生物信息学研究所：EBI， 地址; 欧洲分子生物学实验室：EMBL， 地址； 瑞士生物信息学研究所：SIB； DNA元件百科全书计划：Encyclopedia of DNA Elements，ENCODE， 地址; 尼安德特人基因组分析：Neandertal， 地址; 哺乳动物：mammal； 后口动物：deuterostome； 昆虫：insect； 线虫：nematode； 欧洲核苷酸数据库：European Nucleotide Archive，ENA， 地址； 国际核酸序列数据库协作组织：INSDC； 蛋自质专家注释系统：Swiss-Prot； 核酸序列翻译数据库：TrEMBL；  第五节 重要的非编码基因数据库 1. 名词  ENCODE数据库：ENCODE全称为DNA元件百科全书计划，与2003年启动，获得并分析了超过15兆兆（15万亿字节）的原始数据，对基因组功能元件进行解析。 与编码蛋白质相关的基因只占整个基因组的2%，人类基因组中约80%的DNA序列是具有某种特定功能的。 miRBase：miRBase（ 地址）是存储、维护和命名微小RNA（microRNA）的主要数据库，主要数据资源为microRNA序列和注释信息。miRBase使用友好的网络界面，为用户提供miRNA前体和成熟序列下载。允许用户使用关键词或序列检索数据库，通过关联链接到miRNA的原始参考文献，分析基因组中的定位和挖掘miRNA序列间的关系。miRBase还提供保密的基因命名服务，在新基因发表前指定正式的miRNA名称。  2. 英文及缩写  微小RNA：microRNA；  习题  生物数据库根据其存储的数据类型可以分为几类？\n答：大致可分为5类：基因组数据库、核酸序列数据库、蛋白质序列数、生物大分子（主要是蛋白质）三维空间结构数据库、及根据生命科学不同研究领域的实际需要，对基因组图谱、核酸和蛋自质序列、蛋自质结构以及文献等数据进行分析、整理、归纳、注释，构建具有特殊生物学意义和专门用途的二次数据库。 DDBJ和另外哪两个数据库并称为世界三大核酸数据库，并通过网络查询DDBJ数据库的信息存储情况。\n答：EMBL、GenBank。 Entrez Gene数据库从哪些方面对基因进行注释？\n答：注释内容包括基因概况、基因组结构、基因组定位、参考书目、表现型、基因变异、HIV-1互作、通路注释、互作、基因功能、同源性、编码蛋白质情况、序列信息，及交叉引用链接。 dbSNP数据库维护的数据类型有哪些，这些数据有什么应用？ 答：dbSNP：收录了所有物种中发现的短序列多态和突变信息，包括单核苷酸多态、微卫星、小片段插入\\删除多态（in/del）等定位、侧翼序列和功能、频率信息。 UCSC基因组浏览器显示的数据资源如何以可出版的图片形式输出？\n答：基因组浏览器图像输出：UCSC基因组浏览器支持生成适于文献出版和打印的高质量图像。打印前用户可以在序列碱基栏左端标签处点击鼠标右键选择配置管理（Configure ruler）按钮，打开设置页面，可在标题栏中添加通道输出图片标题，还可以选择增加组合名称和染色体位置方式将标题加入到通道中。鼠标左键拖拽各通道对应的灰色工具条还可以根据输出需要改变各通道的位置。用户完成通道图像配置后，点击导航栏中view按钮下拉菜单中的PDF/PS选项，选择所需的文件输出格式保存图像。 如何利用UCSC模块实现序列数据的批量下载？\n答： EMBL-EBI维护数据的规模化标准有哪些？ 答：数据资源遵循严格的规模化管理：① 可访问性，所有数据和工具完全开放访问；② 兼容性，数据达到世界最高层次的标准化规范，有利于推动数据共享；③ 数据集综合性，与各研究、出版机构和各人数据库达到数据提交、共享协议，保障数据来源和交叉引用；④ 便携性，EBI所有数据库均可下载，全部软件系统可以下载并本地安装；⑤ 保证质量，EBI具有专家注释系统，大量数据资源通过生物医学专家注释保障数据质量。 如何利用Ensembl-BioMart平台实现核酸序列数据的查询和下载？\n答： 简述UniProt数据的基本构建，并简要介绍UniProtKB的检索流程和主要的分析工具。 答：UniProt数据库包括UniProtKnowledgebase（UniProrKB）、UniProt Reference Clusters（UniRef）, UniProt Archive（UniParc）三个主要部分，及用于专门存放元基因组和环境基因组数据信息的UniProt Metagenomic和Environmental Sequences（UniMES）数据库。 试列举2到3个非编码基因序列维护数据库名称及其存储的数据特点。 答：  ","date":1518912000,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1518912000,"objectID":"5f8cd7c8aba3e816401a9cee746fa648","permalink":"/post/%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF%E5%AD%A6-%E6%9D%8E%E9%9C%9E%E7%AC%AC%E4%BA%8C%E7%89%88-%E7%AC%AC%E4%B8%80%E7%AB%A0/","publishdate":"2018-02-18T00:00:00Z","relpermalink":"/post/%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF%E5%AD%A6-%E6%9D%8E%E9%9C%9E%E7%AC%AC%E4%BA%8C%E7%89%88-%E7%AC%AC%E4%B8%80%E7%AB%A0/","section":"post","summary":"第一章 生物序列资源 第一节 引言 1. 英文及缩写 DNA序列：DNA s","tags":["生信"],"title":"生物信息学-李霞第二版--第一章","type":"post"},{"authors":null,"categories":["R","统计"],"content":"\r第2章 R语言环境\r2.1 会话管理\r2.1.1 工作空间窗口\r#用ls()命令了解都哪些变量定义在工作区\rls()\r## character(0)\r#这样输出有些乱\r#可以通过rm()命令来删除某些对象\rrm(height,weight)\r## Warning in rm(height, weight): 找不到对象\u0026#39;height\u0026#39;\r## Warning in rm(height, weight): 找不到对象\u0026#39;weight\u0026#39;\r\r2.1.6 内置数据\r#加载数据thuesen\rdata(thuesen)\r## Warning in data(thuesen): data set \u0026#39;thuesen\u0026#39; not found\r#需要注意的是thuesen这个数据框隶属于ISwR数据\r#要加载thuesen，需要先加载ISwR\rlibrary(ISwR)\rdata(thuesen)\r\r2.1.7 attach和detach\r#如果要重复写一些很长的命令，在数据集中获取变量的符号很很麻烦\r#比如\rplot(thuesen$blood.glucose,thuesen$short.velocity)\r#但可以简化\r#可以让R在给定数据集的变量中寻找目标\rattach(thuesen)\r#然后thuesen中的数据就可以得到，而不需要使用$符号\rblood.glucose\r## [1] 15.3 10.8 8.1 19.5 7.2 5.3 9.3 11.1 7.5 12.2 6.7 5.2 19.0 15.1\r## [15] 6.7 8.6 4.2 10.3 12.5 16.1 13.3 4.9 8.8 9.5\r#上述命令使thuesen被置于系统的搜索路径中\r#可以用search()看到搜索路径\r#可以看到thuesen被置于搜索路径的第二位\r#.GlobalEnv是工作空间\r#package:base是定义了所有标准函数的系统库\rsearch()\r## [1] \u0026quot;.GlobalEnv\u0026quot; \u0026quot;thuesen\u0026quot; \u0026quot;package:ISwR\u0026quot; ## [4] \u0026quot;package:methods\u0026quot; \u0026quot;package:stats\u0026quot; \u0026quot;package:graphics\u0026quot; ## [7] \u0026quot;package:grDevices\u0026quot; \u0026quot;package:utils\u0026quot; \u0026quot;package:datasets\u0026quot; ## [10] \u0026quot;Autoloads\u0026quot; \u0026quot;package:base\u0026quot;\r#可以用detach命令从搜索路径中删除数据集\r#如果不给出参数，那么位于第二位置的数据集将被删除\rdetach()\rsearch()\r## [1] \u0026quot;.GlobalEnv\u0026quot; \u0026quot;package:ISwR\u0026quot; \u0026quot;package:methods\u0026quot; ## [4] \u0026quot;package:stats\u0026quot; \u0026quot;package:graphics\u0026quot; \u0026quot;package:grDevices\u0026quot;\r## [7] \u0026quot;package:utils\u0026quot; \u0026quot;package:datasets\u0026quot; \u0026quot;Autoloads\u0026quot; ## [10] \u0026quot;package:base\u0026quot;\r\r2.1.8 subset，transform和within\r#可以附加一个数据框，从而避免对其中每一个变量的繁琐的索引\r#然而，这对于选择数据子集以及用变化变量创建新的数据框却少有帮助\r#有一些函数使得这一操作变得简单，如：\r#在此处用到subset和transform函数，这里只利用这两个函数的简单功能\r#subset函数，从某一个数据框中选择出符合某条件的数据或是相关的列\r#transform函数为原数据框添加新的列\rthue2 \u0026lt;- subset(thuesen, blood.glucose\u0026lt;7)\rthue2\r## blood.glucose short.velocity\r## 6 5.3 1.49\r## 11 6.7 1.25\r## 12 5.2 1.19\r## 15 6.7 1.52\r## 17 4.2 1.12\r## 22 4.9 1.03\r#transform函数中的=符号并不是赋值，而是表示名称\rthue3 \u0026lt;- transform(thuesen,log.gluc=log(blood.glucose))\rthue3\r## blood.glucose short.velocity log.gluc\r## 1 15.3 1.76 2.727853\r## 2 10.8 1.34 2.379546\r## 3 8.1 1.27 2.091864\r## 4 19.5 1.47 2.970414\r## 5 7.2 1.27 1.974081\r## 6 5.3 1.49 1.667707\r## 7 9.3 1.31 2.230014\r## 8 11.1 1.09 2.406945\r## 9 7.5 1.18 2.014903\r## 10 12.2 1.22 2.501436\r## 11 6.7 1.25 1.902108\r## 12 5.2 1.19 1.648659\r## 13 19.0 1.95 2.944439\r## 14 15.1 1.28 2.714695\r## 15 6.7 1.52 1.902108\r## 16 8.6 NA 2.151762\r## 17 4.2 1.12 1.435085\r## 18 10.3 1.37 2.332144\r## 19 12.5 1.19 2.525729\r## 20 16.1 1.05 2.778819\r## 21 13.3 1.32 2.587764\r## 22 4.9 1.03 1.589235\r## 23 8.8 1.12 2.174752\r## 24 9.5 1.70 2.251292\r#transform函数的替代方法有一种是within函数，用法如下：\rthue4 \u0026lt;- within(thuesen,{\rlog.gluc \u0026lt;- log(blood.glucose)\rm \u0026lt;- mean(log.gluc)\rcentered.log.gluc \u0026lt;- log.gluc - m\rrm(m)\r})\rthue4\r## blood.glucose short.velocity centered.log.gluc log.gluc\r## 1 15.3 1.76 0.481879807 2.727853\r## 2 10.8 1.34 0.133573113 2.379546\r## 3 8.1 1.27 -0.154108960 2.091864\r## 4 19.5 1.47 0.724441444 2.970414\r## 5 7.2 1.27 -0.271891996 1.974081\r## 6 5.3 1.49 -0.578266201 1.667707\r## 7 9.3 1.31 -0.015958621 2.230014\r## 8 11.1 1.09 0.160972087 2.406945\r## 9 7.5 1.18 -0.231070001 2.014903\r## 10 12.2 1.22 0.255462930 2.501436\r## 11 6.7 1.25 -0.343865495 1.902108\r## 12 5.2 1.19 -0.597314396 1.648659\r## 13 19.0 1.95 0.698465958 2.944439\r## 14 15.1 1.28 0.468721722 2.714695\r## 15 6.7 1.52 -0.343865495 1.902108\r## 16 8.6 NA -0.094210818 2.151762\r## 17 4.2 1.12 -0.810888496 1.435085\r## 18 10.3 1.37 0.086170874 2.332144\r## 19 12.5 1.19 0.279755623 2.525729\r## 20 16.1 1.05 0.532846250 2.778819\r## 21 13.3 1.32 0.341791014 2.587764\r## 22 4.9 1.03 -0.656737817 1.589235\r## 23 8.8 1.12 -0.071221300 2.174752\r## 24 9.5 1.70 0.005318777 2.251292\r\r\r2.2 作图系统\r2.2.1 图形布局\rx \u0026lt;- runif(50, 0, 2)\ry \u0026lt;- runif(50, 0, 2)\rplot(x, y, main = \u0026quot;Main title\u0026quot;, sub = \u0026quot;subtitle\u0026quot;,\rxlab = \u0026quot;x-label\u0026quot;, ylab = \u0026quot;y-label\u0026quot;)\r#可以在绘图区域放置点和线\r#可以在plot函数中设定\r#或者用points和lines添加\r#也可以添加如下命令\rtext(0.6, 0.6, \u0026quot;text at (0.6, 0.6)\u0026quot;)\rabline(h=.6, v=.6)\r#调用abline仅是表明文本如何以点（0.6,0.6）为中心的\r#通常，给定a和b后，abline绘制直线y=a+bx\r#边界坐标由mtext函数使用\r#for循环将数字-1到4放置在每条边界线的0.7位置\rfor(side in 1:4) mtext(-1:4, side = side, at=.7, line=-1:4)\r#接下来的调用在每个边界放置一个标签，给出边的数字，font=2表示使用粗体\rmtext(paste(\u0026quot;side\u0026quot;, 1:4), side = 1:4, line = -1, font = 2)\r\r2.2.2 利用部分构造图形\r#下面的命令绘制完全空白的图形\r#type=\u0026quot;n\u0026quot;使得点不被绘制，axes=F删掉坐标轴以及图周围的方框\r#x，y的标题标签被设置成空字符串\rplot(x, y, type = \u0026quot;n\u0026quot;, xlab = \u0026quot;\u0026quot;, ylab = \u0026quot;\u0026quot;, axes = F)\r#添加图形元素\r#第二个axis调用如何制定了小十字符（和标签）的替换\rpoints(x,y)\raxis(1)\raxis(2, at=seq(0.2, 1.8, 0.2))\rbox()\rtitle(main = \u0026quot;Main title\u0026quot;, sub = \u0026quot;subtitle\u0026quot;,\rxlab = \u0026quot;x-label\u0026quot;, ylab = \u0026quot;y-label\u0026quot;)\r\r2.2.3 par的使用\rpar函数可以对图的细节进行非常精细的控制\rpar设置润徐控制线宽和类型、字符大小和字体、颜色、坐标轴的类型、图形图标区域的大小、图形的裁剪等\r利用mfrow和mfcol参数可以把一个图分成几个子图\r\r\r2.2.4 组合图形\r#如果希望把一个元素一起放在同一张图的时候，就会产生一些特殊的要求\r#比如，为直方图添加一个正态密度函数\r#hist中的freq=F参数保证了直方图是根据比例而不是绝对数值画出来的\r#curve函数画出一个表达式（根据x），add=T润徐它叠加到已有的图上\r#但这样的还不够好\rx \u0026lt;- rnorm(100)\rhist(x, freq = F)\rcurve(dnorm(x), add = T)\r#解决方案\r#首先确定两个图形元素的y值的大小，然后使图形足够大到涵盖这两个值\rh \u0026lt;- hist(x, plot = F)\rylim \u0026lt;- range(0, h$density, dnorm(0))\rhist(x, freq = F, ylim = ylim)\rcurve(dnorm(x), add = T)\r\r\r\r","date":1518825600,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1518825600,"objectID":"8cfdd17eb44a4efd521c264318af8153","permalink":"/post/r%E8%AF%AD%E8%A8%80%E7%BB%9F%E8%AE%A1%E5%85%A5%E9%97%A8-%E7%AC%AC%E4%BA%8C%E7%AB%A0/","publishdate":"2018-02-17T00:00:00Z","relpermalink":"/post/r%E8%AF%AD%E8%A8%80%E7%BB%9F%E8%AE%A1%E5%85%A5%E9%97%A8-%E7%AC%AC%E4%BA%8C%E7%AB%A0/","section":"post","summary":"第2章 R语言环境 2.1 会话管理 2.1.1 工作空间窗口 #用ls()命令了解","tags":["R","统计"],"title":"R语言统计入门-第二章","type":"post"},{"authors":null,"categories":["生物信息学"],"content":"绪论 第一节 生物信息学的兴起 一. 名词：  第二代测序技术：边合成边测序； 第三代测序技术：单分子测序； 新一代测序技术：the next generation sequencing，NGS；  二. 英文与缩写：  美国国立生物技术信息中心： National Center for Biotechnology Information，NCBI； 欧洲生物信息学研究所：European Bioinformatics Institute，EBI； 人类基因组计划：human genome project，HGP； 人类单体型图计划：the international hapmap project，HapMap； 单核苷酸多态性：single nucleotide polymorphysm，SNP； 基因组范围关联分析：genome-wide association study，GWAS； 非编码基因：non-coding gene； 高清傅里叶转化质谱：high-resolution Fourier-transform mass spectrometry； 反相蛋白质芯片：reverse-phase protein arrays； 人类蛋白质组草图：the draft map of the human proteome；  第二节 生物信息学的内涵及其在生命科学中的应用 一. 名词：  生物信息学：是研究生物医学资源中蕴含的重要信息的学科，其核心是解决生物医学问题，其常规的研究内容可以简单概括为生物大分子的序列，结构和功能，以及它们之间的相互关系； 生物信息学的内涵：  研究领域：  序列对比：alignment，比较两个或两个以上分子序列的相似程度，包括核酸序列和蛋白质序列的对比过程； 序列装配：sequence assembling， 目前广泛应用的核算测序技术一般只能测出几十到几百个碱基对序列，技术的限制决定了测序过程需要对基因组进行打碎，并在测序后进行重新拼接的过程。 逐步把它们拼接起来形成序列更长的重叠群，直至得到完整序列的过程，即为序列装配； 基因识别：gene identification，基因识别的基本问题是在给定的基因组序列基础上，正确识别蛋白质组编码基因在基因组序列中的序列和精确定位； 多态和基因间区分析：基因多态的识别和功能鉴定是研究物种进化、种群多样性、人类疾病易感和药物敏感性的关键技术。而基因间区的基因组序列组织形式既有多态（重复片段）性，又具有不规则特性，既可能是重要的未知基因的潜伏区域、重要的功能调控子，也可能是真正意义上的“垃圾”片段，对它们的深入理解是解释华因组功能复杂性的关键因素。 RNA表达分析：这里的RNA表达分析主要包括编码RNA和非编码RNA的表达分析。 分子进化：分子进化和比较基因组学研究是从生物大分子的角度考虑的物种之间的垂直进化关系（建立系统发生树）或同一物种内不同亚种之间的迁移进化关系；既可以用DNA序列、遗传多态，也可以用蛋白质序列来开展相应的研究，甚至于可通过结构和分子网络层面的对比分析。 结构预测：structure prediction，主要针对蛋白质序列和RNA序列进行分析，包括2级和高级结构的预测过程； 分子互作：是细胞行使功能过程汇总最主要的作用形式，既包括最早认识到的蛋白质与蛋白质之间的互作关系，也包括蛋白质与核酸、核酸与核酸之间的相互作用。 分子互作是定性与定量相结合的分析过程，阐明分子互作不仅有利于了解整个细胞活动过程，也将对各种分子的功能和作用方式产生深刻的理解。      二. 英文及缩写  高通量组学：high-throughput omics； 生物标记：biomarker； 模式：pattern；  第三节 大数据时代的生物信息学与医学 一. 名词：  遗传图谱：genetic map，又称为连锁图谱linkage map。以遗传多态性标记位点为“路标”，以遗传学距离为图距的基因组图谱。 物理图谱：physical map，HGP DNA物理图谱的构建是基因组DNA测序的基础。 序列图谱：sequence map。 基因图谱：gene map。 组学与生物信息学：组学（X-Omics）概念是参照基因组概念，针对不同层面的生物大分子数据的产生演化而来的描述高通量分子生物数据资源的词汇。  基因组学：genomics 基因组学、结构基因组学、功能基因组学是三个紧密相连的生物信息学重点研究内容。 基因组学的目标是测定和分析某个（些）物种的全部DNA序列特征。 结构基因组学可为基因组学提供大量DNA及蛋白质数据，是基因组学的有力支撑及基础。 功能基因组学的主要任务是充分、合理利用基因组学及结构基因组学提供的信息，系统地研究基因及其产物的功能。  基因组学：研究生物体基因组的组成情况，以及各基因的结构，彼此间关系及表达调控的科学。 结构基因组学： structure genomics，是一门用结构生物学方法在生物体整体水平上（如全生物体、全细胞或整个基因组）对全部蛋白质（受体蛋白质、酶、通道以及与基因调控密切相关的核酸结合蛋白质）、相关蛋白质复合物（如酶和底物，酶与抑制剂，作用源与受体，DNA与其结合蛋白等）、RNA及其他生物大分子进行分析，精细测定其三维结构的学科。 功能基因组学：functional gemomics，代表基因组学分析的新阶段，主要利用结构基因组学提供的信息，发展和应用新的实验以及计算方法，通过在基因组或系统水平上全面分析基因功能。其研究内容主要有如下几个方面：  基因组表达及调控的研究； 基因信息的识别； 基因功能信息的鉴定； 基因多样性分析； 比较基因组学comparative genomics     转录组学：transcriptomics 所谓转录组，就是转录后的所有mRNA的总称，这些能被翻译成蛋白质的编码部分以及非编码部分的功能及相互关系的研究就是转录组的任务。 蛋白质组学：proteomics 是研究一个生命体在其整个生命周期中发挥作用的全部蛋白质，或者参与特定时间和空间（如特定类型的细胞在某一时期经历特定刺激时）范围相关功能的全体蛋白质的情况，包括表达水平、翻译后的修饰、蛋白质-蛋白质互作关系等特征，从而在蛋白质水平上获得对于有关生物体生理、病理等过程的全面认识。    ","date":1518825600,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1518825600,"objectID":"ea692fe8646c4398bd426c575512cff7","permalink":"/post/%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF%E5%AD%A6-%E6%9D%8E%E9%9C%9E%E7%AC%AC%E4%BA%8C%E7%89%88-%E7%BB%AA%E8%AE%BA/","publishdate":"2018-02-17T00:00:00Z","relpermalink":"/post/%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF%E5%AD%A6-%E6%9D%8E%E9%9C%9E%E7%AC%AC%E4%BA%8C%E7%89%88-%E7%BB%AA%E8%AE%BA/","section":"post","summary":"绪论 第一节 生物信息学的兴起 一. 名词： 第二代测序技术：边合成边","tags":["生信"],"title":"生物信息学-李霞第二版-绪论","type":"post"},{"authors":null,"categories":["随笔"],"content":"\r前言\r这是我的第一篇博客。 遥想一年前，兴致勃勃的开始自学生物信息学与R，但是时断时续，没能坚持下来。 现在经过两天摸索，自己建立个网站，或者准确点说，是博客，来记录自己所学，希望能坚持下来。\n\r","date":1518480000,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1518480000,"objectID":"b239fa87cecc5b4990b306b130fb7aa7","permalink":"/post/%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2/","publishdate":"2018-02-13T00:00:00Z","relpermalink":"/post/%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2/","section":"post","summary":"前言 这是我的第一篇博客。 遥想一年前，兴致勃勃的开始自学生物信","tags":["杂"],"title":"第一篇博客","type":"post"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1461715200,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"/project/external-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/external-project/","section":"project","summary":"An example of linking directly to an external project website using `external_link`.","tags":["Demo"],"title":"External Project","type":"project"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1461715200,"objectID":"8f66d660a9a2edc2d08e68cc30f701f7","permalink":"/project/internal-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/internal-project/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Internal Project","type":"project"},{"authors":["Dr.二哈","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1441065600,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1441065600,"objectID":"966884cc0d8ac9e31fab966c4534e973","permalink":"/publication/journal-article/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/journal-article/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example journal article","type":"publication"},{"authors":["Dr.二哈","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1372636800,"objectID":"69425fb10d4db090cfbd46854715582c","permalink":"/publication/conference-paper/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/conference-paper/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example conference paper","type":"publication"}]